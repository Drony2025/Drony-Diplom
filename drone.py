# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/194Xt3i9mPqxAEyXH_VwliCP5V4MSS-o2
"""



# Встановлення всіх необхідних бібліотек
!pip install kagglehub opencv-python-headless numpy pandas matplotlib pillow tqdm albumentations pyyaml ultralytics torch torchvision filterpy fpdf

# Модуль 1: Робота з даними

import os
import cv2
import random
import numpy as np
import pandas as pd
from tqdm import tqdm
import matplotlib.pyplot as plt
from PIL import Image
import shutil
from sklearn.model_selection import train_test_split
import albumentations as A
import kagglehub
import zipfile
import yaml

class DataProcessor:
    """
    Клас для обробки та підготовки даних для системи виявлення дронів.
    """

    def __init__(self, base_path='./drone_data'):
        """
        Ініціалізація обробника даних.

        Параметри:
        -----------
        base_path : str
            Базовий шлях для зберігання даних
        """
        self.base_path = base_path

        # Створення основних директорій
        self.train_path = os.path.join(base_path, 'train')
        self.valid_path = os.path.join(base_path, 'valid')
        self.test_path = os.path.join(base_path, 'test')

        os.makedirs(self.train_path, exist_ok=True)
        os.makedirs(self.valid_path, exist_ok=True)
        os.makedirs(self.test_path, exist_ok=True)

        # Налаштування для класів об'єктів
        self.class_names = ['drone']
        self.class_map = dict(zip(range(len(self.class_names)), self.class_names))

    def download_dataset(self, dataset_id='dasmehdixtr/drone-dataset-uav'):
        """
        Завантаження набору даних з Kaggle.

        Параметри:
        -----------
        dataset_id : str
            Ідентифікатор набору даних на Kaggle

        Повертає:
        -----------
        str : Шлях до завантаженого набору даних
        """
        print(f"Завантаження набору даних: {dataset_id}")
        dataset_path = kagglehub.dataset_download(dataset_id)
        print(f"Набір даних завантажено у: {dataset_path}")
        return dataset_path

    def extract_dataset(self, zip_path, extract_to=None):
        """
        Розпакування архіву з набором даних.

        Параметри:
        -----------
        zip_path : str
            Шлях до архіву
        extract_to : str, опціонально
            Шлях для розпакування (якщо не вказано, використовується базовий шлях)
        """
        if extract_to is None:
            extract_to = self.base_path

        print(f"Розпакування архіву: {zip_path} до {extract_to}")
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(extract_to)

    def find_annotations(self, dataset_path, annotation_ext='.txt', image_ext='.jpg'):
        """
        Пошук файлів анотацій та відповідних зображень у наборі даних.

        Параметри:
        -----------
        dataset_path : str
            Шлях до набору даних
        annotation_ext : str
            Розширення файлів анотацій
        image_ext : str
            Розширення файлів зображень

        Повертає:
        -----------
        list : Список шляхів до файлів анотацій
        """
        annotation_paths = []

        for root, _, files in os.walk(dataset_path):
            for file in files:
                if file.endswith(annotation_ext):
                    annotation_path = os.path.join(root, file)
                    image_path = annotation_path.replace(annotation_ext, image_ext)

                    # Перевіряємо, чи існує відповідне зображення
                    if os.path.exists(image_path):
                        annotation_paths.append(annotation_path)

        print(f"Знайдено {len(annotation_paths)} файлів анотацій з відповідними зображеннями")
        return annotation_paths

    def split_dataset(self, annotation_paths, train_ratio=0.7, valid_ratio=0.2, test_ratio=0.1, random_seed=42):
        """
        Розбиття набору даних на тренувальну, валідаційну та тестову вибірки.

        Параметри:
        -----------
        annotation_paths : list
            Список шляхів до файлів анотацій
        train_ratio : float
            Частка даних для тренування
        valid_ratio : float
            Частка даних для валідації
        test_ratio : float
            Частка даних для тестування
        random_seed : int
            Зерно генератора випадкових чисел

        Повертає:
        -----------
        dict : Словник з індексами для кожної вибірки
        """
        # Перевірка правильності співвідношень
        assert abs(train_ratio + valid_ratio + test_ratio - 1.0) < 1e-10, "Співвідношення мають давати в сумі 1.0"

        # Перемішування індексів
        n = len(annotation_paths)
        indices = list(range(n))
        random.seed(random_seed)
        random.shuffle(indices)

        # Розрахунок розмірів вибірок
        train_size = int(train_ratio * n)
        valid_size = int(valid_ratio * n)

        # Розподіл індексів
        train_indices = indices[:train_size]
        valid_indices = indices[train_size:train_size+valid_size]
        test_indices = indices[train_size+valid_size:]

        split_info = {
            'train': train_indices,
            'valid': valid_indices,
            'test': test_indices
        }

        print(f"Розподіл даних: Тренувальна={len(train_indices)}, "
              f"Валідаційна={len(valid_indices)}, Тестова={len(test_indices)}")

        return split_info

    def copy_files_to_folders(self, annotation_paths, split_info, image_ext='.jpg'):
        """
        Копіювання файлів у відповідні директорії для тренування, валідації та тестування.

        Параметри:
        -----------
        annotation_paths : list
            Список шляхів до файлів анотацій
        split_info : dict
            Словник з індексами для кожної вибірки
        image_ext : str
            Розширення файлів зображень
        """
        # Очищення директорій перед копіюванням
        for path in [self.train_path, self.valid_path, self.test_path]:
            for file in os.listdir(path):
                os.remove(os.path.join(path, file))

        # Копіювання файлів для кожної вибірки
        for split_name, indices in split_info.items():
            target_path = getattr(self, f"{split_name}_path")

            for i in tqdm(indices, desc=f"Копіювання файлів для {split_name}"):
                annotation_path = annotation_paths[i]
                image_path = annotation_path.replace('.txt', image_ext)

                if os.path.exists(image_path):
                    shutil.copy2(annotation_path, target_path)
                    shutil.copy2(image_path, target_path)

            print(f"Скопійовано {len(indices)*2} файлів (анотації + зображення) до {target_path}")

    def create_yaml_config(self, output_path='data.yaml'):
        """
        Створення конфігураційного файлу YAML для навчання моделі YOLO.

        Параметри:
        -----------
        output_path : str
            Шлях для збереження файлу конфігурації
        """
        data_yaml = {
            'train': os.path.relpath(self.train_path, start=os.path.dirname(output_path)),
            'val': os.path.relpath(self.valid_path, start=os.path.dirname(output_path)),
            'test': os.path.relpath(self.test_path, start=os.path.dirname(output_path)),
            'nc': len(self.class_names),
            'names': self.class_names
        }

        with open(output_path, 'w') as f:
            yaml.dump(data_yaml, f, default_flow_style=False)

        print(f"Конфігураційний файл YAML створено: {output_path}")

    def preprocess_image(self, image_path, target_size=(640, 640)):
        """
        Попередня обробка зображення.

        Параметри:
        -----------
        image_path : str
            Шлях до зображення
        target_size : tuple
            Цільовий розмір зображення (висота, ширина)

        Повертає:
        -----------
        numpy.ndarray : Оброблене зображення
        """
        # Завантаження зображення
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"Не вдалося завантажити зображення: {image_path}")

        # Конвертація з BGR у RGB
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # Зміна розміру зображення
        image = cv2.resize(image, target_size)

        # Нормалізація пікселів до діапазону [0, 1]
        image = image.astype(np.float32) / 255.0

        return image

    def augment_image(self, image, bboxes, class_labels):
        """
        Аугментація зображення та обмежувальних рамок.

        Параметри:
        -----------
        image : numpy.ndarray
            Зображення для аугментації
        bboxes : list
            Список обмежувальних рамок у форматі [x_min, y_min, x_max, y_max]
        class_labels : list
            Список міток класів для кожної рамки

        Повертає:
        -----------
        tuple : (Аугментоване зображення, нові обмежувальні рамки, нові мітки класів)
        """
        # Визначення аугментацій
        transform = A.Compose([
            A.RandomBrightnessContrast(p=0.5),
            A.HueSaturationValue(p=0.3),
            A.RandomGamma(p=0.2),
            A.CLAHE(p=0.2),
            A.HorizontalFlip(p=0.5),
            A.Rotate(limit=10, p=0.3),
            A.RandomScale(scale_limit=0.1, p=0.3),
            A.Cutout(num_holes=8, max_h_size=8, max_w_size=8, fill_value=0, p=0.3),
        ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))

        # Застосування аугментацій
        augmented = transform(image=image, bboxes=bboxes, class_labels=class_labels)

        return augmented['image'], augmented['bboxes'], augmented['class_labels']

    def visualize_samples(self, sample_count=5, dataset_type='train'):
        """
        Візуалізація випадкових зразків із набору даних.

        Параметри:
        -----------
        sample_count : int
            Кількість зразків для візуалізації
        dataset_type : str
            Тип набору даних ('train', 'valid', або 'test')
        """
        # Вибір відповідної директорії
        if dataset_type == 'train':
            dataset_path = self.train_path
        elif dataset_type == 'valid':
            dataset_path = self.valid_path
        elif dataset_type == 'test':
            dataset_path = self.test_path
        else:
            raise ValueError(f"Невідомий тип набору даних: {dataset_type}")

        # Отримання списку файлів зображень
        image_files = [f for f in os.listdir(dataset_path) if f.endswith('.jpg')]

        if len(image_files) < sample_count:
            sample_count = len(image_files)
            print(f"Недостатньо зображень, відображення всіх {sample_count} зображень")

        # Вибір випадкових зразків
        random.shuffle(image_files)

        # Відображення зразків
        plt.figure(figsize=(15, 5 * sample_count))

        for i, image_file in enumerate(image_files[:sample_count]):
            # Завантаження зображення
            image_path = os.path.join(dataset_path, image_file)
            image = cv2.imread(image_path)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

            # Завантаження анотації
            annotation_path = image_path.replace('.jpg', '.txt')
            height, width = image.shape[:2]

            plt.subplot(sample_count, 1, i + 1)
            plt.imshow(image)

            if os.path.exists(annotation_path):
                with open(annotation_path, 'r') as f:
                    lines = f.readlines()

                for line in lines:
                    values = line.strip().split()
                    class_id = int(values[0])
                    x_center = float(values[1]) * width
                    y_center = float(values[2]) * height
                    box_width = float(values[3]) * width
                    box_height = float(values[4]) * height

                    x_min = x_center - box_width / 2
                    y_min = y_center - box_height / 2

                    class_name = self.class_map.get(class_id, f"Клас {class_id}")

                    # Додавання обмежувальної рамки
                    rect = plt.Rectangle((x_min, y_min), box_width, box_height,
                                         fill=False, edgecolor='red', linewidth=2)
                    plt.gca().add_patch(rect)

                    # Додавання мітки класу
                    plt.text(x_min, y_min - 5, class_name,
                             bbox=dict(facecolor='red', alpha=0.5),
                             fontsize=8, color='white')

            plt.title(f"{dataset_type.capitalize()}: {image_file}")
            plt.axis('off')

        plt.tight_layout()
        plt.show()

    def process_dataset(self, dataset_id='dasmehdixtr/drone-dataset-uav',
                        annotation_dir='drone_dataset_yolo/dataset_txt',
                        train_ratio=0.7, valid_ratio=0.2, test_ratio=0.1):
        """
        Повний процес обробки набору даних від завантаження до підготовки.

        Параметри:
        -----------
        dataset_id : str
            Ідентифікатор набору даних на Kaggle
        annotation_dir : str
            Директорія з анотаціями в розпакованому наборі даних
        train_ratio : float
            Частка даних для тренування
        valid_ratio : float
            Частка даних для валідації
        test_ratio : float
            Частка даних для тестування
        """
        # Завантаження набору даних
        dataset_path = self.download_dataset(dataset_id)

        # Пошук анотацій
        annotation_paths = self.find_annotations(os.path.join(dataset_path, annotation_dir))

        # Розбиття набору даних
        split_info = self.split_dataset(annotation_paths, train_ratio, valid_ratio, test_ratio)

        # Копіювання файлів у відповідні директорії
        self.copy_files_to_folders(annotation_paths, split_info)

        # Створення конфігураційного файлу YAML
        self.create_yaml_config()

        # Візуалізація зразків
        self.visualize_samples(sample_count=3, dataset_type='train')

        return {
            'dataset_path': dataset_path,
            'annotation_paths': annotation_paths,
            'split_info': split_info,
            'yaml_config': 'data.yaml'
        }


# Приклад використання:
# data_processor = DataProcessor()
# results = data_processor.process_dataset()
# print("Підготовка даних завершена успішно!")

# Модуль 2: Виявлення дронів

import os
import cv2
import numpy as np
import torch
import matplotlib.pyplot as plt
from tqdm import tqdm
from PIL import Image
import yaml
from ultralytics import YOLO
import time
from pathlib import Path

class DroneDetector:
   """
   Клас для виявлення дронів на зображеннях та відео за допомогою YOLOv8.
   """

   def __init__(self, config_path='data.yaml', model_size='m'):
       """
       Ініціалізація детектора дронів.

       Параметри:
       -----------
       config_path : str
           Шлях до конфігураційного файлу YAML
       model_size : str
           Розмір моделі YOLOv8 ('n', 's', 'm', 'l', 'x')
       """
       self.config_path = config_path
       self.model_size = model_size
       self.device = "cuda" if torch.cuda.is_available() else "cpu"
       self.model = None
       self.class_names = None

       # Завантаження конфігурації
       self._load_config()

       # Шляхи для зберігання результатів
       self.results_dir = Path("results")
       self.model_dir = self.results_dir / "weights"
       self.output_dir = self.results_dir / "output"

       # Створення директорій
       self.results_dir.mkdir(exist_ok=True)
       self.model_dir.mkdir(exist_ok=True)
       self.output_dir.mkdir(exist_ok=True)

   def _load_config(self):
       """
       Завантаження конфігурації з YAML-файлу.
       """
       if not os.path.exists(self.config_path):
           raise FileNotFoundError(f"Файл конфігурації не знайдено: {self.config_path}")

       with open(self.config_path, 'r') as f:
           self.config = yaml.safe_load(f)

       self.class_names = self.config.get('names', ['drone'])
       print(f"Завантажено конфігурацію з {self.config_path}")
       print(f"Класи об'єктів: {self.class_names}")

   def _get_pretrained_model(self):
       """
       Отримання попередньо навченої моделі YOLOv8.

       Повертає:
       -----------
       YOLO : попередньо навчена модель
       """
       model_name = f"yolov8{self.model_size}.pt"
       print(f"Завантаження попередньо навченої моделі: {model_name}")

       # Перевірка, чи модель вже завантажена
       if self.model is not None and self.model.model.name == model_name:
           return self.model

       # Завантаження моделі
       model = YOLO(model_name)
       return model

   def train(self, epochs=50, imgsz=640, batch_size=16, patience=15,
             save_period=5, pretrained=True, optimizer='SGD',
             lr0=0.01, device=None, workers=4):
       """
       Навчання моделі YOLOv8 для виявлення дронів.

       Параметри:
       -----------
       epochs : int
           Кількість епох навчання
       imgsz : int
           Розмір вхідних зображень
       batch_size : int
           Розмір пакету для навчання
       patience : int
           Параметр раннього зупинення (скільки епох без покращення)
       save_period : int
           Період збереження проміжних моделей (кожні N епох)
       pretrained : bool
           Використовувати попередньо навчені ваги
       optimizer : str
           Оптимізатор ('SGD', 'Adam', 'AdamW')
       lr0 : float
           Початкова швидкість навчання
       device : str
           Пристрій для навчання ('cpu', 'cuda', '0', '0,1', etc.)
       workers : int
           Кількість робочих процесів для завантаження даних

       Повертає:
       -----------
       str : Шлях до найкращої моделі
       """
       if device is None:
           device = self.device

       print(f"Початок навчання моделі на пристрої: {device}")

       # Отримання попередньо навченої моделі
       if pretrained:
           model = self._get_pretrained_model()
       else:
           model = YOLO(f"yolov8{self.model_size}.yaml")

       # Налаштування параметрів навчання
       hyper_params = {
           'data': self.config_path,
           'epochs': epochs,
           'imgsz': imgsz,
           'batch': batch_size,
           'patience': patience,
           'save_period': save_period,
           'device': device,
           'optimizer': optimizer,
           'lr0': lr0,
           'workers': workers,
           'name': f'yolov8_{self.model_size}_drone',
           'project': str(self.results_dir)
       }

       print(f"Параметри навчання: {hyper_params}")

       # Навчання моделі
       results = model.train(**hyper_params)

       # Збереження навченої моделі
       best_model_path = self.results_dir / f'yolov8_{self.model_size}_drone' / 'weights' / 'best.pt'
       self.model = YOLO(best_model_path)
       print(f"Найкраща модель збережена у: {best_model_path}")

       # Повернення шляху до найкращої моделі
       return str(best_model_path)

   def load_model(self, model_path=None):
       """
       Завантаження навченої моделі.

       Параметри:
       -----------
       model_path : str
           Шлях до файлу моделі. Якщо None, спробує знайти найкращу модель.

       Повертає:
       -----------
       bool : True, якщо модель успішно завантажена
       """
       # Якщо шлях не вказано, шукаємо найкращу модель
       if model_path is None:
           possible_paths = [
               self.model_dir / 'best.pt',
               self.results_dir / f'yolov8_{self.model_size}_drone' / 'weights' / 'best.pt'
           ]

           for path in possible_paths:
               if path.exists():
                   model_path = str(path)
                   break

           if model_path is None:
               print("Навчену модель не знайдено. Використовуємо попередньо навчену модель.")
               self.model = self._get_pretrained_model()
               return False

       # Завантаження моделі
       print(f"Завантаження моделі з: {model_path}")
       try:
           self.model = YOLO(model_path)
           print(f"Модель успішно завантажена.")
           return True
       except Exception as e:
           print(f"Помилка при завантаженні моделі: {e}")
           print("Використовуємо попередньо навчену модель.")
           self.model = self._get_pretrained_model()
           return False

   def detect(self, source, conf=0.25, iou=0.45, device=None, save=True,
              show=False, save_txt=False, classes=None, max_det=300):
       """
       Виявлення дронів на зображеннях або відео.

       Параметри:
       -----------
       source : str
           Шлях до зображення, відео, директорії або URL
       conf : float
           Поріг впевненості
       iou : float
           Поріг перетину над об'єднанням (IoU) для NMS
       device : str
           Пристрій для виведення ('cpu', 'cuda', '0', etc.)
       save : bool
           Зберігати результати виявлення
       show : bool
           Показувати результати
       save_txt : bool
           Зберігати результати у текстовому форматі
       classes : list
           Фільтр за класами (None = всі класи)
       max_det : int
           Максимальна кількість виявлень на зображення

       Повертає:
       -----------
       list : Результати виявлення
       """
       if self.model is None:
           self.load_model()

       if device is None:
           device = self.device

       # Налаштування параметрів виявлення
       detect_params = {
           'source': source,
           'conf': conf,
           'iou': iou,
           'device': device,
           'save': save,
           'show': show,
           'save_txt': save_txt,
           'classes': classes,
           'max_det': max_det,
           'project': str(self.output_dir),
           'name': 'detect'
       }

       print(f"Виявлення об'єктів з параметрами: {detect_params}")

       # Запуск виявлення
       start_time = time.time()
       results = self.model.predict(**detect_params)
       detection_time = time.time() - start_time

       print(f"Виявлення завершено за {detection_time:.2f} секунд")

       # Повернення результатів
       return results

   def draw_detections(self, image, detections, thickness=2, font_scale=0.5, color=None):
       """
       Малювання обмежувальних рамок виявлених об'єктів на зображенні.

       Параметри:
       -----------
       image : numpy.ndarray
           Зображення для відображення результатів
       detections : dict
           Інформація про виявлені об'єкти (x1, y1, x2, y2, conf, cls)
       thickness : int
           Товщина ліній обмежувальних рамок
       font_scale : float
           Розмір шрифту для підписів
       color : tuple
           Колір обмежувальних рамок (B, G, R)

       Повертає:
       -----------
       numpy.ndarray : Зображення з намальованими виявленнями
       """
       # Створення копії зображення
       output_image = image.copy()

       # Якщо колір не вказано, використовуємо різні кольори для різних класів
       colors = [
           (0, 255, 0),     # Зелений
           (255, 0, 0),     # Блакитний
           (0, 0, 255),     # Червоний
           (255, 255, 0),   # Синьо-зелений
           (0, 255, 255),   # Жовтий
           (255, 0, 255)    # Пурпурний
       ]

       # Малювання обмежувальних рамок та міток класів
       for det in detections:
           x1, y1, x2, y2, conf, cls_id = det

           # Перетворення в цілі числа
           x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
           cls_id = int(cls_id)

           # Вибір кольору
           if color is None:
               box_color = colors[cls_id % len(colors)]
           else:
               box_color = color

           # Отримання назви класу
           if cls_id < len(self.class_names):
               class_name = self.class_names[cls_id]
           else:
               class_name = f"Клас {cls_id}"

           # Малювання обмежувальної рамки
           cv2.rectangle(output_image, (x1, y1), (x2, y2), box_color, thickness)

           # Формування тексту підпису
           label = f"{class_name} {conf:.2f}"

           # Розрахунок розміру тексту
           (text_width, text_height), baseline = cv2.getTextSize(
               label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)

           # Малювання фону для тексту
           cv2.rectangle(output_image, (x1, y1 - text_height - baseline),
                         (x1 + text_width, y1), box_color, -1)

           # Малювання тексту
           cv2.putText(output_image, label, (x1, y1 - baseline),
                       cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), thickness)

       return output_image

   def visualize_detection_results(self, results, count=5, figsize=(12, 12)):
       """
       Візуалізація результатів виявлення.

       Параметри:
       -----------
       results : list
           Результати виявлення, отримані від методу detect
       count : int
           Кількість зображень для відображення
       figsize : tuple
           Розмір фігури для відображення
       """
       if len(results) == 0:
           print("Немає результатів для візуалізації.")
           return

       # Обмеження кількості зображень
       n_images = min(count, len(results))

       # Створення фігури для відображення
       fig, axes = plt.subplots(n_images, 1, figsize=figsize)

       # Якщо n_images = 1, axes буде об'єктом, а не масивом
       if n_images == 1:
           axes = [axes]

       # Відображення результатів для кожного зображення
       for i, (result, ax) in enumerate(zip(results[:n_images], axes)):
           # Отримання зображення з результатом
           img = result.plot(conf=True, line_width=2, font_size=12)
           img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

           # Відображення зображення
           ax.imshow(img)
           ax.set_title(f"Результат виявлення #{i+1}")
           ax.axis("off")

       plt.tight_layout()
       plt.show()

   def process_video(self, video_path, output_path=None, conf=0.25, iou=0.45,
                     skip_frames=0, max_frames=None, show_progress=True,
                     show_fps=True, display=False, thickness=2, font_scale=0.5):
       """
       Обробка відео для виявлення дронів.

       Параметри:
       -----------
       video_path : str
           Шлях до відеофайлу
       output_path : str
           Шлях для збереження результату (якщо None, відео не зберігається)
       conf : float
           Поріг впевненості
       iou : float
           Поріг перетину над об'єднанням (IoU) для NMS
       skip_frames : int
           Кількість кадрів для пропуску між обробленими кадрами
       max_frames : int
           Максимальна кількість кадрів для обробки (None = всі кадри)
       show_progress : bool
           Показувати прогрес обробки
       show_fps : bool
           Показувати FPS на вихідному відео
       display : bool
           Показувати відео в реальному часі
       thickness : int
           Товщина ліній обмежувальних рамок
       font_scale : float
           Розмір шрифту для підписів

       Повертає:
       -----------
       str : Шлях до обробленого відео (якщо було збереження)
       """
       if self.model is None:
           self.load_model()

       # Відкриття відеофайлу
       cap = cv2.VideoCapture(video_path)

       # Перевірка, чи відеофайл відкрито успішно
       if not cap.isOpened():
           raise ValueError(f"Не вдалося відкрити відеофайл: {video_path}")

       # Отримання параметрів відео
       fps = cap.get(cv2.CAP_PROP_FPS)
       total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
       width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
       height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

       # Якщо max_frames не вказано, обробляємо все відео
       if max_frames is None:
           max_frames = total_frames
       else:
           max_frames = min(max_frames, total_frames)

       # Створення відеописувача для вихідного файлу
       if output_path is not None:
           fourcc = cv2.VideoWriter_fourcc(*'mp4v')
           out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

       # Ініціалізація змінних для відображення FPS
       frame_count = 0
       total_fps = 0
       avg_fps = 0

       # Прогрес-бар
       if show_progress:
           progress_bar = tqdm(total=max_frames, desc="Обробка відео")

       print(f"Початок обробки відео: {video_path}")
       print(f"Параметри відео: {width}x{height}, {fps} FPS, {total_frames} кадрів")

       # Цикл обробки відео
       while cap.isOpened() and frame_count < max_frames:
           # Зчитування кадру
           ret, frame = cap.read()

           # Перевірка, чи кадр зчитано успішно
           if not ret:
               break

           # Пропуск кадрів, якщо потрібно
           if skip_frames > 0 and frame_count % (skip_frames + 1) != 0:
               frame_count += 1
               if show_progress:
                   progress_bar.update(1)
               continue

           # Вимірювання часу обробки
           start_time = time.time()

           # Виявлення об'єктів на кадрі
           results = self.model(frame, conf=conf, iou=iou, classes=None, device=self.device)

           # Обчислення FPS
           process_time = time.time() - start_time
           fps_current = 1 / process_time if process_time > 0 else 0
           total_fps += fps_current
           avg_fps = total_fps / (frame_count + 1)

           # Отримання результатів виявлення
           detections = []
           if len(results) > 0:
               boxes = results[0].boxes
               for box in boxes:
                   x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                   conf = box.conf[0].cpu().numpy()
                   cls = box.cls[0].cpu().numpy()
                   detections.append([x1, y1, x2, y2, conf, cls])

           # Малювання результатів на кадрі
           output_frame = self.draw_detections(frame, detections, thickness, font_scale)

           # Додавання інформації про FPS
           if show_fps:
               fps_text = f"FPS: {fps_current:.1f} (Сер.: {avg_fps:.1f})"
               cv2.putText(output_frame, fps_text, (10, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

           # Запис кадру у вихідний файл
           if output_path is not None:
               out.write(output_frame)

           # Відображення кадру в реальному часі
           if display:
               cv2.imshow("Виявлення дронів", output_frame)

               # Вихід при натисканні клавіші 'q'
               if cv2.waitKey(1) & 0xFF == ord('q'):
                   break

           # Оновлення лічильника кадрів та прогрес-бару
           frame_count += 1
           if show_progress:
               progress_bar.update(1)

       # Завершення обробки
       cap.release()
       if output_path is not None:
           out.release()
       if display:
           cv2.destroyAllWindows()
       if show_progress:
           progress_bar.close()

       print(f"Обробка відео завершена. Оброблено {frame_count} кадрів.")
       print(f"Середній FPS: {avg_fps:.2f}")

       if output_path is not None:
           print(f"Результат збережено у: {output_path}")
           return output_path

       return None

   def evaluate(self, test_data=None, conf=0.25, iou=0.45, device=None, verbose=True):
       """
       Оцінка ефективності моделі на тестових даних.

       Параметри:
       -----------
       test_data : str
           Шлях до тестових даних (якщо None, використовується test з конфігурації)
       conf : float
           Поріг впевненості
       iou : float
           Поріг перетину над об'єднанням (IoU) для NMS
       device : str
           Пристрій для виведення ('cpu', 'cuda', '0', etc.)
       verbose : bool
           Виводити детальну інформацію

       Повертає:
       -----------
       dict : Метрики ефективності
       """
       if self.model is None:
           self.load_model()

       if device is None:
           device = self.device

       # Якщо test_data не вказано, використовуємо test з конфігурації
       if test_data is None:
           test_data = self.config.get('test', None)
           if test_data is None:
               raise ValueError("Не вказано тестові дані і не знайдено у конфігурації")

       # Налаштування параметрів валідації
       val_params = {
           'data': test_data,
           'conf': conf,
           'iou': iou,
           'device': device,
           'verbose': verbose,
           'split': 'test'
       }

       print(f"Оцінка моделі на {test_data} з параметрами: {val_params}")

       # Запуск валідації
       start_time = time.time()
       results = self.model.val(**val_params)
       eval_time = time.time() - start_time

       print(f"Оцінка завершена за {eval_time:.2f} секунд")

       # Формування звіту з метриками
       metrics = {
           'precision': results.results_dict.get('metrics/precision(B)', 0.0),
           'recall': results.results_dict.get('metrics/recall(B)', 0.0),
           'mAP50': results.results_dict.get('metrics/mAP50(B)', 0.0),
           'mAP50-95': results.results_dict.get('metrics/mAP50-95(B)', 0.0),
           'f1': results.results_dict.get('metrics/F1(B)', 0.0)
       }

       print(f"Метрики ефективності:")
       print(f"  Precision: {metrics['precision']:.4f}")
       print(f"  Recall:    {metrics['recall']:.4f}")
       print(f"  mAP50:     {metrics['mAP50']:.4f}")
       print(f"  mAP50-95:  {metrics['mAP50-95']:.4f}")
       print(f"  F1-score:  {metrics['f1']:.4f}")

       return metrics


# Приклад використання:
# detector = DroneDetector()
#
# # Навчання моделі
# model_path = detector.train(epochs=30, imgsz=640)
#
# # Завантаження моделі
# detector.load_model(model_path)
#
# # Виявлення дронів на зображенні
# results = detector.detect('datasets/test/image.jpg', conf=0.25)
#
# # Візуалізація результатів
# detector.visualize_detection_results(results)
#
# # Обробка відео
# detector.process_video('test_video.mp4', 'output_video.mp4', display=True)
#
# # Оцінка ефективності
# metrics = detector.evaluate()

# Модуль 3: Відстеження дронів (трекінг)

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import time
from collections import deque
from scipy.optimize import linear_sum_assignment
from filterpy.kalman import KalmanFilter
import matplotlib.patches as patches
import matplotlib.lines as mlines
import uuid
from pathlib import Path
import json

class DroneTracker:
   """
   Клас для відстеження дронів між кадрами відео.
   """

   def __init__(self, max_age=30, min_hits=3, iou_threshold=0.3,
                max_distance=100, kalman_process_noise=0.03,
                kalman_measurement_noise=0.1, smooth_factor=0.6):
       """
       Ініціалізація трекера дронів.

       Параметри:
       -----------
       max_age : int
           Максимальна кількість кадрів, протягом яких трек може бути відсутнім
       min_hits : int
           Мінімальна кількість послідовних кадрів з виявленням для підтвердження треку
       iou_threshold : float
           Поріг IoU для асоціації виявлень з треками
       max_distance : float
           Максимальна дистанція (в пікселях) для асоціації виявлень
       kalman_process_noise : float
           Рівень шуму процесу для фільтра Калмана
       kalman_measurement_noise : float
           Рівень шуму вимірювань для фільтра Калмана
       smooth_factor : float
           Коефіцієнт згладжування для фільтрації тремтіння (0-1)
       """
       self.max_age = max_age
       self.min_hits = min_hits
       self.iou_threshold = iou_threshold
       self.max_distance = max_distance
       self.kalman_process_noise = kalman_process_noise
       self.kalman_measurement_noise = kalman_measurement_noise
       self.smooth_factor = smooth_factor

       self.tracks = []
       self.track_id_count = 0

       # Шлях для зберігання результатів відстеження
       self.results_dir = Path("tracking_results")
       self.results_dir.mkdir(exist_ok=True)

   def _calculate_iou(self, box1, box2):
       """
       Розрахунок IoU (Intersection over Union) між двома обмежувальними рамками.

       Параметри:
       -----------
       box1, box2 : tuple
           Обмежувальні рамки у форматі (x1, y1, x2, y2)

       Повертає:
       -----------
       float : значення IoU
       """
       # Розпакування координат
       x1_1, y1_1, x2_1, y2_1 = box1
       x1_2, y1_2, x2_2, y2_2 = box2

       # Розрахунок координат перетину
       x1_i = max(x1_1, x1_2)
       y1_i = max(y1_1, y1_2)
       x2_i = min(x2_1, x2_2)
       y2_i = min(y2_1, y2_2)

       # Розрахунок площі перетину
       if x2_i < x1_i or y2_i < y1_i:
           # Немає перетину
           return 0.0

       intersection_area = (x2_i - x1_i) * (y2_i - y1_i)

       # Розрахунок площ обох обмежувальних рамок
       box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)
       box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)

       # Розрахунок IoU
       iou = intersection_area / float(box1_area + box2_area - intersection_area)

       return iou

   def _calculate_distance(self, centroid1, centroid2):
       """
       Розрахунок евклідової відстані між двома центроїдами.

       Параметри:
       -----------
       centroid1, centroid2 : tuple
           Координати центроїдів у форматі (x, y)

       Повертає:
       -----------
       float : відстань
       """
       return np.sqrt((centroid1[0] - centroid2[0])**2 +
                      (centroid1[1] - centroid2[1])**2)

   def _get_centroid(self, box):
       """
       Отримання центроїда обмежувальної рамки.

       Параметри:
       -----------
       box : tuple
           Обмежувальна рамка у форматі (x1, y1, x2, y2)

       Повертає:
       -----------
       tuple : координати центроїда (x, y)
       """
       x1, y1, x2, y2 = box
       return ((x1 + x2) / 2, (y1 + y2) / 2)

   def _init_kalman_filter(self):
       """
       Ініціалізація фільтра Калмана для відстеження об'єкта.

       Повертає:
       -----------
       KalmanFilter : ініціалізований фільтр Калмана
       """
       kf = KalmanFilter(dim_x=6, dim_z=4)  # Стан: [x, y, width, height, vx, vy], Вимірювання: [x, y, width, height]

       # Матриця переходу
       kf.F = np.array([
           [1, 0, 0, 0, 1, 0],  # x = x + vx
           [0, 1, 0, 0, 0, 1],  # y = y + vy
           [0, 0, 1, 0, 0, 0],  # width = width
           [0, 0, 0, 1, 0, 0],  # height = height
           [0, 0, 0, 0, 1, 0],  # vx = vx
           [0, 0, 0, 0, 0, 1]   # vy = vy
       ])

       # Матриця вимірювання
       kf.H = np.array([
           [1, 0, 0, 0, 0, 0],  # вимірюємо x
           [0, 1, 0, 0, 0, 0],  # вимірюємо y
           [0, 0, 1, 0, 0, 0],  # вимірюємо width
           [0, 0, 0, 1, 0, 0]   # вимірюємо height
       ])

       # Коваріаційна матриця помилки процесу
       q = self.kalman_process_noise
       kf.Q = np.array([
           [q, 0, 0, 0, 0, 0],
           [0, q, 0, 0, 0, 0],
           [0, 0, q, 0, 0, 0],
           [0, 0, 0, q, 0, 0],
           [0, 0, 0, 0, q, 0],
           [0, 0, 0, 0, 0, q]
       ])

       # Коваріаційна матриця помилки вимірювання
       r = self.kalman_measurement_noise
       kf.R = np.array([
           [r, 0, 0, 0],
           [0, r, 0, 0],
           [0, 0, r, 0],
           [0, 0, 0, r]
       ])

       # Початкова коваріаційна матриця помилки оцінки
       kf.P *= 10

       return kf

   class Track:
       """
       Клас для представлення одного треку (відстежуваного об'єкта).
       """
       def __init__(self, box, confidence, class_id, track_id, kalman_filter, smooth_factor=0.6):
           """
           Ініціалізація треку.

           Параметри:
           -----------
           box : tuple
               Обмежувальна рамка у форматі (x1, y1, x2, y2)
           confidence : float
               Рівень впевненості виявлення
           class_id : int
               Ідентифікатор класу об'єкта
           track_id : int
               Ідентифікатор треку
           kalman_filter : KalmanFilter
               Фільтр Калмана для відстеження
           smooth_factor : float
               Коефіцієнт згладжування для фільтрації тремтіння
           """
           self.track_id = track_id
           self.confidence = confidence
           self.class_id = class_id
           self.hits = 1
           self.age = 0
           self.time_since_update = 0
           self.max_confidence = confidence

           # Історія позицій
           self.history = deque(maxlen=50)

           # Фільтр Калмана
           self.kf = kalman_filter

           # Ініціалізація стану фільтра Калмана
           x1, y1, x2, y2 = box
           width = x2 - x1
           height = y2 - y1
           centroid = ((x1 + x2) / 2, (y1 + y2) / 2)

           self.kf.x = np.array([centroid[0], centroid[1], width, height, 0, 0])

           # Згладжені значення для фільтрації тремтіння
           self.smooth_box = box
           self.smooth_factor = smooth_factor

           # Поточний стан
           self.state = "tentative"  # tentative, confirmed, deleted

       def predict(self):
           """
           Прогноз наступного положення об'єкта за допомогою фільтра Калмана.

           Повертає:
           -----------
           tuple : прогнозована обмежувальна рамка (x1, y1, x2, y2)
           """
           self.kf.predict()

           # Отримання прогнозованого стану
           predicted_state = self.kf.x

           # Перетворення стану у формат обмежувальної рамки
           centroid_x = predicted_state[0]
           centroid_y = predicted_state[1]
           width = predicted_state[2] if predicted_state[2] > 0 else 1
           height = predicted_state[3] if predicted_state[3] > 0 else 1

           x1 = centroid_x - width / 2
           y1 = centroid_y - height / 2
           x2 = centroid_x + width / 2
           y2 = centroid_y + height / 2

           return (x1, y1, x2, y2)

       def update(self, box, confidence, class_id):
           """
           Оновлення треку новим виявленням.

           Параметри:
           -----------
           box : tuple
               Обмежувальна рамка у форматі (x1, y1, x2, y2)
           confidence : float
               Рівень впевненості виявлення
           class_id : int
               Ідентифікатор класу об'єкта
           """
           # Оновлення статистики треку
           self.hits += 1
           self.time_since_update = 0
           self.confidence = confidence
           if confidence > self.max_confidence:
               self.max_confidence = confidence

           # Оновлення класу об'єкта (беремо клас з найвищою впевненістю)
           if confidence > self.confidence:
               self.class_id = class_id

           # Перетворення обмежувальної рамки у формат вимірювання для фільтра Калмана
           x1, y1, x2, y2 = box
           width = x2 - x1
           height = y2 - y1
           centroid = ((x1 + x2) / 2, (y1 + y2) / 2)

           # Вимірювання для фільтра Калмана
           measurement = np.array([centroid[0], centroid[1], width, height])

           # Оновлення фільтра Калмана
           self.kf.update(measurement)

           # Отримання оновленого стану
           updated_state = self.kf.x

           # Перетворення стану у формат обмежувальної рамки
           centroid_x = updated_state[0]
           centroid_y = updated_state[1]
           width = updated_state[2] if updated_state[2] > 0 else 1
           height = updated_state[3] if updated_state[3] > 0 else 1

           x1_kf = centroid_x - width / 2
           y1_kf = centroid_y - height / 2
           x2_kf = centroid_x + width / 2
           y2_kf = centroid_y + height / 2

           kalman_box = (x1_kf, y1_kf, x2_kf, y2_kf)

           # Згладжування для зменшення тремтіння
           smooth_box = (
               self.smooth_factor * self.smooth_box[0] + (1 - self.smooth_factor) * kalman_box[0],
               self.smooth_factor * self.smooth_box[1] + (1 - self.smooth_factor) * kalman_box[1],
               self.smooth_factor * self.smooth_box[2] + (1 - self.smooth_factor) * kalman_box[2],
               self.smooth_factor * self.smooth_box[3] + (1 - self.smooth_factor) * kalman_box[3]
           )

           self.smooth_box = smooth_box

           # Додавання поточного положення до історії
           self.history.append(self.get_centroid())

           # Оновлення стану треку
           if self.state == "tentative" and self.hits >= 3:
               self.state = "confirmed"

       def get_box(self):
           """
           Отримання поточної обмежувальної рамки об'єкта.

           Повертає:
           -----------
           tuple : обмежувальна рамка (x1, y1, x2, y2)
           """
           return self.smooth_box

       def get_centroid(self):
           """
           Отримання центроїда поточної обмежувальної рамки.

           Повертає:
           -----------
           tuple : координати центроїда (x, y)
           """
           x1, y1, x2, y2 = self.smooth_box
           return ((x1 + x2) / 2, (y1 + y2) / 2)

   def update(self, detections, frame=None):
       """
       Оновлення трекера новими виявленнями.

       Параметри:
       -----------
       detections : list
           Список виявлень у форматі [[x1, y1, x2, y2, conf, class_id], ...]
       frame : numpy.ndarray, опціонально
           Поточний кадр для візуалізації

       Повертає:
       -----------
       list : Список активних треків у форматі
              [[x1, y1, x2, y2, track_id, conf, class_id, state], ...]
       """
       # Перетворення detections у внутрішній формат, якщо потрібно
       formatted_detections = []
       for det in detections:
           if len(det) >= 6:  # Формат [x1, y1, x2, y2, conf, class_id]
               formatted_detections.append({
                   'box': (det[0], det[1], det[2], det[3]),
                   'confidence': det[4],
                   'class_id': int(det[5])
               })

       # Прогноз положення існуючих треків
       predicted_tracks = []
       for track in self.tracks:
           predicted_box = track.predict()
           predicted_tracks.append({
               'box': predicted_box,
               'track': track
           })

       # Матриця вартості для асоціації виявлень з треками
       cost_matrix = np.zeros((len(formatted_detections), len(predicted_tracks)))

       # Заповнення матриці вартості
       for i, detection in enumerate(formatted_detections):
           for j, track_info in enumerate(predicted_tracks):
               det_box = detection['box']
               track_box = track_info['box']
               track = track_info['track']

               # Розрахунок IoU
               iou = self._calculate_iou(det_box, track_box)
               if iou > 0:
                   # Використання IoU як міри схожості (більший IoU -> менша вартість)
                   cost_matrix[i, j] = 1 - iou
               else:
                   # Якщо IoU = 0, перевіряємо відстань між центроїдами
                   det_centroid = self._get_centroid(det_box)
                   track_centroid = track.get_centroid()
                   distance = self._calculate_distance(det_centroid, track_centroid)

                   if distance < self.max_distance:
                       # Нормалізація відстані до [0, 1] для сумісності з IoU
                       cost_matrix[i, j] = distance / self.max_distance + 1  # +1 щоб було більше за (1 - IoU)
                   else:
                       # Якщо відстань занадто велика, встановлюємо максимальну вартість
                       cost_matrix[i, j] = float('inf')

       # Вирішення задачі призначення за допомогою Угорського алгоритму
       matched_indices = []

       if len(cost_matrix) > 0:
           # Використання Угорського алгоритму для мінімізації вартості призначення
           row_indices, col_indices = linear_sum_assignment(cost_matrix)

           # Фільтрація призначень за порогом вартості
           for row, col in zip(row_indices, col_indices):
               if cost_matrix[row, col] < float('inf'):
                   if cost_matrix[row, col] <= 1:  # Якщо вартість від IoU (<=1)
                       if 1 - cost_matrix[row, col] >= self.iou_threshold:
                           matched_indices.append((row, col))
                   else:  # Якщо вартість від відстані (>1)
                       matched_indices.append((row, col))

       # Отримання індексів неспівставлених виявлень та треків
       unmatched_detections = [i for i in range(len(formatted_detections))
                              if i not in [match[0] for match in matched_indices]]
       unmatched_tracks = [i for i in range(len(predicted_tracks))
                          if i not in [match[1] for match in matched_indices]]

       # Оновлення співставлених треків
       for det_idx, track_idx in matched_indices:
           detection = formatted_detections[det_idx]
           track = predicted_tracks[track_idx]['track']

           # Оновлення треку новим виявленням
           track.update(detection['box'], detection['confidence'], detection['class_id'])

       # Створення нових треків для неспівставлених виявлень
       for det_idx in unmatched_detections:
           detection = formatted_detections[det_idx]

           # Створення нового фільтра Калмана
           kf = self._init_kalman_filter()

           # Створення нового треку
           new_track = self.Track(detection['box'], detection['confidence'],
                                 detection['class_id'], self.track_id_count,
                                 kf, self.smooth_factor)

           # Додавання нового треку до списку треків
           self.tracks.append(new_track)
           self.track_id_count += 1

       # Оновлення неспівставлених треків
       for track_idx in unmatched_tracks:
           track = predicted_tracks[track_idx]['track']
           track.time_since_update += 1

       # Фільтрація треків
       active_tracks = []
       remaining_tracks = []

       for track in self.tracks:
           track.age += 1

           # Перевірка, чи трек все ще активний
           if track.time_since_update > self.max_age:
               track.state = "deleted"
           else:
               # Додавання треку до списку активних треків
               box = track.get_box()
               active_tracks.append([
                   box[0], box[1], box[2], box[3],
                   track.track_id, track.confidence, track.class_id, track.state
               ])

               # Додавання треку до списку треків для наступного кадру
               remaining_tracks.append(track)

       # Оновлення списку треків
       self.tracks = remaining_tracks

       # Візуалізація результатів відстеження, якщо передано кадр
       if frame is not None:
           frame_with_tracks = self.visualize_tracks(frame, active_tracks)
           return active_tracks, frame_with_tracks

       return active_tracks

   def visualize_tracks(self, frame, tracks, thickness=2, font_scale=0.5,
                        show_history=True, history_length=20, class_names=None):
       """
       Візуалізація треків на кадрі.

       Параметри:
       -----------
       frame : numpy.ndarray
           Кадр для візуалізації
       tracks : list
           Список активних треків у форматі
           [[x1, y1, x2, y2, track_id, conf, class_id, state], ...]
       thickness : int
           Товщина ліній обмежувальних рамок
       font_scale : float
           Розмір шрифту для підписів
       show_history : bool
           Показувати історію руху об'єктів
       history_length : int
           Довжина історії для відображення
       class_names : list, опціонально
           Список назв класів

       Повертає:
       -----------
       numpy.ndarray : Кадр з візуалізованими треками
       """
       # Створення копії кадру
       output_frame = frame.copy()

       # Різні кольори для різних треків
       colors = [
           (0, 255, 0),     # Зелений
           (255, 0, 0),     # Блакитний
           (0, 0, 255),     # Червоний
           (255, 255, 0),   # Синьо-зелений
           (0, 255, 255),   # Жовтий
           (255, 0, 255)    # Пурпурний
       ]

       # Візуалізація треків
       for track in tracks:
           x1, y1, x2, y2, track_id, confidence, class_id, state = track

           # Перетворення в цілі числа
           x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
           track_id = int(track_id)
           class_id = int(class_id)

           # Вибір кольору на основі track_id
           color = colors[track_id % len(colors)]

           # Товщина лінії залежить від стану треку
           line_thickness = thickness
           if state == "tentative":
               line_thickness = 1

           # Малювання обмежувальної рамки
           cv2.rectangle(output_frame, (x1, y1), (x2, y2), color, line_thickness)

           # Отримання назви класу
           if class_names is not None and class_id < len(class_names):
               class_name = class_names[class_id]
           else:
               class_name = f"Клас {class_id}"

           # Формування тексту підпису
           if state == "confirmed":
               label = f"ID: {track_id}, {class_name} {confidence:.2f}"
           else:
               label = f"(?) ID: {track_id}, {class_name} {confidence:.2f}"

           # Розрахунок розміру тексту
           (text_width, text_height), baseline = cv2.getTextSize(
               label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)

           # Малювання фону для тексту
           cv2.rectangle(output_frame, (x1, y1 - text_height - baseline),
                         (x1 + text_width, y1), color, -1)

           # Малювання тексту
           cv2.putText(output_frame, label, (x1, y1 - baseline),
                       cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), thickness)

           # Візуалізація історії руху
           if show_history and state == "confirmed":
               # Знаходження треку за ID
               track_obj = None
               for t in self.tracks:
                   if t.track_id == track_id:
                       track_obj = t
                       break

               if track_obj is not None and len(track_obj.history) > 1:
                   # Отримання історії центроїдів
                   history = list(track_obj.history)

                   # Обмеження довжини історії
                   if history_length > 0:
                       history = history[-history_length:]

                   # Малювання траєкторії
                   for i in range(1, len(history)):
                       # Інтенсивність кольору залежить від часу (давніші = прозоріші)
                       alpha = i / len(history)
                       point_color = (int(color[0] * alpha), int(color[1] * alpha), int(color[2] * alpha))

                       # Координати точок
                       pt1 = (int(history[i-1][0]), int(history[i-1][1]))
                       pt2 = (int(history[i][0]), int(history[i][1]))

                       # Малювання лінії між точками
                       cv2.line(output_frame, pt1, pt2, point_color, 1)

       return output_frame

   def process_video(self, video_path, output_path=None, detector=None,
                     conf_threshold=0.25, iou_threshold=0.45,
                     skip_frames=0, max_frames=None, show_progress=True,
                     display=False, display_scale=1.0, class_names=None):
       """
       Обробка відео для відстеження дронів.

       Параметри:
       -----------
       video_path : str
           Шлях до відеофайлу
       output_path : str
           Шлях для збереження результату (якщо None, відео не зберігається)
       detector : object, опціонально
           Об'єкт детектора дронів з методом detect
       conf_threshold : float
           Поріг впевненості для виявлення
       iou_threshold : float
           Поріг IoU для NMS
       skip_frames : int
           Кількість кадрів для пропуску між обробленими кадрами
       max_frames : int
           Максимальна кількість кадрів для обробки (None = всі кадри)
       show_progress : bool
           Показувати прогрес обробки
       display : bool
           Показувати відео в реальному часі
       display_scale : float
           Масштаб для відображення в реальному часі
       class_names : list, опціонально
           Список назв класів

       Повертає:
       -----------
       tuple : (шлях до обробленого відео, дані треків)
       """
       # Відкриття відеофайлу
       cap = cv2.VideoCapture(video_path)

       # Перевірка, чи відеофайл відкрито успішно
       if not cap.isOpened():
           raise ValueError(f"Не вдалося відкрити відеофайл: {video_path}")

       # Отримання параметрів відео
       fps = cap.get(cv2.CAP_PROP_FPS)
       total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
       width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
       height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

       # Якщо max_frames не вказано, обробляємо все відео
       if max_frames is None:
           max_frames = total_frames
       else:
           max_frames = min(max_frames, total_frames)

       # Створення відеописувача для вихідного файлу
       if output_path is not None:
           fourcc = cv2.VideoWriter_fourcc(*'mp4v')
           out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

       # Ініціалізація змінних для відстеження
       frame_count = 0
       process_count = 0
       total_processing_time = 0
       tracking_data = []

       # Прогрес-бар
       if show_progress:
           progress_bar = tqdm(total=max_frames, desc="Обробка відео")

       print(f"Початок обробки відео: {video_path}")
       print(f"Параметри відео: {width}x{height}, {fps} FPS, {total_frames} кадрів")

       # Цикл обробки відео
       while cap.isOpened() and frame_count < max_frames:
           # Зчитування кадру
           ret, frame = cap.read()

           # Перевірка, чи кадр зчитано успішно
           if not ret:
               break

           # Пропуск кадрів, якщо потрібно
           if skip_frames > 0 and frame_count % (skip_frames + 1) != 0:
               frame_count += 1
               if show_progress:
                   progress_bar.update(1)
               continue

           # Обробка кадру
           process_count += 1
           frame_processing_start = time.time()

           # Виявлення об'єктів на кадрі, якщо передано детектор
           if detector is not None:
               # Виявлення об'єктів
               detection_results = detector.detect(frame, conf=conf_threshold, iou=iou_threshold)

               # Отримання обмежувальних рамок
               detections = []
               if len(detection_results) > 0:
                   boxes = detection_results[0].boxes
                   for box in boxes:
                       x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                       conf = box.conf[0].cpu().numpy()
                       cls = box.cls[0].cpu().numpy()
                       detections.append([x1, y1, x2, y2, conf, cls])
           else:
               # Якщо детектор не передано, використовуємо порожній список виявлень
               detections = []

           # Відстеження об'єктів
           tracks, frame_with_tracks = self.update(detections, frame)

           # Запис даних треків для поточного кадру
           frame_tracking_data = {
               'frame': frame_count,
               'timestamp': frame_count / fps,
               'tracks': [
                   {
                       'track_id': int(track[4]),
                       'box': [float(track[0]), float(track[1]), float(track[2]), float(track[3])],
                       'confidence': float(track[5]),
                       'class_id': int(track[6]),
                       'state': track[7]
                   }
                   for track in tracks
               ]
           }
           tracking_data.append(frame_tracking_data)

           # Запис кадру у вихідний файл
           if output_path is not None:
               out.write(frame_with_tracks)

           # Відображення кадру в реальному часі
           if display:
               # Зміна розміру кадру для відображення
               if display_scale != 1.0:
                   display_width = int(width * display_scale)
                   display_height = int(height * display_scale)
                   display_frame = cv2.resize(frame_with_tracks, (display_width, display_height))
               else:
                   display_frame = frame_with_tracks

               cv2.imshow("Відстеження дронів", display_frame)

               # Вихід при натисканні клавіші 'q'
               if cv2.waitKey(1) & 0xFF == ord('q'):
                   break

           # Обчислення часу обробки
           frame_processing_time = time.time() - frame_processing_start
           total_processing_time += frame_processing_time

           # Оновлення лічильника кадрів та прогрес-бару
           frame_count += 1
           if show_progress:
               progress_bar.update(1)

       # Завершення обробки
       cap.release()
       if output_path is not None:
           out.release()
       if display:
           cv2.destroyAllWindows()
       if show_progress:
           progress_bar.close()

       # Обчислення середнього часу обробки
       avg_processing_time = total_processing_time / process_count if process_count > 0 else 0
       avg_fps = process_count / total_processing_time if total_processing_time > 0 else 0

       print(f"Обробка відео завершена. Оброблено {process_count} кадрів.")
       print(f"Середній час обробки на кадр: {avg_processing_time:.3f} с")
       print(f"Середній FPS: {avg_fps:.2f}")

       # Збереження даних відстеження у файл JSON
       if tracking_data:
           json_output_path = output_path.replace('.mp4', '_tracking_data.json') if output_path else str(self.results_dir / 'tracking_data.json')
           with open(json_output_path, 'w') as f:
               json.dump({
                   'video': video_path,
                   'fps': fps,
                   'frames': frame_count,
                   'tracking_data': tracking_data
               }, f, indent=2)
           print(f"Дані відстеження збережено у: {json_output_path}")

       if output_path is not None:
           print(f"Результат збережено у: {output_path}")
           return output_path, tracking_data

       return None, tracking_data

   def analyze_trajectories(self, tracking_data, fps, min_track_length=10,
                           output_path=None, class_names=None):
       """
       Аналіз траєкторій руху об'єктів.

       Параметри:
       -----------
       tracking_data : list
           Список словників з даними треків для кожного кадру
       fps : float
           Частота кадрів відео
       min_track_length : int
           Мінімальна довжина треку для аналізу
       output_path : str, опціонально
           Шлях для збереження результатів аналізу
       class_names : list, опціонально
           Список назв класів

       Повертає:
       -----------
       dict : Результати аналізу траєкторій
       """
       print("Аналіз траєкторій руху об'єктів...")

       # Структурування даних за треками
       tracks_by_id = {}
       max_frame = 0

       for frame_data in tracking_data:
           frame_num = frame_data['frame']
           max_frame = max(max_frame, frame_num)

           for track in frame_data['tracks']:
               track_id = track['track_id']

               if track_id not in tracks_by_id:
                   tracks_by_id[track_id] = {
                       'frames': [],
                       'boxes': [],
                       'centroids': [],
                       'timestamps': [],
                       'confidences': [],
                       'class_id': track['class_id'],
                       'state': track['state']
                   }

               # Додавання даних для поточного кадру
               tracks_by_id[track_id]['frames'].append(frame_num)
               tracks_by_id[track_id]['boxes'].append(track['box'])

               # Розрахунок центроїда
               x1, y1, x2, y2 = track['box']
               centroid = ((x1 + x2) / 2, (y1 + y2) / 2)
               tracks_by_id[track_id]['centroids'].append(centroid)

               tracks_by_id[track_id]['timestamps'].append(frame_data['timestamp'])
               tracks_by_id[track_id]['confidences'].append(track['confidence'])
               tracks_by_id[track_id]['state'] = track['state']  # Оновлення поточного стану

       # Аналіз траєкторій
       trajectory_analysis = {}

       for track_id, track_data in tracks_by_id.items():
           # Пропуск коротких треків
           if len(track_data['frames']) < min_track_length:
               continue

           # Базова інформація про трек
           track_info = {
               'track_id': track_id,
               'class_id': track_data['class_id'],
               'class_name': class_names[track_data['class_id']] if class_names and track_data['class_id'] < len(class_names) else f"Клас {track_data['class_id']}",
               'state': track_data['state'],
               'frames': track_data['frames'],
               'start_frame': track_data['frames'][0],
               'end_frame': track_data['frames'][-1],
               'duration': len(track_data['frames']),
               'duration_seconds': (track_data['timestamps'][-1] - track_data['timestamps'][0]),
               'average_confidence': np.mean(track_data['confidences']),
               'max_confidence': np.max(track_data['confidences']),
               'trajectory': track_data['centroids'],
               'continuous': (track_data['frames'][-1] - track_data['frames'][0] + 1) == len(track_data['frames'])
           }

           # Розрахунок швидкості руху
           if len(track_data['centroids']) > 1:
               # Загальна пройдена відстань
               total_distance = 0
               for i in range(1, len(track_data['centroids'])):
                   pt1 = track_data['centroids'][i-1]
                   pt2 = track_data['centroids'][i]
                   distance = np.sqrt((pt2[0] - pt1[0])**2 + (pt2[1] - pt1[1])**2)
                   total_distance += distance

               # Середня швидкість (пікселів за секунду)
               time_interval = track_data['timestamps'][-1] - track_data['timestamps'][0]
               if time_interval > 0:
                   avg_speed = total_distance / time_interval
               else:
                   avg_speed = 0

               # Миттєві швидкості
               instantaneous_speeds = []
               for i in range(1, len(track_data['centroids'])):
                   pt1 = track_data['centroids'][i-1]
                   pt2 = track_data['centroids'][i]
                   distance = np.sqrt((pt2[0] - pt1[0])**2 + (pt2[1] - pt1[1])**2)
                   time_diff = track_data['timestamps'][i] - track_data['timestamps'][i-1]
                   if time_diff > 0:
                       speed = distance / time_diff
                       instantaneous_speeds.append(speed)

               # Додавання інформації про швидкість
               track_info['total_distance'] = total_distance
               track_info['average_speed'] = avg_speed
               track_info['max_speed'] = max(instantaneous_speeds) if instantaneous_speeds else 0
               track_info['min_speed'] = min(instantaneous_speeds) if instantaneous_speeds else 0
               track_info['speed_std'] = np.std(instantaneous_speeds) if instantaneous_speeds else 0

               # Аналіз стабільності руху (відхилення від прямої лінії)
               if len(track_data['centroids']) > 2:
                   first_point = track_data['centroids'][0]
                   last_point = track_data['centroids'][-1]
                   direct_distance = np.sqrt((last_point[0] - first_point[0])**2 + (last_point[1] - first_point[1])**2)

                   if total_distance > 0:
                       straightness = direct_distance / total_distance
                   else:
                       straightness = 0

                   track_info['straightness'] = straightness
                   track_info['direct_distance'] = direct_distance

           # Додавання інформації про трек до загального аналізу
           trajectory_analysis[track_id] = track_info

       # Статистичний аналіз всіх треків
       all_tracks_summary = {
           'total_tracks': len(trajectory_analysis),
           'total_frames': max_frame + 1,
           'total_time_seconds': (max_frame + 1) / fps,
           'min_track_length': min([track['duration'] for track in trajectory_analysis.values()]) if trajectory_analysis else 0,
           'max_track_length': max([track['duration'] for track in trajectory_analysis.values()]) if trajectory_analysis else 0,
           'avg_track_length': np.mean([track['duration'] for track in trajectory_analysis.values()]) if trajectory_analysis else 0,
           'avg_speed': np.mean([track['average_speed'] for track in trajectory_analysis.values() if 'average_speed' in track]) if trajectory_analysis else 0,
           'max_speed': max([track['max_speed'] for track in trajectory_analysis.values() if 'max_speed' in track]) if trajectory_analysis else 0,
           'avg_straightness': np.mean([track['straightness'] for track in trajectory_analysis.values() if 'straightness' in track]) if trajectory_analysis else 0
       }

       # Додавання статистики за класами
       if class_names:
           class_stats = {}
           for class_id, class_name in enumerate(class_names):
               class_tracks = [track for track in trajectory_analysis.values() if track['class_id'] == class_id]
               if class_tracks:
                   class_stats[class_name] = {
                       'count': len(class_tracks),
                       'avg_confidence': np.mean([track['average_confidence'] for track in class_tracks]),
                       'avg_speed': np.mean([track['average_speed'] for track in class_tracks if 'average_speed' in track]) if class_tracks else 0,
                       'max_speed': max([track['max_speed'] for track in class_tracks if 'max_speed' in track]) if class_tracks else 0
                   }

           all_tracks_summary['class_statistics'] = class_stats

       # Формування результатів аналізу
       analysis_results = {
           'trajectory_analysis': trajectory_analysis,
           'summary': all_tracks_summary
       }

       # Збереження результатів аналізу у файл JSON
       if output_path is not None:
           with open(output_path, 'w') as f:
               json.dump(analysis_results, f, indent=2)
           print(f"Результати аналізу траєкторій збережено у: {output_path}")

       print("Аналіз траєкторій завершено.")
       print(f"Загальна кількість треків: {all_tracks_summary['total_tracks']}")
       print(f"Середня тривалість треку: {all_tracks_summary['avg_track_length']} кадрів")
       if 'avg_speed' in all_tracks_summary:
           print(f"Середня швидкість руху: {all_tracks_summary['avg_speed']:.2f} пікселів/с")

       return analysis_results

   def generate_heatmap(self, tracking_data, frame_shape, min_confidence=0.5,
                       sigma=15, class_id=None, output_path=None):
       """
       Генерація теплової карти руху об'єктів.

       Параметри:
       -----------
       tracking_data : list
           Список словників з даними треків для кожного кадру
       frame_shape : tuple
           Розмір кадру (висота, ширина)
       min_confidence : float
           Мінімальний рівень впевненості для врахування треку
       sigma : float
           Сигма для розмиття Гауса (визначає розмір плям на тепловій карті)
       class_id : int, опціонально
           Ідентифікатор класу для фільтрації (None = всі класи)
       output_path : str, опціонально
           Шлях для збереження теплової карти

       Повертає:
       -----------
       numpy.ndarray : Теплова карта
       """
       # Створення порожньої теплової карти
       height, width = frame_shape[:2]
       heatmap = np.zeros((height, width), dtype=np.float32)

       # Додавання даних треків до теплової карти
       for frame_data in tracking_data:
           for track in frame_data['tracks']:
               # Фільтрація за впевненістю
               if track['confidence'] < min_confidence:
                   continue

               # Фільтрація за класом, якщо вказано
               if class_id is not None and track['class_id'] != class_id:
                   continue

               # Отримання обмежувальної рамки
               x1, y1, x2, y2 = map(int, track['box'])

               # Розрахунок центроїда
               center_x = int((x1 + x2) / 2)
               center_y = int((y1 + y2) / 2)

               # Додавання до теплової карти (з урахуванням впевненості)
               if 0 <= center_x < width and 0 <= center_y < height:
                   heatmap[center_y, center_x] += track['confidence']

       # Розмиття теплової карти для покращення візуалізації
       if sigma > 0:
           heatmap = cv2.GaussianBlur(heatmap, (0, 0), sigma)

       # Нормалізація теплової карти
       if np.max(heatmap) > 0:
           heatmap = heatmap / np.max(heatmap)

       # Візуалізація та збереження теплової карти
       if output_path is not None:
           # Перетворення теплової карти в кольорове зображення
           heatmap_colored = cv2.applyColorMap((heatmap * 255).astype(np.uint8), cv2.COLORMAP_JET)

           # Збереження зображення
           cv2.imwrite(output_path, heatmap_colored)
           print(f"Теплову карту збережено у: {output_path}")

       return heatmap

   def visualize_tracks_summary(self, tracking_data, frame_shape, output_path=None):
       """
       Створення сумарної візуалізації всіх треків.

       Параметри:
       -----------
       tracking_data : list
           Список словників з даними треків для кожного кадру
       frame_shape : tuple
           Розмір кадру (висота, ширина)
       output_path : str, опціонально
           Шлях для збереження візуалізації

       Повертає:
       -----------
       numpy.ndarray : Зображення з візуалізацією треків
       """
       # Створення порожнього зображення
       height, width = frame_shape[:2]
       vis_image = np.ones((height, width, 3), dtype=np.uint8) * 255

       # Структурування даних за треками
       tracks_by_id = {}

       for frame_data in tracking_data:
           for track in frame_data['tracks']:
               track_id = track['track_id']

               if track_id not in tracks_by_id:
                   tracks_by_id[track_id] = {
                       'centroids': [],
                       'confidences': [],
                       'class_id': track['class_id'],
                       'state': track['state']
                   }

               # Отримання обмежувальної рамки
               x1, y1, x2, y2 = track['box']

               # Розрахунок центроїда
               center_x = (x1 + x2) / 2
               center_y = (y1 + y2) / 2

               tracks_by_id[track_id]['centroids'].append((center_x, center_y))
               tracks_by_id[track_id]['confidences'].append(track['confidence'])
               tracks_by_id[track_id]['state'] = track['state']  # Оновлення поточного стану

       # Різні кольори для різних треків
       colors = [
           (0, 255, 0),     # Зелений
           (255, 0, 0),     # Блакитний
           (0, 0, 255),     # Червоний
           (255, 255, 0),   # Синьо-зелений
           (0, 255, 255),   # Жовтий
           (255, 0, 255)    # Пурпурний
       ]

       # Візуалізація треків
       for track_id, track_data in tracks_by_id.items():
           if len(track_data['centroids']) < 2:
               continue

           # Отримання кольору
           color = colors[track_id % len(colors)]

           # Малювання траєкторії
           for i in range(1, len(track_data['centroids'])):
               pt1 = tuple(map(int, track_data['centroids'][i-1]))
               pt2 = tuple(map(int, track_data['centroids'][i]))

               # Градієнт кольору залежно від впевненості
               confidence = track_data['confidences'][i]
               line_color = tuple([int(c * confidence) for c in color])

               # Малювання лінії
               cv2.line(vis_image, pt1, pt2, line_color, 2)

           # Малювання початкової та кінцевої точок
           start_point = tuple(map(int, track_data['centroids'][0]))
           end_point = tuple(map(int, track_data['centroids'][-1]))

           cv2.circle(vis_image, start_point, 5, (0, 255, 0), -1)  # Зелений для початку
           cv2.circle(vis_image, end_point, 5, (0, 0, 255), -1)    # Червоний для кінця

           # Додавання ідентифікатора треку
           cv2.putText(vis_image, f"ID: {track_id}", end_point,
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)

       # Збереження візуалізації
       if output_path is not None:
           cv2.imwrite(output_path, vis_image)
           print(f"Візуалізацію треків збережено у: {output_path}")

       return vis_image


# Приклад використання:
# tracker = DroneTracker()
#
# # Використання трекера з детектором
# detector = DroneDetector()
# detector.load_model()
#
# # Обробка відео
# output_path, tracking_data = tracker.process_video(
#     'test_video.mp4',
#     'output_tracked.mp4',
#     detector=detector,
#     display=True
# )
#
# # Аналіз траєкторій
# analysis_results = tracker.analyze_trajectories(
#     tracking_data,
#     fps=30,
#     output_path='trajectory_analysis.json'
# )
#
# # Створення теплової карти
# frame = cv2.imread('test_frame.jpg')
# heatmap = tracker.generate_heatmap(
#     tracking_data,
#     frame.shape,
#     output_path='heatmap.jpg'
# )
#
# # Візуалізація всіх треків
# summary_image = tracker.visualize_tracks_summary(
#     tracking_data,
#     frame.shape,
#     output_path='tracks_summary.jpg'
# )

# Модуль 4: Фільтрація хибних спрацьовувань

import cv2
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
from collections import deque, Counter
import pandas as pd
import seaborn as sns
from sklearn.ensemble import IsolationForest
from pathlib import Path
import json
import time
import os
from tqdm import tqdm

class FalsePositiveFilter:
   """
   Клас для фільтрації хибних спрацьовувань при виявленні дронів.
   """

   def __init__(self, temporal_window=5, min_detections=3, confidence_threshold=0.3,
               min_size=10, max_size=None, velocity_threshold=50,
               abrupt_change_threshold=30, context_zones=None,
               drone_features_model=None, class_names=None):
       """
       Ініціалізація фільтра хибних спрацьовувань.

       Параметри:
       -----------
       temporal_window : int
           Розмір вікна для аналізу часової узгодженості (кількість кадрів)
       min_detections : int
           Мінімальна кількість виявлень у вікні для підтвердження об'єкта
       confidence_threshold : float
           Поріг впевненості для фільтрації виявлень з низькою достовірністю
       min_size : int
           Мінімальний розмір об'єкта (в пікселях) для фільтрації надто малих об'єктів
       max_size : int, опціонально
           Максимальний розмір об'єкта (в пікселях) для фільтрації надто великих об'єктів
       velocity_threshold : float
           Поріг швидкості для фільтрації об'єктів з нереалістично швидким рухом
       abrupt_change_threshold : float
           Поріг для виявлення різких змін розміру або положення
       context_zones : dict, опціонально
           Зони контексту для фільтрації виявлень за просторовим контекстом
       drone_features_model : object, опціонально
           Модель для верифікації дронів на основі візуальних особливостей
       class_names : list, опціонально
           Список назв класів
       """
       self.temporal_window = temporal_window
       self.min_detections = min_detections
       self.confidence_threshold = confidence_threshold
       self.min_size = min_size
       self.max_size = max_size
       self.velocity_threshold = velocity_threshold
       self.abrupt_change_threshold = abrupt_change_threshold
       self.context_zones = context_zones
       self.drone_features_model = drone_features_model
       self.class_names = class_names

       # Буфер для зберігання виявлень у часовому вікні
       self.detection_history = deque(maxlen=temporal_window)

       # Словник для зберігання фільтрованих виявлень за ID
       self.filtered_detections_by_id = {}

       # Лічильник кадрів
       self.frame_count = 0

       # Аномалії детектор
       self.anomaly_detector = None

       # Статистика фільтрації
       self.filtering_stats = {
           'total_detections': 0,
           'filtered_out': {
               'low_confidence': 0,
               'small_size': 0,
               'large_size': 0,
               'temporal_inconsistency': 0,
               'unrealistic_velocity': 0,
               'abrupt_change': 0,
               'context_mismatch': 0,
               'verification_failed': 0,
               'anomaly': 0
           },
           'filtered_in': 0
       }

       # Шлях для зберігання результатів
       self.results_dir = Path("filtering_results")
       self.results_dir.mkdir(exist_ok=True)

   def _calculate_box_size(self, box):
       """
       Розрахунок розміру обмежувальної рамки.

       Параметри:
       -----------
       box : tuple
           Обмежувальна рамка у форматі (x1, y1, x2, y2)

       Повертає:
       -----------
       tuple : (ширина, висота, площа)
       """
       x1, y1, x2, y2 = box
       width = x2 - x1
       height = y2 - y1
       area = width * height
       return width, height, area

   def _calculate_centroid(self, box):
       """
       Розрахунок центроїда обмежувальної рамки.

       Параметри:
       -----------
       box : tuple
           Обмежувальна рамка у форматі (x1, y1, x2, y2)

       Повертає:
       -----------
       tuple : (x, y)
       """
       x1, y1, x2, y2 = box
       return ((x1 + x2) / 2, (y1 + y2) / 2)

   def _calculate_velocity(self, centroid1, centroid2, time_diff=1):
       """
       Розрахунок швидкості руху об'єкта.

       Параметри:
       -----------
       centroid1, centroid2 : tuple
           Координати центроїдів у форматі (x, y)
       time_diff : float
           Часовий інтервал між центроїдами (в кадрах)

       Повертає:
       -----------
       float : швидкість (пікселів за кадр)
       """
       distance = np.sqrt((centroid2[0] - centroid1[0])**2 +
                          (centroid2[1] - centroid1[1])**2)
       return distance / time_diff

   def _is_in_zone(self, box, zone):
       """
       Перевірка, чи знаходиться об'єкт у вказаній зоні.

       Параметри:
       -----------
       box : tuple
           Обмежувальна рамка у форматі (x1, y1, x2, y2)
       zone : dict
           Опис зони у форматі {'x1': int, 'y1': int, 'x2': int, 'y2': int, 'type': str}

       Повертає:
       -----------
       bool : True, якщо об'єкт знаходиться в зоні
       """
       x1, y1, x2, y2 = box
       centroid = self._calculate_centroid(box)

       # Перевірка, чи центроїд знаходиться в зоні
       if (zone['x1'] <= centroid[0] <= zone['x2'] and
           zone['y1'] <= centroid[1] <= zone['y2']):
           return True

       return False

   def _check_context_compatibility(self, detection, frame_shape):
       """
       Перевірка сумісності виявлення з контекстом.

       Параметри:
       -----------
       detection : dict
           Інформація про виявлення
       frame_shape : tuple
           Розмір кадру (висота, ширина)

       Повертає:
       -----------
       bool : True, якщо виявлення сумісне з контекстом
       """
       if self.context_zones is None:
           return True

       box = detection['box']

       # Перевірка для кожної зони
       for zone in self.context_zones:
           if self._is_in_zone(box, zone):
               # Якщо зона є забороненою для дронів
               if zone['type'] == 'forbidden':
                   return False
               # Якщо зона є дозволеною для дронів
               elif zone['type'] == 'allowed':
                   return True

       # Якщо не знайдено відповідності з жодною зоною
       # і є хоча б одна дозволена зона, вважаємо виявлення нелегітимним
       if any(zone['type'] == 'allowed' for zone in self.context_zones):
           return False

       return True

   def _verify_drone_features(self, detection, frame):
       """
       Верифікація виявлення на основі візуальних особливостей дронів.

       Параметри:
       -----------
       detection : dict
           Інформація про виявлення
       frame : numpy.ndarray
           Поточний кадр

       Повертає:
       -----------
       bool : True, якщо виявлення підтверджено як дрон
       """
       if self.drone_features_model is None or frame is None:
           return True

       # Витягування регіону з зображення
       box = detection['box']
       x1, y1, x2, y2 = map(int, box)

       # Забезпечення, що координати не виходять за межі зображення
       height, width = frame.shape[:2]
       x1 = max(0, x1)
       y1 = max(0, y1)
       x2 = min(width, x2)
       y2 = min(height, y2)

       # Перевірка, чи розмір регіону достатній
       if x2 <= x1 or y2 <= y1:
           return False

       # Вирізання регіону
       roi = frame[y1:y2, x1:x2]

       # Використання моделі для верифікації
       try:
           # Тут має бути код для підготовки roi та його аналізу моделлю
           # Приклад:
           # is_drone = self.drone_features_model.predict(roi)
           # return is_drone > 0.5

           # Оскільки модель не реалізована, завжди повертаємо True
           return True
       except Exception as e:
           print(f"Помилка при верифікації дрону: {e}")
           return True

   def _detect_anomalies(self, detection, frame_shape):
       """
       Виявлення аномальних виявлень на основі статистичних моделей.

       Параметри:
       -----------
       detection : dict
           Інформація про виявлення
       frame_shape : tuple
           Розмір кадру (висота, ширина)

       Повертає:
       -----------
       bool : True, якщо виявлення не є аномальним
       """
       # Якщо аномалій детектор ще не створено, але є достатньо даних
       if self.anomaly_detector is None and len(self.detection_history) >= 50:
           self._train_anomaly_detector()

       # Якщо аномалій детектор все ще None, пропускаємо перевірку
       if self.anomaly_detector is None:
           return True

       # Підготовка ознак для аналізу
       features = self._extract_detection_features(detection, frame_shape)

       # Прогнозування аномалії (-1 для аномалій, 1 для нормальних)
       prediction = self.anomaly_detector.predict([features])[0]

       # Повертаємо True, якщо виявлення нормальне (не аномальне)
       return prediction == 1

   def _extract_detection_features(self, detection, frame_shape):
       """
       Витягування ознак з виявлення для аналізу аномалій.

       Параметри:
       -----------
       detection : dict
           Інформація про виявлення
       frame_shape : tuple
           Розмір кадру (висота, ширина)

       Повертає:
       -----------
       list : вектор ознак
       """
       box = detection['box']
       confidence = detection['confidence']

       # Розрахунок відносних координат та розмірів
       x1, y1, x2, y2 = box
       height, width = frame_shape[:2]

       # Нормалізація координат
       x_center_norm = ((x1 + x2) / 2) / width
       y_center_norm = ((y1 + y2) / 2) / height
       width_norm = (x2 - x1) / width
       height_norm = (y2 - y1) / height
       aspect_ratio = width_norm / height_norm if height_norm > 0 else 0
       area_norm = width_norm * height_norm

       # Формування вектора ознак
       features = [
           x_center_norm,
           y_center_norm,
           width_norm,
           height_norm,
           aspect_ratio,
           area_norm,
           confidence
       ]

       return features

   def _train_anomaly_detector(self):
       """
       Навчання детектора аномалій на основі історії виявлень.
       """
       # Отримання всіх виявлень з історії
       all_detections = []
       for frame_detections in self.detection_history:
           all_detections.extend(frame_detections)

       if len(all_detections) < 10:
           return

       # Витягування ознак для кожного виявлення
       X = []
       for detection in all_detections:
           features = self._extract_detection_features(
               detection,
               frame_shape=(detection.get('frame_height', 720),
                           detection.get('frame_width', 1280))
           )
           X.append(features)

       # Навчання моделі Isolation Forest
       self.anomaly_detector = IsolationForest(
           n_estimators=100,
           contamination=0.1,  # очікувана частка аномалій
           random_state=42
       )

       self.anomaly_detector.fit(X)
       print("Детектор аномалій навчено на історії виявлень.")

   def filter_detections(self, detections, frame=None, frame_index=None):
       """
       Фільтрація виявлень для видалення хибних спрацьовувань.

       Параметри:
       -----------
       detections : list
           Список виявлень у форматі [[x1, y1, x2, y2, conf, class_id], ...]
       frame : numpy.ndarray, опціонально
           Поточний кадр для контекстного аналізу
       frame_index : int, опціонально
           Індекс поточного кадру

       Повертає:
       -----------
       list : Список відфільтрованих виявлень
       """
       # Якщо індекс кадру не вказано, використовуємо лічильник
       if frame_index is None:
           frame_index = self.frame_count
           self.frame_count += 1

       # Отримання розміру кадру
       frame_shape = None
       if frame is not None:
           frame_shape = frame.shape

       # Перетворення detections у внутрішній формат
       formatted_detections = []
       for det in detections:
           if len(det) >= 6:  # Формат [x1, y1, x2, y2, conf, class_id]
               # Оновлення статистики
               self.filtering_stats['total_detections'] += 1

               detection = {
                   'box': (det[0], det[1], det[2], det[3]),
                   'confidence': det[4],
                   'class_id': int(det[5]),
                   'frame_index': frame_index,
                   'filtered_reason': None
               }

               # Додавання розміру кадру, якщо доступно
               if frame_shape is not None:
                   detection['frame_height'] = frame_shape[0]
                   detection['frame_width'] = frame_shape[1]

               formatted_detections.append(detection)

       # Фільтрація за впевненістю
       confidence_filtered = []
       for detection in formatted_detections:
           if detection['confidence'] >= self.confidence_threshold:
               confidence_filtered.append(detection)
           else:
               detection['filtered_reason'] = 'low_confidence'
               self.filtering_stats['filtered_out']['low_confidence'] += 1

       # Фільтрація за розміром
       size_filtered = []
       for detection in confidence_filtered:
           box = detection['box']
           width, height, area = self._calculate_box_size(box)

           if width < self.min_size or height < self.min_size:
               detection['filtered_reason'] = 'small_size'
               self.filtering_stats['filtered_out']['small_size'] += 1
               continue

           if self.max_size is not None and (width > self.max_size or height > self.max_size):
               detection['filtered_reason'] = 'large_size'
               self.filtering_stats['filtered_out']['large_size'] += 1
               continue

           size_filtered.append(detection)

       # Фільтрація за контекстом
       context_filtered = []
       for detection in size_filtered:
           if frame_shape is not None and self.context_zones is not None:
               if self._check_context_compatibility(detection, frame_shape):
                   context_filtered.append(detection)
               else:
                   detection['filtered_reason'] = 'context_mismatch'
                   self.filtering_stats['filtered_out']['context_mismatch'] += 1
           else:
               context_filtered.append(detection)

       # Верифікація на основі візуальних особливостей
       verified_detections = []
       for detection in context_filtered:
           if frame is not None and self.drone_features_model is not None:
               if self._verify_drone_features(detection, frame):
                   verified_detections.append(detection)
               else:
                   detection['filtered_reason'] = 'verification_failed'
                   self.filtering_stats['filtered_out']['verification_failed'] += 1
           else:
               verified_detections.append(detection)

       # Виявлення аномалій
       anomaly_filtered = []
       for detection in verified_detections:
           if frame_shape is not None:
               if self._detect_anomalies(detection, frame_shape):
                   anomaly_filtered.append(detection)
               else:
                   detection['filtered_reason'] = 'anomaly'
                   self.filtering_stats['filtered_out']['anomaly'] += 1
           else:
               anomaly_filtered.append(detection)

       # Додавання поточних виявлень до історії
       self.detection_history.append(anomaly_filtered)

       # Фільтрація за часовою узгодженістю
       temporal_filtered = self._filter_by_temporal_consistency(anomaly_filtered)

       # Оновлення статистики
       self.filtering_stats['filtered_in'] += len(temporal_filtered)

       # Перетворення назад у формат [x1, y1, x2, y2, conf, class_id]
       result_detections = []
       for detection in temporal_filtered:
           box = detection['box']
           result_detections.append([
               box[0], box[1], box[2], box[3],
               detection['confidence'],
               detection['class_id']
           ])

       return result_detections

   def _filter_by_temporal_consistency(self, current_detections):
       """
       Фільтрація виявлень на основі їх часової узгодженості.

       Параметри:
       -----------
       current_detections : list
           Список поточних виявлень

       Повертає:
       -----------
       list : Список виявлень, що пройшли фільтрацію за часовою узгодженістю
       """
       if len(self.detection_history) < 2:
           return current_detections

       # Генерація унікальних ID для нових виявлень
       for detection in current_detections:
           # Пошук найближчого виявлення з попередніх кадрів
           best_match_id = None
           best_match_iou = 0

           # Перебір всіх існуючих треків
           for track_id, track_data in list(self.filtered_detections_by_id.items()):
               last_detection = track_data['detections'][-1]
               last_box = last_detection['box']
               current_box = detection['box']

               # Розрахунок IoU
               iou = self._calculate_iou(last_box, current_box)

               # Якщо IoU достатньо високий, вважаємо це тим самим об'єктом
               if iou > 0.3 and iou > best_match_iou:
                   best_match_id = track_id
                   best_match_iou = iou

           # Якщо знайдено відповідність, додаємо до існуючого треку
           if best_match_id is not None:
               track_data = self.filtered_detections_by_id[best_match_id]

               # Перевірка на різкі зміни
               if self._check_for_abrupt_changes(track_data['detections'][-1], detection):
                   detection['filtered_reason'] = 'abrupt_change'
                   self.filtering_stats['filtered_out']['abrupt_change'] += 1
                   continue

               # Перевірка на нереалістичну швидкість
               if self._check_for_unrealistic_velocity(track_data['detections'][-1], detection):
                   detection['filtered_reason'] = 'unrealistic_velocity'
                   self.filtering_stats['filtered_out']['unrealistic_velocity'] += 1
                   continue

               # Додавання до треку
               track_data['detections'].append(detection)
               track_data['last_seen'] = detection['frame_index']
               track_data['count'] += 1
           else:
               # Створення нового треку
               new_track_id = len(self.filtered_detections_by_id) + 1
               self.filtered_detections_by_id[new_track_id] = {
                   'detections': [detection],
                   'first_seen': detection['frame_index'],
                   'last_seen': detection['frame_index'],
                   'count': 1
               }

       # Фільтрація треків за кількістю виявлень
       valid_tracks = {track_id: track_data for track_id, track_data in
                      self.filtered_detections_by_id.items()
                      if track_data['count'] >= self.min_detections}

       # Видалення старих треків, які давно не оновлювалися
       current_frame = max([d['frame_index'] for d in current_detections]) if current_detections else 0
       self.filtered_detections_by_id = {
           track_id: track_data for track_id, track_data in
           self.filtered_detections_by_id.items()
           if current_frame - track_data['last_seen'] <= self.temporal_window
       }

       # Збір останніх виявлень з валідних треків
       result = []
       for track_id, track_data in valid_tracks.items():
           # Перевірка, чи трек все ще активний
           if current_frame - track_data['last_seen'] <= 1:
               result.append(track_data['detections'][-1])

       # Для виявлень, які не були включені через недостатню кількість підтверджень
       for detection in current_detections:
           if detection not in result and detection.get('filtered_reason') is None:
               detection['filtered_reason'] = 'temporal_inconsistency'
               self.filtering_stats['filtered_out']['temporal_inconsistency'] += 1

       return result

   def _calculate_iou(self, box1, box2):
       """
       Розрахунок IoU (Intersection over Union) між двома обмежувальними рамками.

       Параметри:
       -----------
       box1, box2 : tuple
           Обмежувальні рамки у форматі (x1, y1, x2, y2)

       Повертає:
       -----------
       float : значення IoU
       """
       # Розпакування координат
       x1_1, y1_1, x2_1, y2_1 = box1
       x1_2, y1_2, x2_2, y2_2 = box2

       # Розрахунок координат перетину
       x1_i = max(x1_1, x1_2)
       y1_i = max(y1_1, y1_2)
       x2_i = min(x2_1, x2_2)
       y2_i = min(y2_1, y2_2)

       # Розрахунок площі перетину
       if x2_i < x1_i or y2_i < y1_i:
           # Немає перетину
           return 0.0

       intersection_area = (x2_i - x1_i) * (y2_i - y1_i)

       # Розрахунок площ обох обмежувальних рамок
       box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)
       box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)

       # Розрахунок IoU
       iou = intersection_area / float(box1_area + box2_area - intersection_area)

       return iou

   def _check_for_abrupt_changes(self, previous_detection, current_detection):
       """
       Перевірка на наявність різких змін у розмірі або положенні.

       Параметри:
       -----------
       previous_detection, current_detection : dict
           Інформація про виявлення

       Повертає:
       -----------
       bool : True, якщо виявлено різкі зміни
       """
       prev_box = previous_detection['box']
       curr_box = current_detection['box']

       # Розрахунок розмірів
       prev_width, prev_height, prev_area = self._calculate_box_size(prev_box)
       curr_width, curr_height, curr_area = self._calculate_box_size(curr_box)

       # Розрахунок зміни розміру
       if prev_area > 0:
           size_change_ratio = curr_area / prev_area
           if size_change_ratio < 0.5 or size_change_ratio > 2.0:
               return True

       # Розрахунок зміни положення
       prev_centroid = self._calculate_centroid(prev_box)
       curr_centroid = self._calculate_centroid(curr_box)

       # Нормалізація зміни положення відносно розміру об'єкта
       position_change = self._calculate_velocity(prev_centroid, curr_centroid)
       diagonal = np.sqrt(prev_width**2 + prev_height**2)

       if diagonal > 0 and position_change / diagonal > self.abrupt_change_threshold / 100:
           return True

       return False

   def _check_for_unrealistic_velocity(self, previous_detection, current_detection):
       """
       Перевірка на нереалістично високу швидкість руху.

       Параметри:
       -----------
       previous_detection, current_detection : dict
           Інформація про виявлення

       Повертає:
       -----------
       bool : True, якщо швидкість перевищує поріг
       """
       # Розрахунок часового інтервалу
       time_diff = current_detection['frame_index'] - previous_detection['frame_index']
       if time_diff <= 0:
           return False

       # Розрахунок центроїдів
       prev_centroid = self._calculate_centroid(previous_detection['box'])
       curr_centroid = self._calculate_centroid(current_detection['box'])

       # Розрахунок швидкості
       velocity = self._calculate_velocity(prev_centroid, curr_centroid, time_diff)

       # Перевірка на перевищення порогу
       return velocity > self.velocity_threshold

   def define_context_zones(self, zones_data):

       Визначення зон контексту для фільтрації виявлень.

       Параметри:
       -----------
       zones_data : list
           Список зон у форматі [{'x1': int, 'y1': int, 'x2': int, 'y2': int, 'type': str}, ...]
           Тип зони може бути 'allowed' (дозволено для дронів) або 'forbidden' (заборонено)

       self.context_zones = zones_data
       print(f"Визначено {len(zones_data)} зон контексту.")

   def process_video(self, video_path, detector, output_path=None,
                    skip_frames=0, max_frames=None, show_progress=True,
                    display=False):
       """

       Обробка відео з фільтрацією хибних спрацьовувань.

       Параметри:
       -----------
       video_path : str
           Шлях до відеофайлу
       detector : object
           Об'єкт для виявлення дронів з методом detect
       output_path : str, опціонально
           Шлях для збереження результату
       skip_frames : int
           Кількість кадрів для пропуску між обробленими кадрами
       max_frames : int
           Максимальна кількість кадрів для обробки
       show_progress : bool
           Показувати прогрес обробки
       display : bool
           Показувати відео в реальному часі

       Повертає:
       -----------
       tuple : (шлях до обробленого відео, статистика фільтрації)

        """

       # Відкриття відеофайлу
       cap = cv2.VideoCapture(video_path)

       # Перевірка, чи відеофайл відкрито успішно
       if not cap.isOpened():
           raise ValueError(f"Не вдалося відкрити відеофайл: {video_path}")

       # Отримання параметрів відео
       fps = cap.get(cv2.CAP_PROP_FPS)
       total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
       width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
       height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

       # Якщо max_frames не вказано, обробляємо все відео
       if max_frames is None:
           max_frames = total_frames
       else:
           max_frames = min(max_frames, total_frames)

       # Створення відеописувача для вихідного файлу
       if output_path is not None:
           fourcc = cv2.VideoWriter_fourcc(*'mp4v')
           out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

       # Ініціалізація змінних
       frame_count = 0
       process_count = 0
       total_processing_time = 0
       filtered_detections_history = []

       # Прогрес-бар
       if show_progress:
           progress_bar = tqdm(total=max_frames, desc="Обробка відео")

       print(f"Початок обробки відео: {video_path}")
       print(f"Параметри відео: {width}x{height}, {fps} FPS, {total_frames} кадрів")

       # Скидання лічильника кадрів
       self.frame_count = 0

       # Цикл обробки відео
       while cap.isOpened() and frame_count < max_frames:
           # Зчитування кадру
           ret, frame = cap.read()

           # Перевірка, чи кадр зчитано успішно
           if not ret:
               break

           # Пропуск кадрів, якщо потрібно
           if skip_frames > 0 and frame_count % (skip_frames + 1) != 0:
               frame_count += 1
               if show_progress:
                   progress_bar.update(1)
               continue

           # Обробка кадру
           process_count += 1
           frame_processing_start = time.time()

           # Виявлення об'єктів
           raw_detections = detector.detect(frame)

           # Отримання обмежувальних рамок
           detections = []
           if len(raw_detections) > 0:
               boxes = raw_detections[0].boxes
               for box in boxes:
                   x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                   conf = box.conf[0].cpu().numpy()
                   cls = box.cls[0].cpu().numpy()
                   detections.append([x1, y1, x2, y2, conf, cls])

           # Фільтрація виявлень
           filtered_detections = self.filter_detections(detections, frame, frame_count)
           filtered_detections_history.append(filtered_detections)

           # Візуалізація результатів
           frame_with_detections = self._draw_filtered_detections(frame, filtered_detections)

           # Запис кадру у вихідний файл
           if output_path is not None:
               out.write(frame_with_detections)

           # Відображення кадру в реальному часі
           if display:
               cv2.imshow("Фільтрація хибних спрацьовувань", frame_with_detections)

               # Вихід при натисканні клавіші 'q'
               if cv2.waitKey(1) & 0xFF == ord('q'):
                   break

           # Обчислення часу обробки
           frame_processing_time = time.time() - frame_processing_start
           total_processing_time += frame_processing_time

           # Оновлення лічильника кадрів та прогрес-бару
           frame_count += 1
           if show_progress:
               progress_bar.update(1)

       # Завершення обробки
       cap.release()
       if output_path is not None:
           out.release()
       if display:
           cv2.destroyAllWindows()
       if show_progress:
           progress_bar.close()

       # Обчислення середнього часу обробки
       avg_processing_time = total_processing_time / process_count if process_count > 0 else 0
       avg_fps = process_count / total_processing_time if total_processing_time > 0 else 0

       print(f"Обробка відео завершена. Оброблено {process_count} кадрів.")
       print(f"Середній час обробки на кадр: {avg_processing_time:.3f} с")
       print(f"Середній FPS: {avg_fps:.2f}")

       # Збереження статистики фільтрації
       filtering_stats_path = output_path.replace('.mp4', '_filtering_stats.json') if output_path else str(self.results_dir / 'filtering_stats.json')
       with open(filtering_stats_path, 'w') as f:
           json.dump(self.filtering_stats, f, indent=2)
       print(f"Статистику фільтрації збережено у: {filtering_stats_path}")

       if output_path is not None:
           print(f"Результат збережено у: {output_path}")
           return output_path, self.filtering_stats

       return None, self.filtering_stats

   def _draw_filtered_detections(self, frame, filtered_detections, thickness=2, font_scale=0.6):
       """
       Візуалізація відфільтрованих виявлень на кадрі.

       Параметри:
       -----------
       frame : numpy.ndarray
           Кадр для візуалізації
       filtered_detections : list
           Список відфільтрованих виявлень у форматі [[x1, y1, x2, y2, conf, class_id], ...]
       thickness : int
           Товщина ліній обмежувальних рамок
       font_scale : float
           Розмір шрифту для підписів

       Повертає:
       -----------
       numpy.ndarray : Кадр з візуалізованими виявленнями
       """
       # Створення копії кадру
       output_frame = frame.copy()

       # Малювання зон контексту, якщо вони визначені
       if self.context_zones is not None:
           for zone in self.context_zones:
               # Вибір кольору залежно від типу зони
               if zone['type'] == 'allowed':
                   color = (0, 255, 0, 128)  # Зелений (напівпрозорий)
               else:
                   color = (0, 0, 255, 128)  # Червоний (напівпрозорий)

               # Малювання зони
               cv2.rectangle(output_frame,
                           (zone['x1'], zone['y1']),
                           (zone['x2'], zone['y2']),
                           color[:3], 2)

               # Додавання підпису
               cv2.putText(output_frame,
                         zone['type'].capitalize(),
                         (zone['x1'], zone['y1'] - 5),
                         cv2.FONT_HERSHEY_SIMPLEX,
                         0.7, color[:3], 2)

       # Малювання виявлень
       for det in filtered_detections:
           x1, y1, x2, y2, conf, class_id = det

           # Перетворення в цілі числа
           x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
           class_id = int(class_id)

           # Колір для виявлення
           color = (0, 255, 0)  # Зелений

           # Малювання обмежувальної рамки
           cv2.rectangle(output_frame, (x1, y1), (x2, y2), color, thickness)

           # Отримання назви класу
           if self.class_names is not None and class_id < len(self.class_names):
               class_name = self.class_names[class_id]
           else:
               class_name = f"Клас {class_id}"

           # Формування тексту підпису
           label = f"{class_name} {conf:.2f}"

           # Розрахунок розміру тексту
           (text_width, text_height), baseline = cv2.getTextSize(
               label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)

           # Малювання фону для тексту
           cv2.rectangle(output_frame, (x1, y1 - text_height - baseline),
                         (x1 + text_width, y1), color, -1)

           # Малювання тексту
           cv2.putText(output_frame, label, (x1, y1 - baseline),
                       cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 0), thickness)

       # Додавання інформації про статистику фільтрації
       total = self.filtering_stats['total_detections']
       filtered_out = sum(self.filtering_stats['filtered_out'].values())
       filtered_in = self.filtering_stats['filtered_in']

       stats_text = f"Загально: {total}, Відфільтровано: {filtered_out}, Пропущено: {filtered_in}"
       cv2.putText(output_frame, stats_text, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

       return output_frame

   def plot_filtering_statistics(self, output_path=None):
       """
       Візуалізація статистики фільтрації.

       Параметри:
       -----------
       output_path : str, опціонально
           Шлях для збереження візуалізації

       Повертає:
       -----------
       matplotlib.figure.Figure : Фігура з візуалізацією
       """
       # Підготовка даних
       total = self.filtering_stats['total_detections']
       filtered_out = sum(self.filtering_stats['filtered_out'].values())
       filtered_in = self.filtering_stats['filtered_in']

       # Створення фігури
       fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))

       # Кругова діаграма загального розподілу
       labels = ['Пропущено', 'Відфільтровано']
       sizes = [filtered_in, filtered_out]
       colors = ['#66b3ff', '#ff9999']
       explode = (0.1, 0)  # explode the 1st slice (Пропущено)

       ax1.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%',
              shadow=True, startangle=90)
       ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle
       ax1.set_title('Загальний розподіл виявлень', fontsize=14)

       # Стовпчаста діаграма причин фільтрації
       reasons = list(self.filtering_stats['filtered_out'].keys())
       counts = list(self.filtering_stats['filtered_out'].values())

       # Сортування за кількістю
       sorted_indices = np.argsort(counts)[::-1]
       reasons = [reasons[i] for i in sorted_indices]
       counts = [counts[i] for i in sorted_indices]

       # Переклад причин українською
       reason_names = {
           'low_confidence': 'Низька впевненість',
           'small_size': 'Малий розмір',
           'large_size': 'Великий розмір',
           'temporal_inconsistency': 'Часова неузгодженість',
           'unrealistic_velocity': 'Нереалістична швидкість',
           'abrupt_change': 'Різка зміна',
           'context_mismatch': 'Несумісність з контекстом',
           'verification_failed': 'Невдала верифікація',
           'anomaly': 'Аномалія'
       }

       # Створення стовпчастої діаграми
       bars = ax2.bar(
           [reason_names.get(r, r) for r in reasons],
           counts,
           color=sns.color_palette("viridis", len(reasons))
       )

       # Додавання значень над стовпцями
       for bar in bars:
           height = bar.get_height()
           ax2.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                   f'{height}',
                   ha='center', va='bottom')

       ax2.set_title('Причини фільтрації виявлень', fontsize=14)
       ax2.set_ylabel('Кількість виявлень')
       plt.xticks(rotation=45, ha='right')
       plt.tight_layout()

       # Збереження візуалізації
       if output_path is not None:
           plt.savefig(output_path)
           print(f"Візуалізацію статистики фільтрації збережено у: {output_path}")

       return fig

   def get_filtering_summary(self):
       """
       Отримання текстового звіту зі статистикою фільтрації.

       Повертає:
       -----------
       str : Текстовий звіт
       """
       total = self.filtering_stats['total_detections']
       filtered_out = sum(self.filtering_stats['filtered_out'].values())
       filtered_in = self.filtering_stats['filtered_in']

       if total == 0:
           return "Немає даних для аналізу. Спочатку обробіть відео або зображення."

       summary = [
           "=== Звіт про фільтрацію хибних спрацьовувань ===",
           f"Загальна кількість виявлень: {total}",
           f"Кількість відфільтрованих виявлень: {filtered_out} ({filtered_out/total*100:.1f}%)",
           f"Кількість пропущених виявлень: {filtered_in} ({filtered_in/total*100:.1f}%)",
           "\nРозподіл за причинами фільтрації:"
       ]

       # Переклад причин українською
       reason_names = {
           'low_confidence': 'Низька впевненість',
           'small_size': 'Малий розмір',
           'large_size': 'Великий розмір',
           'temporal_inconsistency': 'Часова неузгодженість',
           'unrealistic_velocity': 'Нереалістична швидкість',
           'abrupt_change': 'Різка зміна',
           'context_mismatch': 'Несумісність з контекстом',
           'verification_failed': 'Невдала верифікація',
           'anomaly': 'Аномалія'
       }

       # Додавання статистики за причинами
       for reason, count in sorted(self.filtering_stats['filtered_out'].items(),
                                  key=lambda x: x[1], reverse=True):
           if count > 0:
               reason_name = reason_names.get(reason, reason)
               percentage = count / filtered_out * 100 if filtered_out > 0 else 0
               summary.append(f"  - {reason_name}: {count} ({percentage:.1f}%)")

       # Додавання висновків
       summary.append("\nВисновки:")

       if filtered_in / total < 0.1:
           summary.append("  - Дуже висока частка відфільтрованих виявлень. Можливо, поріг фільтрації занадто жорсткий.")
       elif filtered_in / total > 0.9:
           summary.append("  - Дуже низька частка відфільтрованих виявлень. Можливо, поріг фільтрації занадто м'який.")

       # Аналіз основних причин фільтрації
       main_reasons = sorted(self.filtering_stats['filtered_out'].items(),
                            key=lambda x: x[1], reverse=True)[:2]

       if main_reasons:
           summary.append("  - Основні причини фільтрації:")
           for reason, count in main_reasons:
               if count > 0:
                   reason_name = reason_names.get(reason, reason)
                   summary.append(f"      * {reason_name}: {count} випадків")

                   # Рекомендації залежно від причини
                   if reason == 'low_confidence':
                       summary.append("        Рекомендація: Перегляньте поріг впевненості або покращіть якість детектора.")
                   elif reason in ['small_size', 'large_size']:
                       summary.append("        Рекомендація: Налаштуйте параметри розміру об'єктів відповідно до ваших потреб.")
                   elif reason == 'temporal_inconsistency':
                       summary.append("        Рекомендація: Розгляньте можливість зміни розміру часового вікна або мінімальної кількості підтверджень.")
                   elif reason in ['unrealistic_velocity', 'abrupt_change']:
                       summary.append("        Рекомендація: Перегляньте пороги для швидкості та різких змін.")
                   elif reason == 'context_mismatch':
                       summary.append("        Рекомендація: Перевірте визначення зон контексту.")

       return "\n".join(summary)

   def clear_statistics(self):
       """
       Очищення статистики фільтрації.
       """
       self.filtering_stats = {
           'total_detections': 0,
           'filtered_out': {
               'low_confidence': 0,
               'small_size': 0,
               'large_size': 0,
               'temporal_inconsistency': 0,
               'unrealistic_velocity': 0,
               'abrupt_change': 0,
               'context_mismatch': 0,
               'verification_failed': 0,
               'anomaly': 0
           },
           'filtered_in': 0
       }
       self.detection_history.clear()
       self.filtered_detections_by_id.clear()
       self.frame_count = 0
       print("Статистику фільтрації очищено.")


# Приклад використання:
# filter = FalsePositiveFilter(
#     temporal_window=5,
#     min_detections=3,
#     confidence_threshold=0.3,
#     min_size=10,
#     velocity_threshold=50
# )
#
# # Визначення зон контексту (наприклад, небо - дозволена зона для дронів)
# filter.define_context_zones([
#     {'x1': 0, 'y1': 0, 'x2': 1280, 'y2': 400, 'type': 'allowed'},
#     {'x1': 0, 'y1': 400, 'x2': 1280, 'y2': 720, 'type': 'forbidden'}
# ])
#
# # Обробка відео
# detector = DroneDetector()
# detector.load_model()
#
# output_path, filtering_stats = filter.process_video(
#     'test_video.mp4',
#     detector,
#     output_path='output_filtered.mp4',
#     display=True
# )
#
# # Візуалізація статистики
# filter.plot_filtering_statistics('filtering_stats.png')
#
# # Отримання звіту
# summary = filter.get_filtering_summary()
# print(summary)

# Модуль 5: Візуалізація результатів

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import matplotlib.patches as patches
import seaborn as sns
import pandas as pd
from matplotlib.colors import LinearSegmentedColormap
from matplotlib.animation import FuncAnimation
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import json
from pathlib import Path
from tqdm import tqdm
import base64
from io import BytesIO
from datetime import datetime
from PIL import Image
import folium
from folium.plugins import HeatMap
import math

class ResultsVisualizer:
    """
    Клас для візуалізації результатів виявлення та відстеження дронів.
    """

    def __init__(self, output_dir='visualization_results'):
        """
        Ініціалізація візуалізатора результатів.

        Параметри:
        -----------
        output_dir : str
            Директорія для збереження результатів візуалізації
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)

        # Створення піддиректорій для різних типів візуалізації
        self.images_dir = self.output_dir / 'images'
        self.charts_dir = self.output_dir / 'charts'
        self.heatmaps_dir = self.output_dir / 'heatmaps'
        self.trajectories_dir = self.output_dir / 'trajectories'
        self.interactive_dir = self.output_dir / 'interactive'

        for directory in [self.images_dir, self.charts_dir, self.heatmaps_dir,
                          self.trajectories_dir, self.interactive_dir]:
            directory.mkdir(exist_ok=True)

        # Настройки для палітр кольорів
        self.detection_colors = {
            0: (0, 255, 0),    # Зелений для основного класу (дрон)
            1: (0, 0, 255),    # Червоний для інших класів
            2: (255, 0, 0),    # Синій
            3: (255, 255, 0),  # Блакитний
            4: (0, 255, 255),  # Жовтий
            5: (255, 0, 255)   # Пурпурний
        }

        # Стилі для візуалізації
        plt.style.use('ggplot')

        # Налаштування для інтерактивних графіків
        self.plotly_config = {'responsive': True}

    def visualize_detection(self, image, detections, class_names=None, confidence_threshold=0.25,
                           thickness=2, font_scale=0.6, output_path=None):
        """
        Візуалізація виявлених дронів на зображенні.

        Параметри:
        -----------
        image : numpy.ndarray або str
            Зображення або шлях до зображення
        detections : list
            Список виявлень у форматі [[x1, y1, x2, y2, conf, class_id], ...]
        class_names : list, опціонально
            Список назв класів
        confidence_threshold : float
            Поріг впевненості для відображення виявлень
        thickness : int
            Товщина ліній обмежувальних рамок
        font_scale : float
            Розмір шрифту для підписів
        output_path : str, опціонально
            Шлях для збереження результату

        Повертає:
        -----------
        numpy.ndarray : Зображення з візуалізованими виявленнями
        """
        # Завантаження зображення, якщо передано шлях
        if isinstance(image, str):
            image = cv2.imread(image)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # Створення копії зображення
        output_image = image.copy()

        # Фільтрація виявлень за порогом впевненості
        filtered_detections = [det for det in detections if det[4] >= confidence_threshold]

        # Візуалізація виявлень
        for detection in filtered_detections:
            x1, y1, x2, y2, confidence, class_id = detection

            # Перетворення в цілі числа
            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
            class_id = int(class_id)

            # Вибір кольору залежно від класу
            color = self.detection_colors.get(class_id, (0, 255, 0))

            # Малювання обмежувальної рамки
            cv2.rectangle(output_image, (x1, y1), (x2, y2), color, thickness)

            # Отримання назви класу
            if class_names is not None and class_id < len(class_names):
                class_name = class_names[class_id]
            else:
                class_name = f"Клас {class_id}"

            # Формування тексту підпису
            label = f"{class_name} {confidence:.2f}"

            # Розрахунок розміру тексту
            (text_width, text_height), baseline = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)

            # Малювання фону для тексту
            cv2.rectangle(output_image, (x1, y1 - text_height - baseline),
                         (x1 + text_width, y1), color, -1)

            # Малювання тексту
            cv2.putText(output_image, label, (x1, y1 - baseline),
                       cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), thickness)

        # Додавання інформації про кількість виявлень
        info_text = f"Виявлено об'єктів: {len(filtered_detections)}"
        cv2.putText(output_image, info_text, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)

        # Збереження результату
        if output_path is not None:
            if output_path.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
                # Конвертація з RGB в BGR для збереження через OpenCV
                output_image_bgr = cv2.cvtColor(output_image, cv2.COLOR_RGB2BGR)
                cv2.imwrite(output_path, output_image_bgr)
            else:
                output_path = str(self.images_dir / f"detection_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg")
                output_image_bgr = cv2.cvtColor(output_image, cv2.COLOR_RGB2BGR)
                cv2.imwrite(output_path, output_image_bgr)
            print(f"Зображення з виявленнями збережено у: {output_path}")

        return output_image

    def visualize_detection_batch(self, image_paths, detector, confidence_threshold=0.25,
                                 max_images=10, class_names=None, output_dir=None):
        """
        Візуалізація виявлень для набору зображень.

        Параметри:
        -----------
        image_paths : list
            Список шляхів до зображень
        detector : object
            Об'єкт детектора з методом detect
        confidence_threshold : float
            Поріг впевненості для відображення виявлень
        max_images : int
            Максимальна кількість зображень для обробки
        class_names : list, опціонально
            Список назв класів
        output_dir : str, опціонально
            Директорія для збереження результатів

        Повертає:
        -----------
        list : Список шляхів до збережених зображень
        """
        if len(image_paths) > max_images:
            print(f"Обмеження кількості зображень до {max_images} з {len(image_paths)}")
            image_paths = image_paths[:max_images]

        # Створення директорії для результатів
        if output_dir is None:
            output_dir = self.images_dir / f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        else:
            output_dir = Path(output_dir)

        output_dir.mkdir(exist_ok=True)

        output_paths = []

        # Обробка кожного зображення
        for i, image_path in enumerate(tqdm(image_paths, desc="Візуалізація виявлень")):
            # Завантаження зображення
            image = cv2.imread(image_path)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

            # Виявлення об'єктів
            detection_results = detector.detect(image_path, conf=confidence_threshold)

            # Отримання обмежувальних рамок
            detections = []
            if len(detection_results) > 0:
                boxes = detection_results[0].boxes
                for box in boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    conf = box.conf[0].cpu().numpy()
                    cls = box.cls[0].cpu().numpy()
                    detections.append([x1, y1, x2, y2, conf, cls])

            # Візуалізація виявлень
            output_path = output_dir / f"detection_{i:04d}.jpg"
            self.visualize_detection(
                image, detections, class_names, confidence_threshold,
                output_path=str(output_path)
            )

            output_paths.append(str(output_path))

        print(f"Візуалізацію завершено. Збережено {len(output_paths)} зображень у {output_dir}")
        return output_path

    def create_geospatial_visualization(self, coordinates_data, output_path=None,
                                     base_map='OpenStreetMap', zoom_start=12, include_heatmap=True):
        """
        Створення геопросторової візуалізації виявлень дронів.

        Параметри:
        -----------
        coordinates_data : list
            Список координат виявлень у форматі [(lat, lon, weight), ...]
        output_path : str, опціонально
            Шлях для збереження HTML-файлу з картою
        base_map : str
            Тип базової карти ('OpenStreetMap', 'Stamen Terrain', 'Stamen Toner')
        zoom_start : int
            Початковий рівень масштабування карти
        include_heatmap : bool
            Включити теплову карту розподілу виявлень

        Повертає:
        -----------
        folium.Map : Об'єкт карти
        """
        if not coordinates_data:
            print("Немає даних координат для візуалізації")
            return None

        # Визначення центральної точки карти
        center_lat = sum(lat for lat, _, _ in coordinates_data) / len(coordinates_data)
        center_lon = sum(lon for _, lon, _ in coordinates_data) / len(coordinates_data)

        # Створення карти
        m = folium.Map(location=[center_lat, center_lon], zoom_start=zoom_start, tiles=base_map)

        # Додавання маркерів для кожного виявлення
        for lat, lon, weight in coordinates_data:
            popup_text = f"Впевненість: {weight:.3f}"

            # Визначення кольору маркера залежно від ваги
            if weight > 0.7:
                color = 'red'
            elif weight > 0.5:
                color = 'orange'
            else:
                color = 'blue'

            folium.Marker(
                location=[lat, lon],
                popup=popup_text,
                icon=folium.Icon(color=color, icon='plane')
            ).add_to(m)

        # Додавання теплової карти, якщо потрібно
        if include_heatmap:
            # Підготовка даних для теплової карти
            heat_data = [[lat, lon, min(weight * 10, 1)] for lat, lon, weight in coordinates_data]

            # Додавання теплової карти
            HeatMap(heat_data, radius=15).add_to(m)

        # Додавання елементів керування шарами
        folium.LayerControl().add_to(m)

        # Збереження карти
        if output_path is None:
            output_path = str(self.interactive_dir / f"geospatial_map_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html")

        m.save(output_path)
        print(f"Геопросторову візуалізацію збережено у: {output_path}")

        return m


# Приклад використання:
# visualizer = ResultsVisualizer()
#
# # Візуалізація виявлень на зображенні
# image = cv2.imread('test_image.jpg')
# detections = [[100, 100, 200, 200, 0.8, 0], [300, 300, 400, 400, 0.6, 0]]
# visualizer.visualize_detection(image, detections, output_path='detection_result.jpg')
#
# # Створення теплової карти
# frame_shape = (720, 1280)
# visualizer.generate_heatmap(detections, frame_shape, output_path='heatmap.jpg')
#
# # Візуалізація шляхів відстеження
# tracking_data = [...]  # Дані відстеження
# visualizer.visualize_tracking_paths(tracking_data, frame_shape, output_path='tracking_paths.jpg')
#
# # Створення інтерактивного графіка
# visualizer.create_interactive_trajectory_plot(tracking_data, output_path='interactive_plot.html')s

    def plot_confidence_distribution(self, detections, output_path=None, bins=20, class_names=None):
        """
        Побудова гістограми розподілу впевненості виявлень.

        Параметри:
        -----------
        detections : list
            Список виявлень у форматі [[x1, y1, x2, y2, conf, class_id], ...]
        output_path : str, опціонально
            Шлях для збереження графіка
        bins : int
            Кількість інтервалів для гістограми
        class_names : list, опціонально
            Список назв класів

        Повертає:
        -----------
        matplotlib.figure.Figure : Фігура з гістограмою
        """
        if not detections:
            print("Немає виявлень для аналізу")
            return None

        # Отримання значень впевненості
        confidences = [det[4] for det in detections]

        # Створення гістограми
        plt.figure(figsize=(10, 6))

        # Побудова гістограми
        n, bins, patches = plt.hist(confidences, bins=bins, alpha=0.7, color='skyblue',
                                   edgecolor='black')

        # Додавання середньої лінії
        plt.axvline(np.mean(confidences), color='red', linestyle='dashed', linewidth=2,
                   label=f'Середнє: {np.mean(confidences):.3f}')

        # Додавання медіанної лінії
        plt.axvline(np.median(confidences), color='green', linestyle='dashed', linewidth=2,
                   label=f'Медіана: {np.median(confidences):.3f}')

        # Налаштування графіка
        plt.title('Розподіл впевненості виявлень', fontsize=14)
        plt.xlabel('Впевненість', fontsize=12)
        plt.ylabel('Кількість виявлень', fontsize=12)
        plt.grid(axis='y', alpha=0.75)
        plt.legend()

        # Додавання статистичної інформації
        stats_text = (
            f"Мін: {min(confidences):.3f}\n"
            f"Макс: {max(confidences):.3f}\n"
            f"Середнє: {np.mean(confidences):.3f}\n"
            f"Медіана: {np.median(confidences):.3f}\n"
            f"Станд. відх.: {np.std(confidences):.3f}"
        )
        plt.annotate(stats_text, xy=(0.02, 0.95), xycoords='axes fraction',
                    bbox=dict(boxstyle="round,pad=0.3", edgecolor="gray", facecolor="white", alpha=0.8))

        # Збереження графіка
        if output_path is None:
            output_path = str(self.charts_dir / f"confidence_distribution_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png")

        plt.tight_layout()
        plt.savefig(output_path)
        print(f"Гістограму розподілу впевненості збережено у: {output_path}")

        return plt.gcf()

    def plot_size_distribution(self, detections, output_path=None, class_names=None):
        """
        Побудова розподілу розмірів виявлених об'єктів.

        Параметри:
        -----------
        detections : list
            Список виявлень у форматі [[x1, y1, x2, y2, conf, class_id], ...]
        output_path : str, опціонально
            Шлях для збереження графіка
        class_names : list, опціонально
            Список назв класів

        Повертає:
        -----------
        matplotlib.figure.Figure : Фігура з графіком
        """
        if not detections:
            print("Немає виявлень для аналізу")
            return None

        # Розрахунок розмірів об'єктів
        widths = []
        heights = []
        areas = []
        aspect_ratios = []

        for det in detections:
            x1, y1, x2, y2 = det[0], det[1], det[2], det[3]
            width = x2 - x1
            height = y2 - y1
            area = width * height
            aspect_ratio = width / height if height > 0 else 0

            widths.append(width)
            heights.append(height)
            areas.append(area)
            aspect_ratios.append(aspect_ratio)

        # Створення фігури з підграфіками
        fig, axs = plt.subplots(2, 2, figsize=(14, 10))

        # Гістограма ширин
        axs[0, 0].hist(widths, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
        axs[0, 0].set_title('Розподіл ширин об\'єктів', fontsize=12)
        axs[0, 0].set_xlabel('Ширина (пікселі)', fontsize=10)
        axs[0, 0].set_ylabel('Кількість', fontsize=10)
        axs[0, 0].grid(axis='y', alpha=0.75)

        # Гістограма висот
        axs[0, 1].hist(heights, bins=20, alpha=0.7, color='lightgreen', edgecolor='black')
        axs[0, 1].set_title('Розподіл висот об\'єктів', fontsize=12)
        axs[0, 1].set_xlabel('Висота (пікселі)', fontsize=10)
        axs[0, 1].set_ylabel('Кількість', fontsize=10)
        axs[0, 1].grid(axis='y', alpha=0.75)

        # Гістограма площ
        axs[1, 0].hist(areas, bins=20, alpha=0.7, color='salmon', edgecolor='black')
        axs[1, 0].set_title('Розподіл площ об\'єктів', fontsize=12)
        axs[1, 0].set_xlabel('Площа (пікселі²)', fontsize=10)
        axs[1, 0].set_ylabel('Кількість', fontsize=10)
        axs[1, 0].grid(axis='y', alpha=0.75)

        # Гістограма співвідношень сторін
        axs[1, 1].hist(aspect_ratios, bins=20, alpha=0.7, color='plum', edgecolor='black')
        axs[1, 1].set_title('Розподіл співвідношень сторін', fontsize=12)
        axs[1, 1].set_xlabel('Співвідношення сторін (ширина/висота)', fontsize=10)
        axs[1, 1].set_ylabel('Кількість', fontsize=10)
        axs[1, 1].grid(axis='y', alpha=0.75)

        # Додавання статистичної інформації
        fig.suptitle('Аналіз розмірів виявлених об\'єктів', fontsize=16)

        # Додавання загальної статистики
        stats_text = (
            f"Середня ширина: {np.mean(widths):.1f} пікс\n"
            f"Середня висота: {np.mean(heights):.1f} пікс\n"
            f"Середня площа: {np.mean(areas):.1f} пікс²\n"
            f"Середнє співвідношення: {np.mean(aspect_ratios):.2f}\n"
            f"Всього об'єктів: {len(detections)}"
        )

        fig.text(0.5, 0.02, stats_text, ha='center',
                bbox=dict(boxstyle="round,pad=0.3", edgecolor="gray",
                         facecolor="white", alpha=0.8))

        # Збереження графіка
        if output_path is None:
            output_path = str(self.charts_dir / f"size_distribution_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png")

        plt.tight_layout(rect=[0, 0.05, 1, 0.95])
        plt.savefig(output_path)
        print(f"Графік розподілу розмірів збережено у: {output_path}")

        return fig

    def generate_heatmap(self, detections, frame_shape, confidence_threshold=0.25,
                        sigma=15, class_id=None, output_path=None, overlay_image=None):
        """
        Генерація теплової карти розподілу виявлень.

        Параметри:
        -----------
        detections : list
            Список виявлень у форматі [[x1, y1, x2, y2, conf, class_id], ...]
        frame_shape : tuple
            Розмір кадру (висота, ширина)
        confidence_threshold : float
            Поріг впевненості для врахування виявлень
        sigma : float
            Сигма для розмиття Гауса (визначає розмір плям на тепловій карті)
        class_id : int, опціонально
            Ідентифікатор класу для фільтрації (None = всі класи)
        output_path : str, опціонально
            Шлях для збереження теплової карти
        overlay_image : numpy.ndarray, опціонально
            Зображення для накладання теплової карти

        Повертає:
        -----------
        numpy.ndarray : Теплова карта або накладена теплова карта
        """
        # Фільтрація виявлень за впевненістю та класом
        filtered_detections = []
        for det in detections:
            if det[4] >= confidence_threshold:
                if class_id is None or int(det[5]) == class_id:
                    filtered_detections.append(det)

        if not filtered_detections:
            print("Немає виявлень, які відповідають критеріям фільтрації")
            return None

        # Створення порожньої теплової карти
        height, width = frame_shape[:2]
        heatmap = np.zeros((height, width), dtype=np.float32)

        # Додавання виявлень до теплової карти
        for det in filtered_detections:
            x1, y1, x2, y2, conf, _ = det

            # Розрахунок центроїда
            center_x = int((x1 + x2) / 2)
            center_y = int((y1 + y2) / 2)

            # Додавання до теплової карти (з урахуванням впевненості)
            if 0 <= center_x < width and 0 <= center_y < height:
                heatmap[center_y, center_x] += conf

        # Розмиття теплової карти для покращення візуалізації
        if sigma > 0:
            heatmap = cv2.GaussianBlur(heatmap, (0, 0), sigma)

        # Нормалізація теплової карти
        if np.max(heatmap) > 0:
            heatmap = heatmap / np.max(heatmap)

        # Перетворення теплової карти в кольорове зображення
        heatmap_colored = cv2.applyColorMap((heatmap * 255).astype(np.uint8), cv2.COLORMAP_JET)

        # Накладання теплової карти на зображення, якщо передано
        if overlay_image is not None:
            # Переконаємося, що розміри співпадають
            if overlay_image.shape[:2] != (height, width):
                overlay_image = cv2.resize(overlay_image, (width, height))

            # Накладання теплової карти на зображення
            alpha = 0.6  # Прозорість теплової карти
            output_image = cv2.addWeighted(overlay_image, 1 - alpha, heatmap_colored, alpha, 0)

            # Збереження результату
            if output_path is not None:
                cv2.imwrite(output_path, output_image)
                print(f"Накладену теплову карту збережено у: {output_path}")

            return output_image
        else:
            # Збереження теплової карти
            if output_path is not None:
                cv2.imwrite(output_path, heatmap_colored)
                print(f"Теплову карту збережено у: {output_path}")

            return heatmap_colored

    def generate_heatmap_from_tracking(self, tracking_data, frame_shape, min_confidence=0.5,
                                      sigma=15, class_id=None, output_path=None, overlay_image=None):
        """
        Генерація теплової карти з даних відстеження.

        Параметри:
        -----------
        tracking_data : list
            Список словників з даними треків для кожного кадру
        frame_shape : tuple
            Розмір кадру (висота, ширина)
        min_confidence : float
            Мінімальний рівень впевненості для врахування треку
        sigma : float
            Сигма для розмиття Гауса
        class_id : int, опціонально
            Ідентифікатор класу для фільтрації
        output_path : str, опціонально
            Шлях для збереження теплової карти
        overlay_image : numpy.ndarray, опціонально
            Зображення для накладання теплової карти

        Повертає:
        -----------
        numpy.ndarray : Теплова карта або накладена теплова карта
        """
        # Створення порожньої теплової карти
        height, width = frame_shape[:2]
        heatmap = np.zeros((height, width), dtype=np.float32)

        # Додавання даних треків до теплової карти
        for frame_data in tracking_data:
            for track in frame_data['tracks']:
                # Фільтрація за впевненістю
                if track['confidence'] < min_confidence:
                    continue

                # Фільтрація за класом, якщо вказано
                if class_id is not None and track['class_id'] != class_id:
                    continue

                # Отримання обмежувальної рамки
                x1, y1, x2, y2 = map(int, track['box'])

                # Розрахунок центроїда
                center_x = int((x1 + x2) / 2)
                center_y = int((y1 + y2) / 2)

                # Додавання до теплової карти (з урахуванням впевненості)
                if 0 <= center_x < width and 0 <= center_y < height:
                    heatmap[center_y, center_x] += track['confidence']

        # Розмиття теплової карти для покращення візуалізації
        if sigma > 0:
            heatmap = cv2.GaussianBlur(heatmap, (0, 0), sigma)

        # Нормалізація теплової карти
        if np.max(heatmap) > 0:
            heatmap = heatmap / np.max(heatmap)

        # Перетворення теплової карти в кольорове зображення
        heatmap_colored = cv2.applyColorMap((heatmap * 255).astype(np.uint8), cv2.COLORMAP_JET)

        # Накладання теплової карти на зображення, якщо передано
        if overlay_image is not None:
            # Переконаємося, що розміри співпадають
            if overlay_image.shape[:2] != (height, width):
                overlay_image = cv2.resize(overlay_image, (width, height))

            # Накладання теплової карти на зображення
            alpha = 0.6  # Прозорість теплової карти
            output_image = cv2.addWeighted(overlay_image, 1 - alpha, heatmap_colored, alpha, 0)

            # Збереження результату
            if output_path is not None:
                cv2.imwrite(output_path, output_image)
                print(f"Накладену теплову карту збережено у: {output_path}")

            return output_image
        else:
            # Збереження теплової карти
            if output_path is not None:
                cv2.imwrite(output_path, heatmap_colored)
                print(f"Теплову карту збережено у: {output_path}")

            return heatmap_colored

    def visualize_tracking_paths(self, tracking_data, frame_shape, min_track_length=5,
                               output_path=None, overlay_image=None, class_names=None,
                               line_thickness=2, show_points=True):
        """
        Візуалізація шляхів переміщення дронів за даними відстеження.

        Параметри:
        -----------
        tracking_data : list
            Список словників з даними треків для кожного кадру
        frame_shape : tuple
            Розмір кадру (висота, ширина)
        min_track_length : int
            Мінімальна довжина треку для відображення
        output_path : str, опціонально
            Шлях для збереження візуалізації
        overlay_image : numpy.ndarray, опціонально
            Зображення для накладання шляхів
        class_names : list, опціонально
            Список назв класів
        line_thickness : int
            Товщина ліній шляхів
        show_points : bool
            Показувати точки на шляху

        Повертає:
        -----------
        numpy.ndarray : Зображення з візуалізованими шляхами
        """
        # Створення порожнього зображення
        height, width = frame_shape[:2]
        if overlay_image is not None:
            # Переконаємося, що розміри співпадають
            if overlay_image.shape[:2] != (height, width):
                overlay_image = cv2.resize(overlay_image, (width, height))
            vis_image = overlay_image.copy()
        else:
            vis_image = np.ones((height, width, 3), dtype=np.uint8) * 255

        # Структурування даних за треками
        tracks_by_id = {}

        for frame_data in tracking_data:
            for track in frame_data['tracks']:
                track_id = track['track_id']

                if track_id not in tracks_by_id:
                    tracks_by_id[track_id] = {
                        'centroids': [],
                        'confidences': [],
                        'class_id': track['class_id'],
                        'state': track['state']
                    }

                # Отримання обмежувальної рамки
                x1, y1, x2, y2 = track['box']

                # Розрахунок центроїда
                center_x = (x1 + x2) / 2
                center_y = (y1 + y2) / 2

                tracks_by_id[track_id]['centroids'].append((center_x, center_y))
                tracks_by_id[track_id]['confidences'].append(track['confidence'])
                tracks_by_id[track_id]['state'] = track['state']  # Оновлення поточного стану

        # Фільтрація коротких треків
        tracks_by_id = {track_id: data for track_id, data in tracks_by_id.items()
                       if len(data['centroids']) >= min_track_length}

        # Кольорова карта для треків
        cmap = plt.cm.get_cmap('hsv', len(tracks_by_id) + 1)

        # Візуалізація треків
        for i, (track_id, track_data) in enumerate(tracks_by_id.items()):
            # Отримання кольору
            color = tuple(int(c * 255) for c in cmap(i)[:3])

            # Малювання шляху
            centroids = track_data['centroids']
            for j in range(1, len(centroids)):
                pt1 = tuple(map(int, centroids[j-1]))
                pt2 = tuple(map(int, centroids[j]))

                # Малювання лінії
                cv2.line(vis_image, pt1, pt2, color, line_thickness)

                # Малювання точок
                if show_points:
                    cv2.circle(vis_image, pt2, 3, color, -1)

            # Малювання початкової та кінцевої точок
            start_point = tuple(map(int, centroids[0]))
            end_point = tuple(map(int, centroids[-1]))

            cv2.circle(vis_image, start_point, 7, (0, 255, 0), -1)  # Зелений для початку
            cv2.circle(vis_image, end_point, 7, (0, 0, 255), -1)    # Червоний для кінця

            # Додавання ідентифікатора треку
            class_name = ""
            if class_names is not None and track_data['class_id'] < len(class_names):
                class_name = class_names[track_data['class_id']]

            label = f"ID: {track_id}"
            if class_name:
                label += f" ({class_name})"

            cv2.putText(vis_image, label, (end_point[0] + 10, end_point[1]),
                      cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

        # Додавання інформації про кількість треків
        info_text = f"Кількість треків: {len(tracks_by_id)}"
        cv2.putText(vis_image, info_text, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)

        # Збереження результату
        if output_path is not None:
            cv2.imwrite(output_path, vis_image)
            print(f"Візуалізацію шляхів збережено у: {output_path}")

        return vis_image

    def visualize_tracking_animation(self, tracking_data, background_image,
                                    output_path=None, fps=10, class_names=None):
        """
        Створення анімації руху дронів за даними відстеження.

        Параметри:
        -----------
        tracking_data : list
            Список словників з даними треків для кожного кадру
        background_image : numpy.ndarray
            Фонове зображення для анімації
        output_path : str, опціонально
            Шлях для збереження анімації
        fps : int
            Кількість кадрів на секунду в анімації
        class_names : list, опціонально
            Список назв класів

        Повертає:
        -----------
        matplotlib.animation.FuncAnimation : Об'єкт анімації
        """
        # Переконаємося, що у нас є якісь дані для відстеження
        if not tracking_data:
            print("Немає даних відстеження для анімації")
            return None

        # Створення фігури
        fig, ax = plt.subplots(figsize=(12, 8))

        # Відображення фонового зображення
        if background_image is not None:
            ax.imshow(background_image)
        else:
            ax.set_xlim(0, 1280)  # За замовчуванням
            ax.set_ylim(0, 720)   # За замовчуванням

        # Організація даних за кадрами
        frames_data = {}
        max_frame = 0

        for frame_data in tracking_data:
            frame_num = frame_data['frame']
            frames_data[frame_num] = frame_data['tracks']
            max_frame = max(max_frame, frame_num)

        # Створення словника для зберігання даних об'єктів в анімації
        plot_objects = {}

        # Функція для оновлення кадру анімації
        def update(frame):
            # Очищення попередніх об'єктів
            for obj_list in plot_objects.values():
                for obj in obj_list:
                    if obj is not None:
                        obj.remove()
            plot_objects.clear()

            # Відображення поточного кадру
            ax.set_title(f"Кадр: {frame}")

            # Перевірка, чи є дані для цього кадру
            if frame not in frames_data:
                return []

            # Отримання даних треків для поточного кадру
            current_tracks = frames_data[frame]

            for track in current_tracks:
                track_id = track['track_id']
                box = track['box']
                conf = track['confidence']
                class_id = track['class_id']

                # Розрахунок центроїда
                center_x = (box[0] + box[2]) / 2
                center_y = (box[1] + box[3]) / 2

                # Створення об'єктів для відображення
                if track_id not in plot_objects:
                    plot_objects[track_id] = []

                # Вибір кольору
                color = plt.cm.hsv(track_id / (len(frames_data) + 1))

                # Малювання обмежувальної рамки
                rect = patches.Rectangle(
                    (box[0], box[1]), box[2] - box[0], box[3] - box[1],
                    linewidth=1, edgecolor=color, facecolor='none'
                )
                ax.add_patch(rect)
                plot_objects[track_id].append(rect)

                # Малювання центроїда
                dot = ax.scatter(center_x, center_y, c=[color], s=50, marker='o')
                plot_objects[track_id].append(dot)

                # Додавання тексту
                class_name = ""
                if class_names is not None and class_id < len(class_names):
                    class_name = class_names[class_id]

                text = f"ID: {track_id} {conf:.2f}"
                if class_name:
                    text += f"\n{class_name}"

                txt = ax.text(box[0], box[1] - 10, text,
                            bbox=dict(facecolor=color, alpha=0.5), color='white')
                plot_objects[track_id].append(txt)

            return list(plot_objects.values())

        # Створення анімації
        anim = FuncAnimation(
            fig, update, frames=range(max_frame + 1),
            interval=1000/fps, blit=False
        )

        # Збереження анімації
        if output_path is not None:
            anim.save(output_path, writer='pillow', fps=fps)
            print(f"Анімацію відстеження збережено у: {output_path}")

        return anim

    def plot_metrics_over_time(self, metrics_data, metric_names, output_path=None):
        """
        Побудова графіків метрик продуктивності моделі з часом.

        Параметри:
        -----------
        metrics_data : dict
            Словник з даними метрик у форматі {метрика: [значення для різних періодів]}
        metric_names : list
            Список назв метрик для відображення
        output_path : str, опціонально
            Шлях для збереження графіка

        Повертає:
        -----------
        matplotlib.figure.Figure : Фігура з графіками
        """
        # Перевірка даних
        if not metrics_data or not metric_names:
            print("Немає даних метрик для відображення")
            return None

        # Створення фігури
        fig, ax = plt.subplots(figsize=(12, 8))

        # Побудова графіків для кожної метрики
        for metric_name in metric_names:
            if metric_name in metrics_data:
                ax.plot(metrics_data[metric_name], label=metric_name)

        # Налаштування графіка
        ax.set_title('Динаміка метрик продуктивності з часом', fontsize=14)
        ax.set_xlabel('Період', fontsize=12)
        ax.set_ylabel('Значення метрики', fontsize=12)
        ax.grid(True, alpha=0.3)
        ax.legend()

        # Додавання сітки
        ax.grid(True, linestyle='--', alpha=0.7)

        # Збереження графіка
        if output_path is None:
            output_path = str(self.charts_dir / f"metrics_over_time_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png")

        plt.tight_layout()
        plt.savefig(output_path)
        print(f"Графік метрик збережено у: {output_path}")

        return fig

    def plot_confusion_matrix(self, conf_matrix, class_names=None, output_path=None):
        """
        Візуалізація матриці помилок.

        Параметри:
        -----------
        conf_matrix : numpy.ndarray
            Матриця помилок
        class_names : list, опціонально
            Список назв класів
        output_path : str, опціонально
            Шлях для збереження матриці помилок

        Повертає:
        -----------
        matplotlib.figure.Figure : Фігура з матрицею помилок
        """
        # Перевірка даних
        if conf_matrix is None or conf_matrix.size == 0:
            print("Немає даних для побудови матриці помилок")
            return None

        # Нормалізація матриці
        conf_matrix_norm = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]

        # Створення фігури
        fig, ax = plt.subplots(figsize=(10, 8))

        # Використання seaborn для гарного відображення
        sns.heatmap(conf_matrix_norm, annot=conf_matrix, fmt='d', cmap='Blues',
                   xticklabels=class_names, yticklabels=class_names, ax=ax)

        # Налаштування графіка
        ax.set_title('Матриця помилок', fontsize=14)
        ax.set_xlabel('Передбачені класи', fontsize=12)
        ax.set_ylabel('Фактичні класи', fontsize=12)

        # Збереження графіка
        if output_path is None:
            output_path = str(self.charts_dir / f"confusion_matrix_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png")

        plt.tight_layout()
        plt.savefig(output_path)
        print(f"Матрицю помилок збережено у: {output_path}")

        return fig

    def create_interactive_detection_timeline(self, tracking_data, output_path=None, class_names=None):
        """
        Створення інтерактивного графіка з часовою лінією виявлень.

        Параметри:
        -----------
        tracking_data : list
            Список словників з даними треків для кожного кадру
        output_path : str, опціонально
            Шлях для збереження HTML-файлу з графіком
        class_names : list, опціонально
            Список назв класів

        Повертає:
        -----------
        plotly.graph_objects.Figure : Інтерактивний графік
        """
        if not tracking_data:
            print("Немає даних відстеження для візуалізації")
            return None

        # Підготовка даних для графіка
        track_data = []

        for frame_data in tracking_data:
            frame_num = frame_data['frame']
            timestamp = frame_data.get('timestamp', frame_num)

            for track in frame_data['tracks']:
                track_id = track['track_id']
                confidence = track['confidence']
                class_id = track['class_id']

                # Отримання назви класу
                class_name = f"Клас {class_id}"
                if class_names is not None and class_id < len(class_names):
                    class_name = class_names[class_id]

                # Додавання даних для графіка
                track_data.append({
                    'frame': frame_num,
                    'timestamp': timestamp,
                    'track_id': track_id,
                    'confidence': confidence,
                    'class_id': class_id,
                    'class_name': class_name
                })

        # Створення DataFrame
        df = pd.DataFrame(track_data)

        # Створення інтерактивного графіка
        fig = make_subplots(rows=2, cols=1,
                           subplot_titles=("Часова лінія виявлень", "Розподіл впевненості"),
                           row_heights=[0.7, 0.3])

        # Додавання даних для основного графіка
        for track_id in df['track_id'].unique():
            track_df = df[df['track_id'] == track_id]

            fig.add_trace(
                go.Scatter(
                    x=track_df['timestamp'],
                    y=[track_id] * len(track_df),
                    mode='markers+lines',
                    name=f'Трек {track_id}',
                    marker=dict(
                        size=10,
                        color=track_df['confidence'],
                        colorscale='YlOrRd',
                        showscale=False
                    ),
                    text=[f"ID: {track_id}<br>Кадр: {row['frame']}<br>"
                          f"Клас: {row['class_name']}<br>"
                          f"Впевненість: {row['confidence']:.3f}"
                          for _, row in track_df.iterrows()],
                    hoverinfo='text'
                ),
                row=1, col=1
            )

        # Додавання гістограми розподілу впевненості
        fig.add_trace(
            go.Histogram(
                x=df['confidence'],
                nbinsx=20,
                marker_color='rgba(0, 128, 255, 0.7)',
                name='Розподіл впевненості'
            ),
            row=2, col=1
        )

        # Налаштування графіка
        fig.update_layout(
            title='Інтерактивна часова лінія виявлень дронів',
            xaxis=dict(title='Час/Кадр'),
            yaxis=dict(title='ID треку'),
            xaxis2=dict(title='Впевненість'),
            yaxis2=dict(title='Кількість'),
            hovermode='closest',
            height=800,
            showlegend=False
        )

        # Збереження графіка як HTML
        if output_path is None:
            output_path = str(self.interactive_dir / f"detection_timeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html")

        fig.write_html(output_path, config=self.plotly_config)
        print(f"Інтерактивний графік збережено у: {output_path}")

        return fig

    def create_interactive_trajectory_plot(self, tracking_data, background_image=None,
                                        output_path=None, class_names=None):
        """
        Створення інтерактивного графіка з траєкторіями руху дронів.

        Параметри:
        -----------
        tracking_data : list
            Список словників з даними треків для кожного кадру
        background_image : numpy.ndarray або str, опціонально
            Фонове зображення або шлях до нього
        output_path : str, опціонально
            Шлях для збереження HTML-файлу з графіком
        class_names : list, опціонально
            Список назв класів

        Повертає:
        -----------
        plotly.graph_objects.Figure : Інтерактивний графік
        """
        if not tracking_data:
            print("Немає даних відстеження для візуалізації")
            return None

        # Структурування даних за треками
        tracks_by_id = {}

        for frame_data in tracking_data:
            for track in frame_data['tracks']:
                track_id = track['track_id']

                if track_id not in tracks_by_id:
                    tracks_by_id[track_id] = {
                        'frames': [],
                        'timestamps': [],
                        'centroids': [],
                        'confidences': [],
                        'class_id': track['class_id'],
                        'boxes': []
                    }

                # Отримання обмежувальної рамки
                x1, y1, x2, y2 = track['box']

                # Розрахунок центроїда
                center_x = (x1 + x2) / 2
                center_y = (y1 + y2) / 2

                tracks_by_id[track_id]['frames'].append(frame_data['frame'])
                tracks_by_id[track_id]['timestamps'].append(frame_data.get('timestamp', frame_data['frame']))
                tracks_by_id[track_id]['centroids'].append((center_x, center_y))
                tracks_by_id[track_id]['confidences'].append(track['confidence'])
                tracks_by_id[track_id]['boxes'].append(track['box'])

        # Створення фігури
        fig = go.Figure()

        # Додавання фонового зображення, якщо воно доступне
        if background_image is not None:
            if isinstance(background_image, str):
                # Завантаження зображення з файлу
                img = Image.open(background_image)
                background_image = np.array(img)

            # Кодування зображення в base64 для відображення
            height, width = background_image.shape[:2]

            # Перетворення з RGB в BGR, якщо потрібно
            if background_image.ndim == 3 and background_image.shape[2] == 3:
                background_image = cv2.cvtColor(background_image, cv2.COLOR_RGB2BGR)

            # Кодування зображення
            img_byte_arr = BytesIO()
            Image.fromarray(background_image).save(img_byte_arr, format='JPEG')
            encoded_image = base64.b64encode(img_byte_arr.getvalue()).decode('ascii')

            # Додавання зображення на задній план
            fig.add_layout_image(
                dict(
                    source=f'data:image/jpeg;base64,{encoded_image}',
                    x=0,
                    y=0,
                    xref="x",
                    yref="y",
                    sizex=width,
                    sizey=height,
                    sizing="stretch",
                    opacity=0.7,
                    layer="below"
                )
            )

            # Налаштування меж графіка
            fig.update_layout(
                xaxis=dict(range=[0, width], autorange=False),
                yaxis=dict(range=[height, 0], autorange=False),
                width=width,
                height=height
            )

        # Додавання траєкторій руху для кожного треку
        for track_id, track_data in tracks_by_id.items():
            if len(track_data['centroids']) < 2:
                continue

            # Отримання назви класу
            class_id = track_data['class_id']
            class_name = f"Клас {class_id}"
            if class_names is not None and class_id < len(class_names):
                class_name = class_names[class_id]

            # Розпакування центроїдів
            x_coords = [point[0] for point in track_data['centroids']]
            y_coords = [point[1] for point in track_data['centroids']]

            # Створення тексту для спливаючих підказок
            hover_texts = []
            for i in range(len(track_data['frames'])):
                frame = track_data['frames'][i]
                conf = track_data['confidences'][i]
                timestamp = track_data['timestamps'][i]

                hover_texts.append(
                    f"ID: {track_id}<br>"
                    f"Клас: {class_name}<br>"
                    f"Кадр: {frame}<br>"
                    f"Час: {timestamp:.2f}<br>"
                    f"Впевненість: {conf:.3f}<br>"
                    f"X: {x_coords[i]:.1f}, Y: {y_coords[i]:.1f}"
                )

            # Додавання ліній траєкторії
            fig.add_trace(
                go.Scatter(
                    x=x_coords,
                    y=y_coords,
                    mode='lines+markers',
                    name=f'Трек {track_id} ({class_name})',
                    line=dict(width=2, color=px.colors.qualitative.Plotly[track_id % len(px.colors.qualitative.Plotly)]),
                    marker=dict(
                        size=6,
                        color=track_data['confidences'],
                        colorscale='YlOrRd',
                        showscale=False
                    ),
                    text=hover_texts,
                    hoverinfo='text'
                )
            )

            # Додавання початкової точки
            fig.add_trace(
                go.Scatter(
                    x=[x_coords[0]],
                    y=[y_coords[0]],
                    mode='markers',
                    marker=dict(
                        size=12,
                        color='green',
                        symbol='triangle-up'
                    ),
                    name=f'Початок треку {track_id}',
                    text=f"Початок треку {track_id}",
                    hoverinfo='text'
                )
            )

            # Додавання кінцевої точки
            fig.add_trace(
                go.Scatter(
                    x=[x_coords[-1]],
                    y=[y_coords[-1]],
                    mode='markers',
                    marker=dict(
                        size=12,
                        color='red',
                        symbol='triangle-down'
                    ),
                    name=f'Кінець треку {track_id}',
                    text=f"Кінець треку {track_id}",
                    hoverinfo='text'
                )
            )

        # Налаштування графіка
        fig.update_layout(
            title='Інтерактивна візуалізація траєкторій руху дронів',
            hovermode='closest',
            showlegend=True,
            legend=dict(
                x=1.05,
                y=1,
                xanchor='left',
                yanchor='top'
            )
        )

        # Збереження графіка як HTML
        if output_path is None:
            output_path = str(self.interactive_dir / f"trajectory_plot_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html")

        fig.write_html(output_path, config=self.plotly_config)
        print(f"Інтерактивний графік траєкторій збережено у: {output_path}")

        return fig

    def create_interactive_metrics_dashboard(self, metrics_data, output_path=None):
        """
        Створення інтерактивної панелі з метриками моделі.

        Параметри:
        -----------
        metrics_data : dict
            Словник з даними метрик
        output_path : str, опціонально
            Шлях для збереження HTML-файлу з панеллю

        Повертає:
        -----------
        plotly.graph_objects.Figure : Інтерактивний графік
        """
        if not metrics_data:
            print("Немає даних метрик для візуалізації")
            return None

        # Структурування даних для графіків
        metrics_over_time = {}
        latest_metrics = {}

        # Перевірка, чи є часові ряди
        has_time_series = False
        for metric_name, metric_value in metrics_data.items():
            if isinstance(metric_value, list):
                metrics_over_time[metric_name] = metric_value
                latest_metrics[metric_name] = metric_value[-1] if metric_value else 0
                has_time_series = True
            else:
                latest_metrics[metric_name] = metric_value

        # Створення фігури з підграфіками
        if has_time_series:
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=(
                    "Метрики з часом",
                    "Останні значення метрик",
                    "Порівняння метрик",
                    "Розподіл метрик"
                ),
                specs=[
                    [{"type": "scatter"}, {"type": "bar"}],
                    [{"type": "bar"}, {"type": "pie"}]
                ]
            )

            # Графік 1: Метрики з часом
            for metric_name, values in metrics_over_time.items():
                fig.add_trace(
                    go.Scatter(
                        x=list(range(len(values))),
                        y=values,
                        mode='lines+markers',
                        name=metric_name
                    ),
                    row=1, col=1
                )

            # Графік 2: Останні значення метрик (стовпчаста діаграма)
            fig.add_trace(
                go.Bar(
                    x=list(latest_metrics.keys()),
                    y=list(latest_metrics.values()),
                    marker_color=px.colors.qualitative.Plotly
                ),
                row=1, col=2
            )

            # Графік 3: Порівняння метрик (стовпчаста діаграма з групами)
            comparison_data = []
            for metric_name, values in metrics_over_time.items():
                if len(values) >= 3:
                    comparison_data.append(go.Bar(
                        name=metric_name,
                        x=['Початок', 'Середина', 'Кінець'],
                        y=[values[0], values[len(values)//2], values[-1]]
                    ))

            if comparison_data:
                for trace in comparison_data:
                    fig.add_trace(trace, row=2, col=1)

            # Графік 4: Розподіл метрик (кругова діаграма)
            fig.add_trace(
                go.Pie(
                    labels=list(latest_metrics.keys()),
                    values=list(latest_metrics.values()),
                    hole=0.3
                ),
                row=2, col=2
            )
        else:
            # Якщо немає часових рядів, створюємо простішу панель
            fig = make_subplots(
                rows=1, cols=2,
                subplot_titles=("Значення метрик", "Розподіл метрик"),
                specs=[
                    [{"type": "bar"}, {"type": "pie"}]
                ]
            )

            # Графік 1: Значення метрик (стовпчаста діаграма)
            fig.add_trace(
                go.Bar(
                    x=list(latest_metrics.keys()),
                    y=list(latest_metrics.values()),
                    marker_color=px.colors.qualitative.Plotly
                ),
                row=1, col=1
            )

            # Графік 2: Розподіл метрик (кругова діаграма)
            fig.add_trace(
                go.Pie(
                    labels=list(latest_metrics.keys()),
                    values=list(latest_metrics.values()),
                    hole=0.3
                ),
                row=1, col=2
            )

# Модуль 6: Інференс для нових даних

import os
import cv2
import numpy as np
import time
import threading
import queue
from pathlib import Path
import torch
import platform
import psutil
import argparse
import json
import urllib.request
import datetime
from tqdm import tqdm

class RealTimeInference:
    """
    Клас для інференсу моделі на нових даних у реальному часі.
    """

    def __init__(self, detector=None, tracker=None, filter=None, visualizer=None,
                output_dir='inference_results', device=None):
        """
        Ініціалізація системи інференсу в реальному часі.

        Параметри:
        -----------
        detector : object, опціонально
            Об'єкт детектора дронів
        tracker : object, опціонально
            Об'єкт трекера дронів
        filter : object, опціонально
            Об'єкт фільтра хибних спрацьовувань
        visualizer : object, опціонально
            Об'єкт візуалізатора результатів
        output_dir : str
            Директорія для збереження результатів
        device : str, опціонально
            Пристрій для інференсу ('cpu', 'cuda', '0', etc.)
        """
        self.detector = detector
        self.tracker = tracker
        self.filter = filter
        self.visualizer = visualizer

        # Створення директорії для результатів
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)

        # Визначення пристрою для інференсу
        self.device = device
        if self.device is None:
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'

        # Параметри для обробки відео
        self.frame_queue = queue.Queue(maxsize=30)  # Буфер кадрів
        self.result_queue = queue.Queue()  # Черга результатів
        self.is_running = False  # Прапорець роботи
        self.processing_fps = 0  # FPS обробки
        self.display_fps = 0  # FPS відображення

        # Для роботи з декількома камерами
        self.camera_streams = {}  # Словник активних потоків камер

        # Параметри оптимізації
        self.batch_size = 1
        self.skip_frames = 0
        self.resize_factor = 1.0
        self.low_power_mode = False
        self.frame_count = 0

        # Результати моніторингу
        self.performance_metrics = {
            'inference_times': [],
            'processing_fps': [],
            'memory_usage': [],
            'cpu_usage': [],
            'gpu_usage': [] if torch.cuda.is_available() else None
        }

        # Статистика виявлень
        self.detection_stats = {
            'total_frames': 0,
            'frames_with_detections': 0,
            'total_detections': 0,
            'detection_classes': {},
            'average_confidence': 0,
            'total_confidence': 0
        }

        # Список класів
        self.class_names = ['drone']

        print(f"Ініціалізовано систему інференсу на пристрої: {self.device}")

    def load_detector(self, model_path=None):
        """
        Завантаження детектора дронів.

        Параметри:
        -----------
        model_path : str, опціонально
            Шлях до файлу моделі

        Повертає:
        -----------
        bool : True, якщо модель успішно завантажена
        """
        if self.detector is None:
            from DroneDetector import DroneDetector
            self.detector = DroneDetector(model_size='m')

        if model_path is not None:
            return self.detector.load_model(model_path)

        return True

    def load_tracker(self):
        """
        Завантаження трекера дронів.

        Повертає:
        -----------
        bool : True, якщо трекер успішно завантажено
        """
        if self.tracker is None:
            from DroneTracker import DroneTracker
            self.tracker = DroneTracker()

        return True

    def load_filter(self):
        """
        Завантаження фільтра хибних спрацьовувань.

        Повертає:
        -----------
        bool : True, якщо фільтр успішно завантажено
        """
        if self.filter is None:
            from FalsePositiveFilter import FalsePositiveFilter
            self.filter = FalsePositiveFilter()

        return True

    def load_visualizer(self):
        """
        Завантаження візуалізатора результатів.

        Повертає:
        -----------
        bool : True, якщо візуалізатор успішно завантажено
        """
        if self.visualizer is None:
            from ResultsVisualizer import ResultsVisualizer
            self.visualizer = ResultsVisualizer()

        return True

    def optimize_performance(self, target_fps=30, available_memory=None):
        """
        Автоматична оптимізація параметрів продуктивності.

        Параметри:
        -----------
        target_fps : int
            Цільова частота кадрів
        available_memory : int, опціонально
            Доступна пам'ять (в MB)

        Повертає:
        -----------
        dict : Оптимізовані параметри
        """
        print("Оптимізація параметрів продуктивності...")

        # Отримання інформації про систему
        cpu_count = psutil.cpu_count(logical=False)
        total_memory = psutil.virtual_memory().total / (1024 * 1024)  # MB

        if available_memory is None:
            available_memory = total_memory * 0.5  # 50% від загальної пам'яті

        # Визначення параметрів на основі системних ресурсів та цільового FPS
        if self.device == 'cpu':
            # На CPU немає сенсу використовувати великий batch_size
            if cpu_count <= 2:
                self.batch_size = 1
                self.skip_frames = 2
                self.resize_factor = 0.5
                self.low_power_mode = True
            elif cpu_count <= 4:
                self.batch_size = 1
                self.skip_frames = 1
                self.resize_factor = 0.75
                self.low_power_mode = False
            else:
                self.batch_size = 1
                self.skip_frames = 0
                self.resize_factor = 1.0
                self.low_power_mode = False
        else:
            # Для GPU
            gpu_info = torch.cuda.get_device_properties(0)
            gpu_memory = gpu_info.total_memory / (1024 * 1024)  # MB

            if gpu_memory < 2000:  # < 2 GB
                self.batch_size = 1
                self.skip_frames = 1
                self.resize_factor = 0.75
                self.low_power_mode = True
            elif gpu_memory < 4000:  # < 4 GB
                self.batch_size = 2
                self.skip_frames = 0
                self.resize_factor = 0.75
                self.low_power_mode = False
            elif gpu_memory < 8000:  # < 8 GB
                self.batch_size = 4
                self.skip_frames = 0
                self.resize_factor = 1.0
                self.low_power_mode = False
            else:  # >= 8 GB
                self.batch_size = 8
                self.skip_frames = 0
                self.resize_factor = 1.0
                self.low_power_mode = False

        # Тестування продуктивності з поточними параметрами
        # та подальше налаштування
        self._test_and_adjust_performance(target_fps)

        print(f"Параметри оптимізації:")
        print(f"  Пристрій: {self.device}")
        print(f"  Розмір пакету: {self.batch_size}")
        print(f"  Пропуск кадрів: {self.skip_frames}")
        print(f"  Коефіцієнт зменшення розміру: {self.resize_factor}")
        print(f"  Режим низького енергоспоживання: {self.low_power_mode}")

        return {
            'device': self.device,
            'batch_size': self.batch_size,
            'skip_frames': self.skip_frames,
            'resize_factor': self.resize_factor,
            'low_power_mode': self.low_power_mode
        }

    def _test_and_adjust_performance(self, target_fps):
        """
        Тестування та налаштування параметрів продуктивності.

        Параметри:
        -----------
        target_fps : int
            Цільова частота кадрів
        """
        # Перевірка, що модель завантажена
        if self.detector is None:
            self.load_detector()

        # Створення тестового зображення
        test_frame = np.zeros((720, 1280, 3), dtype=np.uint8)

        # Виконання тестових інференсів
        num_tests = 10
        inference_times = []

        for _ in range(num_tests):
            start_time = time.time()

            # Тестова обробка
            if self.resize_factor < 1.0:
                h, w = test_frame.shape[:2]
                new_h, new_w = int(h * self.resize_factor), int(w * self.resize_factor)
                resized_frame = cv2.resize(test_frame, (new_w, new_h))
                self.detector.detect(resized_frame)
            else:
                self.detector.detect(test_frame)

            inference_time = time.time() - start_time
            inference_times.append(inference_time)

        # Розрахунок середнього часу інференсу
        avg_inference_time = sum(inference_times) / len(inference_times)
        current_fps = 1.0 / avg_inference_time

        print(f"Тестова продуктивність: {current_fps:.2f} FPS")

        # Налаштування параметрів, якщо не досягнута цільова частота кадрів
        if current_fps < target_fps * 0.8:  # Менше 80% від цільового FPS
            # Спробуємо зменшити розмір зображення
            if self.resize_factor > 0.5:
                self.resize_factor = max(0.5, self.resize_factor - 0.25)

            # Збільшимо пропуск кадрів
            self.skip_frames = min(3, self.skip_frames + 1)

            # Зменшимо розмір пакету
            if self.batch_size > 1:
                self.batch_size = max(1, self.batch_size // 2)

            # Увімкнемо режим низького енергоспоживання
            self.low_power_mode = True

            print(f"Параметри продуктивності налаштовано для досягнення цільового FPS")

    def set_class_names(self, class_names):
        """
        Встановлення списку назв класів.

        Параметри:
        -----------
        class_names : list
            Список назв класів
        """
        self.class_names = class_names

    def process_frame(self, frame, frame_index=None):
        """
        Обробка одного кадру для виявлення та відстеження дронів.

        Параметри:
        -----------
        frame : numpy.ndarray
            Кадр для обробки
        frame_index : int, опціонально
            Індекс кадру

        Повертає:
        -----------
        tuple : (Оброблений кадр, результати виявлення, результати відстеження)
        """
        if frame is None:
            return None, [], []

        # Збільшення лічильника кадрів
        self.frame_count += 1
        if frame_index is None:
            frame_index = self.frame_count

        # Пропуск кадрів для оптимізації
        if self.skip_frames > 0 and (self.frame_count % (self.skip_frames + 1)) != 0:
            # Просто візуалізуємо попередні результати
            if hasattr(self, 'last_tracking_results') and self.visualizer is not None:
                return self.visualizer.visualize_tracking_paths(
                    self.last_tracking_results, frame.shape, min_track_length=1,
                    overlay_image=frame, class_names=self.class_names
                ), [], []
            else:
                return frame, [], []

        # Зміна розміру для оптимізації
        if self.resize_factor < 1.0:
            h, w = frame.shape[:2]
            new_h, new_w = int(h * self.resize_factor), int(w * self.resize_factor)
            resized_frame = cv2.resize(frame, (new_w, new_h))

            # Виявлення на зменшеному кадрі
            start_time = time.time()
            detection_results = self.detector.detect(resized_frame)
            inference_time = time.time() - start_time

            # Масштабування результатів назад до оригінального розміру
            detections = []
            if len(detection_results) > 0:
                boxes = detection_results[0].boxes
                for box in boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    conf = box.conf[0].cpu().numpy()
                    cls = box.cls[0].cpu().numpy()

                    # Масштабування координат
                    x1 = x1 / self.resize_factor
                    y1 = y1 / self.resize_factor
                    x2 = x2 / self.resize_factor
                    y2 = y2 / self.resize_factor

                    detections.append([x1, y1, x2, y2, conf, cls])
        else:
            # Виявлення на оригінальному кадрі
            start_time = time.time()
            detection_results = self.detector.detect(frame)
            inference_time = time.time() - start_time

            # Отримання виявлень
            detections = []
            if len(detection_results) > 0:
                boxes = detection_results[0].boxes
                for box in boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    conf = box.conf[0].cpu().numpy()
                    cls = box.cls[0].cpu().numpy()
                    detections.append([x1, y1, x2, y2, conf, cls])

        # Оновлення статистики виявлень
        self._update_detection_stats(detections)

        # Застосування фільтра хибних спрацьовувань, якщо доступний
        if self.filter is not None:
            detections = self.filter.filter_detections(detections, frame, frame_index)

        # Відстеження дронів, якщо доступний трекер
        tracking_results = []
        if self.tracker is not None:
            tracking_results = [{
                'frame': frame_index,
                'timestamp': frame_index / 30.0,  # Приблизний час
                'tracks': self.tracker.update(detections)
            }]
            self.last_tracking_results = tracking_results

        # Візуалізація результатів
        output_frame = frame
        if self.visualizer is not None:
            if self.tracker is not None:
                output_frame = self.visualizer.visualize_tracking_paths(
                    tracking_results, frame.shape, min_track_length=1,
                    overlay_image=frame, class_names=self.class_names
                )
            else:
                output_frame = self.visualizer.visualize_detection(
                    frame, detections, class_names=self.class_names
                )

        # Додавання інформації про FPS
        if self.processing_fps > 0:
            cv2.putText(
                output_frame, f"FPS: {self.processing_fps:.1f}",
                (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2
            )

        # Збереження даних про продуктивність
        self.performance_metrics['inference_times'].append(inference_time)

        # Обмеження розміру списків для економії пам'яті
        if len(self.performance_metrics['inference_times']) > 100:
            self.performance_metrics['inference_times'] = self.performance_metrics['inference_times'][-100:]

        return output_frame, detections, tracking_results

    def process_video(self, video_source, output_path=None, display=True,
                    max_frames=None, save_detections=True):
        """
        Обробка відеофайлу або відеопотоку для виявлення та відстеження дронів.

        Параметри:
        -----------
        video_source : str або int
            Шлях до відеофайлу або індекс камери
        output_path : str, опціонально
            Шлях для збереження обробленого відео
        display : bool
            Відображення оброблених кадрів у реальному часі
        max_frames : int, опціонально
            Максимальна кількість кадрів для обробки
        save_detections : bool
            Зберігати результати виявлень та відстеження у форматі JSON

        Повертає:
        -----------
        dict : Результати обробки
        """
        # Перевірка, що всі необхідні компоненти завантажені
        if self.detector is None:
            self.load_detector()

        # Автоматична оптимізація продуктивності
        self.optimize_performance()

        # Відкриття відеоджерела
        if isinstance(video_source, str):
            if video_source.startswith(('http://', 'https://', 'rtsp://', 'rtmp://')):
                print(f"Підключення до відеопотоку: {video_source}")
            else:
                print(f"Відкриття відеофайлу: {video_source}")
            cap = cv2.VideoCapture(video_source)
        else:
            print(f"Відкриття камери #{video_source}")
            cap = cv2.VideoCapture(video_source)

        # Перевірка, чи вдалося відкрити відеоджерело
        if not cap.isOpened():
            print(f"Помилка: Не вдалося відкрити відеоджерело: {video_source}")
            return {'success': False, 'error': 'Не вдалося відкрити відеоджерело'}

        # Отримання параметрів відео
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        if fps <= 0:
            fps = 30  # Стандартне значення, якщо не вдалося отримати

        # Якщо max_frames не вказано та джерело - файл, обробляємо все відео
        if max_frames is None:
            if isinstance(video_source, str) and not video_source.startswith(('http://', 'https://', 'rtsp://', 'rtmp://')):
                max_frames = total_frames
            else:
                max_frames = float('inf')  # Необмежено для потоків

        # Створення відеописувача для вихідного файлу
        out = None
        if output_path is not None:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

        # Ініціалізація змінних
        frame_count = 0
        processing_times = []
        detection_results = []
        tracking_results = []

        print(f"Початок обробки відео: {width}x{height} @ {fps:.2f} FPS")

        # Скидання лічильника кадрів
        self.frame_count = 0

        # Прогрес-бар
        pbar = None
        if max_frames < float('inf'):
            pbar = tqdm(total=max_frames, desc="Обробка відео")

        # Основний цикл обробки
        while cap.isOpened() and frame_count < max_frames:
            # Зчитування кадру
            ret, frame = cap.read()

            # Перевірка, чи кадр зчитано успішно
            if not ret:
                break

            # Вимірювання часу обробки
            start_time = time.time()

            # Обробка кадру
            processed_frame, detections, tracking = self.process_frame(frame, frame_count)

            # Розрахунок часу обробки
            processing_time = time.time() - start_time
            processing_times.append(processing_time)

            # Розрахунок FPS
            if len(processing_times) > 10:
                self.processing_fps = 1.0 / (sum(processing_times[-10:]) / 10)
            else:
                self.processing_fps = 1.0 / processing_time

            # Збереження результатів
            if detections:
                detection_results.append({
                    'frame': frame_count,
                    'timestamp': frame_count / fps,
                    'detections': detections
                })

            if tracking:
                tracking_results.extend(tracking)

            # Запис кадру у вихідний файл
            if out is not None:
                out.write(processed_frame)

            # Відображення оброблених кадрів у реальному часі
            if display:
                cv2.imshow("Виявлення дронів у реальному часі", processed_frame)

                # Вихід при натисканні клавіші 'q'
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

            # Оновлення лічильника кадрів та прогрес-бару
            frame_count += 1
            if pbar:
                pbar.update(1)

        # Завершення обробки
        cap.release()
        if out is not None:
            out.release()
        if display:
            cv2.destroyAllWindows()
        if pbar:
            pbar.close()

        # Збереження результатів у JSON
        results_info = {
            'source': video_source,
            'processed_frames': frame_count,
            'fps': fps,
            'width': width,
            'height': height,
            'processing_fps': self.processing_fps,
            'settings': {
                'device': self.device,
                'batch_size': self.batch_size,
                'skip_frames': self.skip_frames,
                'resize_factor': self.resize_factor
            },
            'detection_stats': self.detection_stats
        }

        if save_detections:
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')

            # Збереження результатів виявлень
            if detection_results:
                detection_path = self.output_dir / f"detections_{timestamp}.json"
                with open(detection_path, 'w') as f:
                    json.dump(detection_results, f, indent=2)
                print(f"Результати виявлень збережено у: {detection_path}")
                results_info['detection_path'] = str(detection_path)

            # Збереження результатів відстеження
            if tracking_results:
                tracking_path = self.output_dir / f"tracking_{timestamp}.json"
                with open(tracking_path, 'w') as f:
                    json.dump(tracking_results, f, indent=2)
                print(f"Результати відстеження збережено у: {tracking_path}")
                results_info['tracking_path'] = str(tracking_path)

            # Збереження загальної інформації
            info_path = self.output_dir / f"info_{timestamp}.json"
            with open(info_path, 'w') as f:
                json.dump(results_info, f, indent=2)
            print(f"Інформацію про обробку збережено у: {info_path}")

        if output_path is not None:
            print(f"Оброблене відео збережено у: {output_path}")
            results_info['output_path'] = output_path

        print(f"Обробку відео завершено. Оброблено {frame_count} кадрів.")
        print(f"Середній FPS: {self.processing_fps:.2f}")

        return {
            'success': True,
            'results': results_info,
            'detection_results': detection_results if not save_detections else None,
            'tracking_results': tracking_results if not save_detections else None
        }

    def start_realtime_processing(self, source=0, display=True,
                                output_path=None, limit_time=None):
        """
        Запуск обробки відеопотоку в реальному часі з використанням потоків.

        Параметри:
        -----------
        source : int або str
            Індекс камери або URL відеопотоку
        display : bool
            Відображення оброблених кадрів у реальному часі
        output_path : str, опціонально
            Шлях для збереження обробленого відео
        limit_time : float, опціонально
            Обмеження часу роботи в секундах

        Повертає:
        -----------
        bool : True, якщо обробка успішно запущена
        """
        # Перевірка, що всі необхідні компоненти завантажені
        if self.detector is None:
            self.load_detector()

        # Автоматична оптимізація продуктивності
        self.optimize_performance()

        # Перевірка, чи система вже запущена
        if self.is_running:
            print("Система вже працює. Спочатку зупиніть поточну обробку.")
            return False

        # Очищення черг
        while not self.frame_queue.empty():
            self.frame_queue.get()

        while not self.result_queue.empty():
            self.result_queue.get()

        # Запуск потоків
        self.is_running = True

        # Запуск потоку захоплення кадрів
        capture_thread = threading.Thread(
            target=self._capture_thread,
            args=(source, output_path, limit_time)
        )
        capture_thread.daemon = True
        capture_thread.start()

        # Запуск потоку обробки
        processing_thread = threading.Thread(
            target=self._processing_thread
        )
        processing_thread.daemon = True
        processing_thread.start()

        # Якщо потрібно відображення, запускаємо його в головному потоці
        if display:
            self._display_thread()
        else:
            return True

    def _capture_thread(self, source, output_path=None, limit_time=None):
        """
        Потік для захоплення кадрів з камери.

        Параметри:
        -----------
        source : int або str
            Індекс камери або URL відеопотоку
        output_path : str, опціонально
            Шлях для збереження обробленого відео
        limit_time : float, опціонально
            Обмеження часу роботи в секундах
        """
        # Відкриття відеоджерела
        cap = cv2.VideoCapture(source)

        # Перевірка, чи вдалося відкрити відеоджерело
        if not cap.isOpened():
            print(f"Помилка: Не вдалося відкрити відеоджерело: {source}")
            self.is_running = False
            return

        # Отримання параметрів відео
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

        if fps <= 0:
            fps = 30  # Стандартне значення, якщо не вдалося отримати

        # Створення відеописувача для вихідного файлу, якщо потрібно
        out = None
        if output_path is not None:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

        # Встановлення часу початку
        start_time = time.time()

        # Основний цикл захоплення кадрів
        print(f"Початок захоплення відео з джерела: {source}")

        frame_count = 0

        while self.is_running:
            # Перевірка обмеження часу
            if limit_time is not None and time.time() - start_time > limit_time:
                print(f"Досягнуто обмеження часу роботи: {limit_time} секунд")
                break

            # Зчитування кадру
            ret, frame = cap.read()

            # Перевірка, чи кадр зчитано успішно
            if not ret:
                print("Помилка читання кадру або кінець відео")
                break

            # Додавання кадру до черги з обмеженням
            try:
                self.frame_queue.put((frame, frame_count), block=False)
            except queue.Full:
                # Якщо черга заповнена, пропускаємо кадр
                pass

            frame_count += 1

            # Невелика затримка для зменшення навантаження на CPU
            time.sleep(0.001)

        # Завершення захоплення
        cap.release()

        if out is not None:
            out.release()

        print(f"Захоплення відео завершено. Захоплено {frame_count} кадрів.")
        self.is_running = False

    def _processing_thread(self):
        """
        Потік для обробки кадрів.
        """
        print("Початок обробки кадрів")

        while self.is_running:
            # Отримання кадру з черги
            try:
                frame, frame_index = self.frame_queue.get(timeout=1)
            except queue.Empty:
                continue

            # Обробка кадру
            processed_frame, detections, tracking = self.process_frame(frame, frame_index)

            # Додавання результату до черги результатів
            try:
                self.result_queue.put((processed_frame, detections, tracking, frame_index))
            except:
                pass

            # Позначення завдання як виконаного
            self.frame_queue.task_done()

        print("Обробку кадрів завершено")

    def _display_thread(self):
        """
        Функція для відображення оброблених кадрів.
        """
        print("Початок відображення результатів")

        display_time = time.time()
        frame_count = 0

        while self.is_running:
            # Отримання результату з черги
            try:
                processed_frame, _, _, _ = self.result_queue.get(timeout=1)
            except queue.Empty:
                # Якщо черга пуста, показуємо інформацію про чекання
                info_frame = np.zeros((480, 640, 3), dtype=np.uint8)
                cv2.putText(
                    info_frame, "Очікування даних...",
                    (50, 240), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2
                )
                cv2.imshow("Виявлення дронів у реальному часі", info_frame)
                cv2.waitKey(1)
                continue

            # Відображення кадру
            cv2.imshow("Виявлення дронів у реальному часі", processed_frame)

            # Вихід при натисканні клавіші 'q'
            if cv2.waitKey(1) & 0xFF == ord('q'):
                self.is_running = False
                break

            # Розрахунок FPS відображення
            frame_count += 1
            if frame_count % 10 == 0:
                current_time = time.time()
                self.display_fps = 10 / (current_time - display_time)
                display_time = current_time

            # Позначення завдання як виконаного
            self.result_queue.task_done()

        # Закриття вікон відображення
        cv2.destroyAllWindows()
        print("Відображення результатів завершено")

    def stop_processing(self):
        """
        Зупинка обробки в реальному часі.

        Повертає:
        -----------
        bool : True, якщо обробка була зупинена
        """
        if not self.is_running:
            print("Система не запущена")
            return False

        self.is_running = False

        # Очікування завершення черг
        time.sleep(1)

        print("Обробку в реальному часі зупинено")
        return True

    def setup_multi_camera(self, camera_sources):
        """
        Налаштування системи для роботи з декількома камерами.

        Параметри:
        -----------
        camera_sources : dict
            Словник з джерелами камер у форматі {camera_id: source}

        Повертає:
        -----------
        bool : True, якщо налаштування успішне
        """
        # Перевірка, що система не запущена
        if self.is_running:
            print("Система вже працює. Спочатку зупиніть поточну обробку.")
            return False

        # Збереження джерел камер
        self.camera_streams = {}

        for camera_id, source in camera_sources.items():
            # Перевірка доступності камери
            cap = cv2.VideoCapture(source)
            if not cap.isOpened():
                print(f"Помилка: Не вдалося відкрити камеру {camera_id}: {source}")
                cap.release()
                continue

            # Збереження інформації про камеру
            self.camera_streams[camera_id] = {
                'source': source,
                'cap': cap,
                'width': int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),
                'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),
                'fps': cap.get(cv2.CAP_PROP_FPS),
                'frame_queue': queue.Queue(maxsize=10),
                'result_queue': queue.Queue()
            }

        print(f"Налаштовано {len(self.camera_streams)} камер для обробки")
        return True

    def start_multi_camera_processing(self, display=True, output_dir=None):
        """
        Запуск обробки відеопотоків з декількох камер.

        Параметри:
        -----------
        display : bool
            Відображення оброблених кадрів у реальному часі
        output_dir : str, опціонально
            Директорія для збереження оброблених відео

        Повертає:
        -----------
        bool : True, якщо обробка успішно запущена
        """
        # Перевірка, що всі необхідні компоненти завантажені
        if self.detector is None:
            self.load_detector()

        # Автоматична оптимізація продуктивності
        self.optimize_performance()

        # Перевірка, чи система вже запущена
        if self.is_running:
            print("Система вже працює. Спочатку зупиніть поточну обробку.")
            return False

        # Перевірка, чи налаштовані камери
        if not self.camera_streams:
            print("Спочатку налаштуйте камери за допомогою метода setup_multi_camera")
            return False

        # Створення директорії для результатів, якщо потрібно
        if output_dir is not None:
            output_dir = Path(output_dir)
            output_dir.mkdir(exist_ok=True)

        # Запуск потоків для кожної камери
        self.is_running = True

        for camera_id, camera_info in self.camera_streams.items():
            # Шлях для збереження відео
            output_path = None
            if output_dir is not None:
                output_path = output_dir / f"camera_{camera_id}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4"

            # Запуск потоку захоплення кадрів
            capture_thread = threading.Thread(
                target=self._capture_thread_multi,
                args=(camera_id, camera_info, output_path)
            )
            capture_thread.daemon = True
            capture_thread.start()

            # Запуск потоку обробки
            processing_thread = threading.Thread(
                target=self._processing_thread_multi,
                args=(camera_id, camera_info)
            )
            processing_thread.daemon = True
            processing_thread.start()

        # Якщо потрібно відображення, запускаємо його в головному потоці
        if display:
            self._display_thread_multi()

        return True

    def _capture_thread_multi(self, camera_id, camera_info, output_path=None):
        """
        Потік для захоплення кадрів з камери в режимі мультикамери.

        Параметри:
        -----------
        camera_id : str
            Ідентифікатор камери
        camera_info : dict
            Інформація про камеру
        output_path : str, опціонально
            Шлях для збереження обробленого відео
        """
        cap = camera_info['cap']
        frame_queue = camera_info['frame_queue']

        # Створення відеописувача для вихідного файлу, якщо потрібно
        out = None
        if output_path is not None:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(
                str(output_path), fourcc,
                camera_info['fps'] if camera_info['fps'] > 0 else 30,
                (camera_info['width'], camera_info['height'])
            )

        # Основний цикл захоплення кадрів
        print(f"Початок захоплення з камери {camera_id}")

        frame_count = 0

        while self.is_running:
            # Зчитування кадру
            ret, frame = cap.read()

            # Перевірка, чи кадр зчитано успішно
            if not ret:
                print(f"Помилка читання кадру з камери {camera_id}")
                # Спроба повторного відкриття камери
                cap.release()
                cap = cv2.VideoCapture(camera_info['source'])
                if not cap.isOpened():
                    print(f"Не вдалося повторно відкрити камеру {camera_id}")
                    break
                camera_info['cap'] = cap
                continue

            # Додавання кадру до черги з обмеженням
            try:
                frame_queue.put((frame, frame_count), block=False)
            except queue.Full:
                # Якщо черга заповнена, пропускаємо кадр
                pass

            # Запис у файл, якщо потрібно
            if out is not None:
                out.write(frame)

            frame_count += 1

            # Невелика затримка для зменшення навантаження на CPU
            time.sleep(0.001)

        # Завершення захоплення
        cap.release()

        if out is not None:
            out.release()

        print(f"Захоплення з камери {camera_id} завершено. Захоплено {frame_count} кадрів.")

    def _processing_thread_multi(self, camera_id, camera_info):
        """
        Потік для обробки кадрів у режимі мультикамери.

        Параметри:
        -----------
        camera_id : str
            Ідентифікатор камери
        camera_info : dict
            Інформація про камеру
        """
        frame_queue = camera_info['frame_queue']
        result_queue = camera_info['result_queue']

        print(f"Початок обробки кадрів з камери {camera_id}")

        while self.is_running:
            # Отримання кадру з черги
            try:
                frame, frame_index = frame_queue.get(timeout=1)
            except queue.Empty:
                continue

            # Обробка кадру
            processed_frame, detections, tracking = self.process_frame(frame, frame_index)

            # Додавання результату до черги результатів
            try:
                result_queue.put((processed_frame, detections, tracking, frame_index))
            except:
                pass

            # Позначення завдання як виконаного
            frame_queue.task_done()

        print(f"Обробку кадрів з камери {camera_id} завершено")

    def _display_thread_multi(self):
        """
        Функція для відображення оброблених кадрів з декількох камер.
        """
        print("Початок відображення результатів з декількох камер")

        # Створення мозаїчного зображення
        def create_mosaic(frames):
            if not frames:
                return None

            # Визначення розміру мозаїки
            n = len(frames)
            cols = int(np.ceil(np.sqrt(n)))
            rows = int(np.ceil(n / cols))

            # Зміна розміру всіх кадрів до однакового
            height, width = 360, 640  # Стандартний розмір для кожної камери
            resized_frames = [cv2.resize(frame, (width, height)) for frame in frames]

            # Створення порожнього зображення
            mosaic = np.zeros((height * rows, width * cols, 3), dtype=np.uint8)

            # Заповнення мозаїки
            for i, frame in enumerate(resized_frames):
                row = i // cols
                col = i % cols
                mosaic[row*height:(row+1)*height, col*width:(col+1)*width] = frame

            return mosaic

        while self.is_running:
            # Отримання останніх оброблених кадрів з усіх камер
            frames = []
            camera_ids = []

            for camera_id, camera_info in self.camera_streams.items():
                result_queue = camera_info['result_queue']

                if not result_queue.empty():
                    processed_frame, _, _, _ = result_queue.get()

                    # Додавання ідентифікатора камери на кадр
                    cv2.putText(
                        processed_frame, f"Camera {camera_id}",
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2
                    )

                    frames.append(processed_frame)
                    camera_ids.append(camera_id)

                    # Позначення завдання як виконаного
                    result_queue.task_done()

            # Якщо є кадри для відображення
            if frames:
                # Створення мозаїчного зображення
                mosaic = create_mosaic(frames)

                # Відображення мозаїки
                cv2.imshow("Мультикамерне виявлення дронів", mosaic)

                # Вихід при натисканні клавіші 'q'
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    self.is_running = False
                    break
            else:
                # Якщо немає кадрів, показуємо інформацію про чекання
                info_frame = np.zeros((480, 640, 3), dtype=np.uint8)
                cv2.putText(
                    info_frame, "Очікування даних...",
                    (50, 240), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2
                )
                cv2.imshow("Мультикамерне виявлення дронів", info_frame)
                cv2.waitKey(1)

            # Невелика затримка для зменшення навантаження на CPU
            time.sleep(0.03)

        # Закриття вікон відображення
        cv2.destroyAllWindows()
        print("Відображення результатів з декількох камер завершено")

    def connect_to_stream(self, url, auth_user=None, auth_pass=None):
        """
        Підключення до відеопотоку з авторизацією.

        Параметри:
        -----------
        url : str
            URL відеопотоку
        auth_user : str, опціонально
            Логін для авторизації
        auth_pass : str, опціонально
            Пароль для авторизації

        Повертає:
        -----------
        bool : True, якщо підключення успішне
        """
        # Перевірка URL
        if not url.startswith(('http://', 'https://', 'rtsp://', 'rtmp://')):
            print(f"Некоректний URL: {url}")
            return False

        # Додавання авторизації, якщо потрібно
        if auth_user is not None and auth_pass is not None:
            # Для RTSP
            if url.startswith('rtsp://'):
                url = url.replace('rtsp://', f'rtsp://{auth_user}:{auth_pass}@')
            # Для HTTP/HTTPS
            elif url.startswith(('http://', 'https://')):
                # Встановлення базової авторизації
                password_mgr = urllib.request.HTTPPasswordMgrWithDefaultRealm()
                password_mgr.add_password(None, url, auth_user, auth_pass)
                handler = urllib.request.HTTPBasicAuthHandler(password_mgr)
                opener = urllib.request.build_opener(handler)
                urllib.request.install_opener(opener)

        # Спроба підключення
        cap = cv2.VideoCapture(url)
        if not cap.isOpened():
            print(f"Не вдалося підключитися до потоку: {url}")
            return False

        print(f"Успішне підключення до потоку: {url}")
        cap.release()

        return True

    def monitor_system_resources(self, interval=5.0):
        """
        Моніторинг системних ресурсів під час роботи.

        Параметри:
        -----------
        interval : float
            Інтервал між вимірюваннями в секундах

        Повертає:
        -----------
        threading.Thread : Потік моніторингу
        """
        def monitoring_thread():
            print("Початок моніторингу системних ресурсів")

            while self.is_running:
                # Вимірювання використання CPU
                cpu_usage = psutil.cpu_percent(interval=1)

                # Вимірювання використання пам'яті
                memory_info = psutil.Process(os.getpid()).memory_info()
                memory_usage = memory_info.rss / (1024 * 1024)  # MB

                # Вимірювання використання GPU, якщо доступно
                gpu_usage = None
                if torch.cuda.is_available():
                    try:
                        gpu_usage = torch.cuda.memory_allocated(0) / (1024 * 1024)  # MB
                    except:
                        gpu_usage = None

                # Збереження метрик
                self.performance_metrics['cpu_usage'].append(cpu_usage)
                self.performance_metrics['memory_usage'].append(memory_usage)
                if gpu_usage is not None:
                    self.performance_metrics['gpu_usage'].append(gpu_usage)

                # Обмеження розміру списків для економії пам'яті
                for key in ['cpu_usage', 'memory_usage']:
                    if len(self.performance_metrics[key]) > 100:
                        self.performance_metrics[key] = self.performance_metrics[key][-100:]

                if gpu_usage is not None and len(self.performance_metrics['gpu_usage']) > 100:
                    self.performance_metrics['gpu_usage'] = self.performance_metrics['gpu_usage'][-100:]

                # Виведення інформації
                print(f"Системні ресурси: CPU {cpu_usage:.1f}%, "
                      f"Пам'ять {memory_usage:.1f} MB"
                      f"{', GPU ' + str(gpu_usage) + ' MB' if gpu_usage is not None else ''}")

                # Чекання до наступного вимірювання
                time.sleep(interval)

            print("Моніторинг системних ресурсів завершено")

        # Створення та запуск потоку
        monitor_thread = threading.Thread(target=monitoring_thread)
        monitor_thread.daemon = True
        monitor_thread.start()

        return monitor_thread

    def _update_detection_stats(self, detections):
        """
        Оновлення статистики виявлень.

        Параметри:
        -----------
        detections : list
            Список виявлень
        """
        self.detection_stats['total_frames'] += 1

        if detections:
            self.detection_stats['frames_with_detections'] += 1
            self.detection_stats['total_detections'] += len(detections)

            # Розрахунок середньої впевненості
            conf_sum = sum(det[4] for det in detections)
            self.detection_stats['total_confidence'] += conf_sum
            self.detection_stats['average_confidence'] = (
                self.detection_stats['total_confidence'] / self.detection_stats['total_detections']
                if self.detection_stats['total_detections'] > 0 else 0
            )

            # Оновлення статистики за класами
            for det in detections:
                class_id = int(det[5])
                confidence = det[4]

                if class_id not in self.detection_stats['detection_classes']:
                    self.detection_stats['detection_classes'][class_id] = {
                        'count': 0,
                        'total_confidence': 0,
                        'average_confidence': 0
                    }

                class_stats = self.detection_stats['detection_classes'][class_id]
                class_stats['count'] += 1
                class_stats['total_confidence'] += confidence
                class_stats['average_confidence'] = (
                    class_stats['total_confidence'] / class_stats['count']
                )

    def get_performance_report(self):
        """
        Отримання звіту про продуктивність системи.

        Повертає:
        -----------
        dict : Звіт про продуктивність
        """
        report = {
            'device': self.device,
            'processing_fps': self.processing_fps,
            'display_fps': self.display_fps,
            'batch_size': self.batch_size,
            'skip_frames': self.skip_frames,
            'resize_factor': self.resize_factor,
            'low_power_mode': self.low_power_mode,
            'detection_stats': self.detection_stats,
        }

        # Додавання середніх значень метрик продуктивності
        for key in ['inference_times', 'cpu_usage', 'memory_usage', 'gpu_usage']:
            if self.performance_metrics[key] and self.performance_metrics[key][0] is not None:
                report[f'avg_{key}'] = sum(self.performance_metrics[key]) / len(self.performance_metrics[key])
                report[f'max_{key}'] = max(self.performance_metrics[key])

        return report


# Приклад використання:
# inference = RealTimeInference()
#
# # Завантаження моделі
# inference.load_detector('models/best.pt')
# inference.load_tracker()
# inference.load_filter()
# inference.load_visualizer()
#
# # Обробка відеофайлу
# result = inference.process_video('test_video.mp4', output_path='output_video.mp4')
#
# # Обробка відеопотоку в реальному часі
# inference.start_realtime_processing(source=0, display=True)
#
# # Обробка від декількох камер
# camera_sources = {
#     'front': 0,
#     'back': 'rtsp://192.168.1.100:554/stream'
# }
# inference.setup_multi_camera(camera_sources)
# inference.start_multi_camera_processing(display=True)

# Модуль 7: Експорт та звітність

import os
import csv
import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import datetime
import cv2
import shutil
from tqdm import tqdm
import io
from PIL import Image
import base64
import time
from fpdf import FPDF
import xml.etree.ElementTree as ET
import zipfile
import logging
import threading

class ExportReporting:
    """
    Клас для експорту результатів виявлення та відстеження дронів
    у різні формати та генерації звітів.
    """

    def __init__(self, output_dir='export_results'):
        """
        Ініціалізація модуля експорту та звітності.

        Параметри:
        -----------
        output_dir : str
            Базова директорія для збереження результатів експорту
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)

        # Створення піддиректорій для різних типів експорту
        self.csv_dir = self.output_dir / 'csv'
        self.json_dir = self.output_dir / 'json'
        self.reports_dir = self.output_dir / 'reports'
        self.images_dir = self.output_dir / 'images'
        self.videos_dir = self.output_dir / 'videos'

        for directory in [self.csv_dir, self.json_dir, self.reports_dir,
                         self.images_dir, self.videos_dir]:
            directory.mkdir(exist_ok=True)

        # Налаштування логування
        self.logger = self._setup_logger()

        # Статистика для звітів
        self.current_stats = {
            'total_detections': 0,
            'detections_by_class': {},
            'detections_by_confidence': {},
            'total_tracks': 0,
            'avg_track_length': 0,
            'export_count': 0
        }

        # Стилі для PDF-звітів
        self.pdf_styles = {
            'title_font': 'Arial',
            'text_font': 'Times',
            'title_size': 16,
            'subtitle_size': 14,
            'text_size': 12,
            'text_color': (0, 0, 0),
            'header_color': (70, 130, 180),
            'highlight_color': (0, 100, 0)
        }

        self.logger.info(f"Модуль експорту та звітності ініціалізовано. Базова директорія: {self.output_dir}")

    def _setup_logger(self):
        """
        Налаштування системи логування.

        Повертає:
        -----------
        logging.Logger : Об'єкт логера
        """
        logger = logging.getLogger('ExportReporting')
        logger.setLevel(logging.INFO)

        # Створення обробника файлу
        log_path = self.output_dir / 'export_log.txt'
        file_handler = logging.FileHandler(log_path)

        # Створення форматера
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        file_handler.setFormatter(formatter)

        # Додавання обробника до логера
        logger.addHandler(file_handler)

        return logger

    def export_to_csv(self, data, filename=None, data_type='detections', extra_info=None):
        """
        Експорт даних у формат CSV.

        Параметри:
        -----------
        data : list або dict
            Дані для експорту
        filename : str, опціонально
            Ім'я файлу для збереження (без розширення)
        data_type : str
            Тип даних ('detections', 'tracks', 'statistics')
        extra_info : dict, опціонально
            Додаткова інформація для включення у файл

        Повертає:
        -----------
        str : Шлях до створеного CSV-файлу
        """
        if not data:
            self.logger.warning("Немає даних для експорту в CSV")
            return None

        # Якщо filename не вказано, генеруємо ім'я на основі поточної дати/часу
        if filename is None:
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"{data_type}_{timestamp}"

        # Шлях до файлу
        file_path = self.csv_dir / f"{filename}.csv"

        try:
            # Підготовка даних залежно від типу
            if data_type == 'detections':
                # Експорт даних про виявлення
                # Приведення даних до плоского формату
                rows = []

                for detection_group in data:
                    frame = detection_group.get('frame', 0)
                    timestamp = detection_group.get('timestamp', 0)

                    for detection in detection_group.get('detections', []):
                        # Перевірка на формат детекції
                        if len(detection) >= 6:
                            x1, y1, x2, y2, confidence, class_id = detection[:6]
                            rows.append({
                                'frame': frame,
                                'timestamp': timestamp,
                                'x1': x1,
                                'y1': y1,
                                'x2': x2,
                                'y2': y2,
                                'width': x2 - x1,
                                'height': y2 - y1,
                                'confidence': confidence,
                                'class_id': class_id
                            })

                # Створення DataFrame
                df = pd.DataFrame(rows)

            elif data_type == 'tracks':
                # Експорт даних про треки
                rows = []

                for track_data in data:
                    frame = track_data.get('frame', 0)
                    timestamp = track_data.get('timestamp', 0)

                    for track in track_data.get('tracks', []):
                        track_id = track.get('track_id')
                        if isinstance(track.get('box'), (list, tuple)) and len(track.get('box')) >= 4:
                            x1, y1, x2, y2 = track.get('box')[:4]
                            rows.append({
                                'frame': frame,
                                'timestamp': timestamp,
                                'track_id': track_id,
                                'x1': x1,
                                'y1': y1,
                                'x2': x2,
                                'y2': y2,
                                'width': x2 - x1,
                                'height': y2 - y1,
                                'confidence': track.get('confidence', 0),
                                'class_id': track.get('class_id', 0),
                                'state': track.get('state', '')
                            })

                # Створення DataFrame
                df = pd.DataFrame(rows)

            elif data_type == 'statistics':
                # Експорт статистичних даних
                # Якщо дані - словник, перетворюємо його в плоский формат
                if isinstance(data, dict):
                    flattened_data = self._flatten_dict(data)
                    df = pd.DataFrame([flattened_data])
                else:
                    df = pd.DataFrame(data)
            else:
                # Якщо тип даних невідомий, просто зберігаємо як є
                df = pd.DataFrame(data)

            # Додавання додаткової інформації
            if extra_info and isinstance(extra_info, dict):
                # Створення додаткового файлу з інформацією
                info_path = self.csv_dir / f"{filename}_info.csv"
                info_df = pd.DataFrame([self._flatten_dict(extra_info)])
                info_df.to_csv(info_path, index=False)
                self.logger.info(f"Додаткову інформацію збережено у {info_path}")

            # Збереження у CSV
            df.to_csv(file_path, index=False)

            self.logger.info(f"Дані успішно експортовано у CSV: {file_path}")
            self.current_stats['export_count'] += 1

            return str(file_path)

        except Exception as e:
            self.logger.error(f"Помилка при експорті в CSV: {e}")
            return None

    def export_to_json(self, data, filename=None, data_type='detections', extra_info=None):
        """
        Експорт даних у формат JSON.

        Параметри:
        -----------
        data : list або dict
            Дані для експорту
        filename : str, опціонально
            Ім'я файлу для збереження (без розширення)
        data_type : str
            Тип даних ('detections', 'tracks', 'statistics')
        extra_info : dict, опціонально
            Додаткова інформація для включення у файл

        Повертає:
        -----------
        str : Шлях до створеного JSON-файлу
        """
        if not data:
            self.logger.warning("Немає даних для експорту в JSON")
            return None

        # Якщо filename не вказано, генеруємо ім'я на основі поточної дати/часу
        if filename is None:
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"{data_type}_{timestamp}"

        # Шлях до файлу
        file_path = self.json_dir / f"{filename}.json"

        try:
            # Підготовка даних для JSON
            output_data = {
                'data_type': data_type,
                'timestamp': datetime.datetime.now().isoformat(),
                'data': data
            }

            # Додавання додаткової інформації
            if extra_info and isinstance(extra_info, dict):
                output_data['metadata'] = extra_info

            # Збереження в JSON
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, indent=2)

            self.logger.info(f"Дані успішно експортовано у JSON: {file_path}")
            self.current_stats['export_count'] += 1

            return str(file_path)

        except Exception as e:
            self.logger.error(f"Помилка при експорті в JSON: {e}")
            return None

    def export_to_xml(self, data, filename=None, data_type='detections', extra_info=None):
        """
        Експорт даних у формат XML.

        Параметри:
        -----------
        data : list або dict
            Дані для експорту
        filename : str, опціонально
            Ім'я файлу для збереження (без розширення)
        data_type : str
            Тип даних ('detections', 'tracks', 'statistics')
        extra_info : dict, опціонально
            Додаткова інформація для включення у файл

        Повертає:
        -----------
        str : Шлях до створеного XML-файлу
        """
        if not data:
            self.logger.warning("Немає даних для експорту в XML")
            return None

        # Якщо filename не вказано, генеруємо ім'я на основі поточної дати/часу
        if filename is None:
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"{data_type}_{timestamp}"

        # Шлях до файлу
        file_path = self.output_dir / f"{filename}.xml"

        try:
            # Створення кореневого елементу
            root = ET.Element("DroneDetection")

            # Додавання метаданих
            metadata = ET.SubElement(root, "Metadata")
            ET.SubElement(metadata, "DataType").text = data_type
            ET.SubElement(metadata, "Timestamp").text = datetime.datetime.now().isoformat()

            # Додавання додаткової інформації
            if extra_info and isinstance(extra_info, dict):
                info_node = ET.SubElement(root, "ExtraInfo")
                for key, value in extra_info.items():
                    ET.SubElement(info_node, key).text = str(value)

            # Додавання даних
            if data_type == 'detections':
                detections_node = ET.SubElement(root, "Detections")

                for i, detection_group in enumerate(data):
                    group_node = ET.SubElement(detections_node, "Frame")
                    group_node.set("id", str(detection_group.get('frame', i)))
                    group_node.set("timestamp", str(detection_group.get('timestamp', 0)))

                    for j, detection in enumerate(detection_group.get('detections', [])):
                        if len(detection) >= 6:
                            det_node = ET.SubElement(group_node, "Detection")
                            det_node.set("id", str(j))

                            x1, y1, x2, y2, confidence, class_id = detection[:6]

                            ET.SubElement(det_node, "X1").text = str(x1)
                            ET.SubElement(det_node, "Y1").text = str(y1)
                            ET.SubElement(det_node, "X2").text = str(x2)
                            ET.SubElement(det_node, "Y2").text = str(y2)
                            ET.SubElement(det_node, "Width").text = str(x2 - x1)
                            ET.SubElement(det_node, "Height").text = str(y2 - y1)
                            ET.SubElement(det_node, "Confidence").text = str(confidence)
                            ET.SubElement(det_node, "ClassID").text = str(class_id)

            elif data_type == 'tracks':
                tracks_node = ET.SubElement(root, "Tracks")

                for track_data in data:
                    frame_node = ET.SubElement(tracks_node, "Frame")
                    frame_node.set("id", str(track_data.get('frame', 0)))
                    frame_node.set("timestamp", str(track_data.get('timestamp', 0)))

                    for track in track_data.get('tracks', []):
                        track_node = ET.SubElement(frame_node, "Track")
                        track_node.set("id", str(track.get('track_id', 0)))

                        if isinstance(track.get('box'), (list, tuple)) and len(track.get('box')) >= 4:
                            x1, y1, x2, y2 = track.get('box')[:4]
                            ET.SubElement(track_node, "X1").text = str(x1)
                            ET.SubElement(track_node, "Y1").text = str(y1)
                            ET.SubElement(track_node, "X2").text = str(x2)
                            ET.SubElement(track_node, "Y2").text = str(y2)
                            ET.SubElement(track_node, "Width").text = str(x2 - x1)
                            ET.SubElement(track_node, "Height").text = str(y2 - y1)

                        ET.SubElement(track_node, "Confidence").text = str(track.get('confidence', 0))
                        ET.SubElement(track_node, "ClassID").text = str(track.get('class_id', 0))
                        ET.SubElement(track_node, "State").text = str(track.get('state', ''))

            elif data_type == 'statistics':
                stats_node = ET.SubElement(root, "Statistics")

                if isinstance(data, dict):
                    for key, value in self._flatten_dict(data).items():
                        ET.SubElement(stats_node, key.replace(' ', '_')).text = str(value)
                else:
                    for i, item in enumerate(data):
                        item_node = ET.SubElement(stats_node, f"Item_{i}")
                        if isinstance(item, dict):
                            for key, value in item.items():
                                ET.SubElement(item_node, key.replace(' ', '_')).text = str(value)
                        else:
                            item_node.text = str(item)

            # Створення дерева XML і збереження
            tree = ET.ElementTree(root)
            tree.write(file_path, encoding='utf-8', xml_declaration=True)

            self.logger.info(f"Дані успішно експортовано у XML: {file_path}")
            self.current_stats['export_count'] += 1

            return str(file_path)

        except Exception as e:
            self.logger.error(f"Помилка при експорті в XML: {e}")
            return None

    def export_statistics(self, detection_data=None, tracking_data=None, metrics=None,
                        formats=None, filename=None):
        """
        Експорт статистичних даних у різні формати.

        Параметри:
        -----------
        detection_data : list, опціонально
            Дані про виявлення
        tracking_data : list, опціонально
            Дані про треки
        metrics : dict, опціонально
            Метрики ефективності моделі
        formats : list, опціонально
            Список форматів для експорту ('csv', 'json', 'xml')
        filename : str, опціонально
            Базове ім'я файлу для збереження

        Повертає:
        -----------
        dict : Словник зі шляхами до створених файлів
        """
        if formats is None:
            formats = ['csv', 'json']

        if filename is None:
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"stats_{timestamp}"

        # Розрахунок статистики
        statistics = self._calculate_statistics(detection_data, tracking_data, metrics)

        # Експорт у вказані формати
        result_paths = {}

        for fmt in formats:
            if fmt.lower() == 'csv':
                path = self.export_to_csv(statistics, filename, 'statistics')
                if path:
                    result_paths['csv'] = path
            elif fmt.lower() == 'json':
                path = self.export_to_json(statistics, filename, 'statistics')
                if path:
                    result_paths['json'] = path
            elif fmt.lower() == 'xml':
                path = self.export_to_xml(statistics, filename, 'statistics')
                if path:
                    result_paths['xml'] = path

        return result_paths

    def _calculate_statistics(self, detection_data=None, tracking_data=None, metrics=None):
        """
        Розрахунок статистичних даних для експорту.

        Параметри:
        -----------
        detection_data : list, опціонально
            Дані про виявлення
        tracking_data : list, опціонально
            Дані про треки
        metrics : dict, опціонально
            Метрики ефективності моделі

        Повертає:
        -----------
        dict : Словник зі статистичними даними
        """
        stats = {
            'timestamp': datetime.datetime.now().isoformat(),
            'detection_stats': {},
            'tracking_stats': {},
            'model_metrics': {}
        }

        # Статистика по виявленням
        if detection_data:
            total_detections = 0
            total_confidence = 0
            class_counts = {}
            confidence_ranges = {
                '0.0-0.2': 0,
                '0.2-0.4': 0,
                '0.4-0.6': 0,
                '0.6-0.8': 0,
                '0.8-1.0': 0
            }

            for detection_group in detection_data:
                detections = detection_group.get('detections', [])
                total_detections += len(detections)

                for detection in detections:
                    if len(detection) >= 6:
                        confidence = detection[4]
                        class_id = int(detection[5])

                        # Підрахунок за класами
                        if class_id not in class_counts:
                            class_counts[class_id] = 0
                        class_counts[class_id] += 1

                        # Підрахунок за впевненістю
                        total_confidence += confidence

                        # Розподіл за діапазонами впевненості
                        if confidence < 0.2:
                            confidence_ranges['0.0-0.2'] += 1
                        elif confidence < 0.4:
                            confidence_ranges['0.2-0.4'] += 1
                        elif confidence < 0.6:
                            confidence_ranges['0.4-0.6'] += 1
                        elif confidence < 0.8:
                            confidence_ranges['0.6-0.8'] += 1
                        else:
                            confidence_ranges['0.8-1.0'] += 1

            # Заповнення статистики
            stats['detection_stats'] = {
                'total_detections': total_detections,
                'avg_confidence': total_confidence / total_detections if total_detections > 0 else 0,
                'class_distribution': class_counts,
                'confidence_distribution': confidence_ranges
            }

            # Оновлення поточної статистики
            self.current_stats['total_detections'] = total_detections
            self.current_stats['detections_by_class'] = class_counts
            self.current_stats['detections_by_confidence'] = confidence_ranges

        # Статистика по трекам
        if tracking_data:
            track_ids = set()
            track_lengths = {}
            track_confidences = {}

            for frame_data in tracking_data:
                for track in frame_data.get('tracks', []):
                    track_id = track.get('track_id', 0)
                    track_ids.add(track_id)

                    # Оновлення довжини треку
                    if track_id not in track_lengths:
                        track_lengths[track_id] = 0
                    track_lengths[track_id] += 1

                    # Оновлення впевненості треку
                    if track_id not in track_confidences:
                        track_confidences[track_id] = []
                    track_confidences[track_id].append(track.get('confidence', 0))

            # Розрахунок середніх значень
            avg_track_length = sum(track_lengths.values()) / len(track_lengths) if track_lengths else 0
            avg_confidences = {track_id: sum(confs) / len(confs) for track_id, confs in track_confidences.items()}

            # Заповнення статистики
            stats['tracking_stats'] = {
                'total_tracks': len(track_ids),
                'avg_track_length': avg_track_length,
                'max_track_length': max(track_lengths.values()) if track_lengths else 0,
                'min_track_length': min(track_lengths.values()) if track_lengths else 0,
                'track_lengths': track_lengths,
                'avg_confidences': avg_confidences
            }

            # Оновлення поточної статистики
            self.current_stats['total_tracks'] = len(track_ids)
            self.current_stats['avg_track_length'] = avg_track_length

        # Метрики моделі
        if metrics:
            stats['model_metrics'] = metrics

        return stats

    def _flatten_dict(self, d, parent_key='', sep='_'):
        """
        Перетворення вкладеного словника на плоский.

        Параметри:
        -----------
        d : dict
            Вхідний словник
        parent_key : str
            Ключ батьківського рівня
        sep : str
            Роздільник між ключами

        Повертає:
        -----------
        dict : Плоский словник
        """
        items = []
        for k, v in d.items():
            new_key = parent_key + sep + k if parent_key else k
            if isinstance(v, dict):
                items.extend(self._flatten_dict(v, new_key, sep=sep).items())
            else:
                items.append((new_key, v))
        return dict(items)

    def generate_pdf_report(self, detection_data=None, tracking_data=None,
                          metrics=None, report_type='full', output_path=None,
                          include_images=True, image_paths=None):
        """
        Генерація PDF-звіту зі статистикою та візуалізаціями.

        Параметри:
        -----------
        detection_data : list, опціонально
            Дані про виявлення
        tracking_data : list, опціонально
            Дані про треки
        metrics : dict, опціонально
            Метрики ефективності моделі
        report_type : str
            Тип звіту ('full', 'summary', 'detections', 'tracking')
        output_path : str, опціонально
            Шлях для збереження звіту
        include_images : bool
            Включати зображення у звіт
        image_paths : list, опціонально
            Список шляхів до зображень для включення

        Повертає:
        -----------
        str : Шлях до згенерованого PDF-звіту
        """
        if output_path is None:
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
            output_path = self.reports_dir / f"report_{report_type}_{timestamp}.pdf"
        else:
            output_path = Path(output_path)

        # Створення PDF-документа
        pdf = FPDF()
        pdf.set_auto_page_break(auto=True, margin=15)
        pdf.add_page()

        # Налаштування шрифтів
        pdf.add_font('DejaVu', '', 'DejaVuSansCondensed.ttf', uni=True)
        pdf.add_font('DejaVu', 'B', 'DejaVuSansCondensed-Bold.ttf', uni=True)

        # Заголовок звіту
        pdf.set_font('DejaVu', 'B', 16)
        pdf.cell(0, 10, 'Звіт про виявлення та відстеження дронів', 0, 1, 'C')

        # Дата і час генерації звіту
        pdf.set_font('DejaVu', '', 12)
        pdf.cell(0, 10, f'Дата створення: {datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")}', 0, 1, 'C')

        # Розділова лінія
        pdf.line(10, 30, 200, 30)
        pdf.ln(10)

        # Визначення вмісту звіту залежно від типу
        if report_type == 'full' or report_type == 'summary':
            self._add_summary_section(pdf, detection_data, tracking_data, metrics)

        if report_type == 'full' or report_type == 'detections':
            self._add_detections_section(pdf, detection_data)

        if report_type == 'full' or report_type == 'tracking':
            self._add_tracking_section(pdf, tracking_data)

        # Додавання зображень, якщо потрібно
        if include_images and image_paths:
            self._add_images_section(pdf, image_paths)

        # Збереження PDF-файлу
        try:
            pdf.output(str(output_path))
            self.logger.info(f"PDF-звіт успішно створено: {output_path}")
            return str(output_path)
        except Exception as e:
            self.logger.error(f"Помилка при створенні PDF-звіту: {e}")
            return None

    def _add_summary_section(self, pdf, detection_data, tracking_data, metrics):
        """
        Додавання розділу із загальною інформацією до PDF-звіту.

        Параметри:
        -----------
        pdf : FPDF
            Об'єкт PDF-документа
        detection_data : list
            Дані про виявлення
        tracking_data : list
            Дані про треки
        metrics : dict
            Метрики ефективності моделі
        """
        # Заголовок розділу
        pdf.set_font('DejaVu', 'B', 14)
        pdf.cell(0, 10, 'Загальна інформація', 0, 1, 'L')

        pdf.set_font('DejaVu', '', 12)

        # Основні статистичні дані
        stats = self._calculate_statistics(detection_data, tracking_data, metrics)

        # Виявлення
        if stats['detection_stats']:
            pdf.set_font('DejaVu', 'B', 12)
            pdf.cell(0, 10, 'Статистика виявлень:', 0, 1, 'L')
            pdf.set_font('DejaVu', '', 12)

            total_detections = stats['detection_stats'].get('total_detections', 0)
            avg_confidence = stats['detection_stats'].get('avg_confidence', 0)

            pdf.cell(0, 8, f'Кількість виявлень: {total_detections}', 0, 1, 'L')
            pdf.cell(0, 8, f'Середня впевненість: {avg_confidence:.3f}', 0, 1, 'L')

            # Розподіл за класами
            if 'class_distribution' in stats['detection_stats']:
                pdf.ln(5)
                pdf.set_font('DejaVu', 'B', 12)
                pdf.cell(0, 8, 'Розподіл за класами:', 0, 1, 'L')
                pdf.set_font('DejaVu', '', 12)

                for class_id, count in stats['detection_stats']['class_distribution'].items():
                    pdf.cell(0, 8, f'Клас {class_id}: {count} виявлень', 0, 1, 'L')

        # Треки
        if stats['tracking_stats']:
            pdf.ln(5)
            pdf.set_font('DejaVu', 'B', 12)
            pdf.cell(0, 10, 'Статистика треків:', 0, 1, 'L')
            pdf.set_font('DejaVu', '', 12)

            total_tracks = stats['tracking_stats'].get('total_tracks', 0)
            avg_length = stats['tracking_stats'].get('avg_track_length', 0)
            max_length = stats['tracking_stats'].get('max_track_length', 0)

            pdf.cell(0, 8, f'Кількість треків: {total_tracks}', 0, 1, 'L')
            pdf.cell(0, 8, f'Середня довжина треку: {avg_length:.1f} кадрів', 0, 1, 'L')
            pdf.cell(0, 8, f'Максимальна довжина треку: {max_length} кадрів', 0, 1, 'L')

        # Метрики моделі
        if stats['model_metrics']:
            pdf.ln(5)
            pdf.set_font('DejaVu', 'B', 12)
            pdf.cell(0, 10, 'Метрики моделі:', 0, 1, 'L')
            pdf.set_font('DejaVu', '', 12)

            for name, value in stats['model_metrics'].items():
                if isinstance(value, (int, float)):
                    pdf.cell(0, 8, f'{name}: {value:.4f}', 0, 1, 'L')

        # Додавання графіка з розподілом впевненості
        if stats['detection_stats'].get('confidence_distribution'):
            self._add_confidence_distribution_chart(pdf, stats['detection_stats']['confidence_distribution'])

        pdf.ln(10)

    def _add_detections_section(self, pdf, detection_data):
        """
        Додавання розділу з інформацією про виявлення до PDF-звіту.

        Параметри:
        -----------
        pdf : FPDF
            Об'єкт PDF-документа
        detection_data : list
            Дані про виявлення
        """
        if not detection_data:
            return

        # Додавання нової сторінки
        pdf.add_page()

        # Заголовок розділу
        pdf.set_font('DejaVu', 'B', 14)
        pdf.cell(0, 10, 'Детальна інформація про виявлення', 0, 1, 'L')

        # Обмеження кількості записів для відображення
        max_entries = 20
        entries_count = sum(len(group.get('detections', [])) for group in detection_data)

        pdf.set_font('DejaVu', '', 12)
        pdf.cell(0, 8, f'Загальна кількість записів: {entries_count}', 0, 1, 'L')
        pdf.cell(0, 8, f'Відображено перші {min(max_entries, entries_count)} записів', 0, 1, 'L')
        pdf.ln(5)

        # Таблиця з даними про виявлення
        col_widths = [15, 25, 25, 25, 25, 25]
        header = ['Кадр', 'Координати', 'Розмір', 'Впев.', 'Клас', 'Стан']

        # Заголовок таблиці
        pdf.set_font('DejaVu', 'B', 10)
        pdf.set_fill_color(200, 220, 255)

        for i, col in enumerate(header):
            pdf.cell(col_widths[i], 10, col, 1, 0, 'C', True)
        pdf.ln()

        # Дані таблиці
        pdf.set_font('DejaVu', '', 10)
        count = 0

        for group in detection_data:
            frame = group.get('frame', 0)

            for detection in group.get('detections', []):
                if count >= max_entries:
                    break

                if len(detection) >= 6:
                    x1, y1, x2, y2, confidence, class_id = detection[:6]

                    coordinates = f'({int(x1)},{int(y1)})-({int(x2)},{int(y2)})'
                    size = f'{int(x2-x1)}x{int(y2-y1)}'
                    confidence_str = f'{confidence:.3f}'

                    pdf.cell(col_widths[0], 8, str(frame), 1, 0, 'C')
                    pdf.cell(col_widths[1], 8, coordinates, 1, 0, 'C')
                    pdf.cell(col_widths[2], 8, size, 1, 0, 'C')
                    pdf.cell(col_widths[3], 8, confidence_str, 1, 0, 'C')
                    pdf.cell(col_widths[4], 8, f'Клас {class_id}', 1, 0, 'C')
                    pdf.cell(col_widths[5], 8, '', 1, 0, 'C')  # Стан відсутній для виявлень
                    pdf.ln()

                    count += 1

        pdf.ln(10)

        # Додавання розділу з аналізом
        pdf.set_font('DejaVu', 'B', 12)
        pdf.cell(0, 10, 'Аналіз виявлень', 0, 1, 'L')
        pdf.set_font('DejaVu', '', 12)

        # Розрахунок додаткової статистики
        class_counts = {}
        size_data = {'width': [], 'height': [], 'area': []}

        for group in detection_data:
            for detection in group.get('detections', []):
                if len(detection) >= 6:
                    x1, y1, x2, y2, _, class_id = detection[:6]

                    # Підрахунок класів
                    if class_id not in class_counts:
                        class_counts[class_id] = 0
                    class_counts[class_id] += 1

                    # Збір даних про розміри
                    width = x2 - x1
                    height = y2 - y1
                    area = width * height

                    size_data['width'].append(width)
                    size_data['height'].append(height)
                    size_data['area'].append(area)

        # Найпоширеніший клас
        if class_counts:
            most_common_class = max(class_counts.items(), key=lambda x: x[1])
            pdf.cell(0, 8, f'Найпоширеніший клас: Клас {most_common_class[0]} ({most_common_class[1]} виявлень)', 0, 1, 'L')

        # Середні розміри об'єктів
        if size_data['width'] and size_data['height']:
            avg_width = sum(size_data['width']) / len(size_data['width'])
            avg_height = sum(size_data['height']) / len(size_data['height'])
            pdf.cell(0, 8, f'Середній розмір об\'єкта: {avg_width:.1f} x {avg_height:.1f} пікселів', 0, 1, 'L')

        # Додавання графіка розмірів
        if size_data['width'] and size_data['height'] and size_data['area']:
            self._add_size_distribution_chart(pdf, size_data)

    def _add_tracking_section(self, pdf, tracking_data):
        """
        Додавання розділу з інформацією про треки до PDF-звіту.

        Параметри:
        -----------
        pdf : FPDF
            Об'єкт PDF-документа
        tracking_data : list
            Дані про треки
        """
        if not tracking_data:
            return

        # Додавання нової сторінки
        pdf.add_page()

        # Заголовок розділу
        pdf.set_font('DejaVu', 'B', 14)
        pdf.cell(0, 10, 'Детальна інформація про треки', 0, 1, 'L')

        # Аналіз даних про треки
        track_info = {}

        for frame_data in tracking_data:
            frame = frame_data.get('frame', 0)

            for track in frame_data.get('tracks', []):
                track_id = track.get('track_id')

                if track_id not in track_info:
                    track_info[track_id] = {
                        'frames': [],
                        'confidences': [],
                        'boxes': [],
                        'class_id': track.get('class_id'),
                        'state': track.get('state', '')
                    }

                track_info[track_id]['frames'].append(frame)
                track_info[track_id]['confidences'].append(track.get('confidence', 0))
                track_info[track_id]['boxes'].append(track.get('box', [0, 0, 0, 0]))

        # Статистика треків
        pdf.set_font('DejaVu', '', 12)
        pdf.cell(0, 8, f'Кількість треків: {len(track_info)}', 0, 1, 'L')

        # Визначення довжини треків
        track_lengths = {track_id: len(info['frames']) for track_id, info in track_info.items()}
        avg_length = sum(track_lengths.values()) / len(track_lengths) if track_lengths else 0
        max_track_id = max(track_lengths.items(), key=lambda x: x[1])[0] if track_lengths else None

        pdf.cell(0, 8, f'Середня довжина треку: {avg_length:.1f} кадрів', 0, 1, 'L')

        if max_track_id is not None:
            pdf.cell(0, 8, f'Найдовший трек: ID {max_track_id} ({track_lengths[max_track_id]} кадрів)', 0, 1, 'L')

        pdf.ln(5)

        # Таблиця з детальною інформацією про треки
        max_tracks = 10  # Обмеження кількості треків для відображення

        if track_info:
            pdf.set_font('DejaVu', 'B', 12)
            pdf.cell(0, 10, f'Топ {min(max_tracks, len(track_info))} треків за тривалістю:', 0, 1, 'L')

            # Заголовок таблиці
            col_widths = [15, 30, 30, 30, 30]
            header = ['ID', 'Довжина', 'Поч. кадр', 'Кін. кадр', 'Клас']

            pdf.set_font('DejaVu', 'B', 10)
            pdf.set_fill_color(200, 220, 255)

            for i, col in enumerate(header):
                pdf.cell(col_widths[i], 10, col, 1, 0, 'C', True)
            pdf.ln()

            # Дані таблиці
            pdf.set_font('DejaVu', '', 10)

            # Сортування треків за довжиною
            sorted_tracks = sorted(track_info.items(), key=lambda x: len(x[1]['frames']), reverse=True)

            for i, (track_id, info) in enumerate(sorted_tracks[:max_tracks]):
                frames = info['frames']
                first_frame = min(frames) if frames else 0
                last_frame = max(frames) if frames else 0
                track_length = len(frames)
                class_id = info['class_id']

                pdf.cell(col_widths[0], 8, str(track_id), 1, 0, 'C')
                pdf.cell(col_widths[1], 8, str(track_length), 1, 0, 'C')
                pdf.cell(col_widths[2], 8, str(first_frame), 1, 0, 'C')
                pdf.cell(col_widths[3], 8, str(last_frame), 1, 0, 'C')
                pdf.cell(col_widths[4], 8, f'Клас {class_id}', 1, 0, 'C')
                pdf.ln()

        pdf.ln(10)

        # Додавання графіка розподілу довжин треків
        if track_lengths:
            self._add_track_length_chart(pdf, track_lengths)

    def _add_images_section(self, pdf, image_paths):
        """
        Додавання розділу зі зображеннями до PDF-звіту.

        Параметри:
        -----------
        pdf : FPDF
            Об'єкт PDF-документа
        image_paths : list
            Список шляхів до зображень
        """
        if not image_paths:
            return

        # Додавання нової сторінки
        pdf.add_page()

        # Заголовок розділу
        pdf.set_font('DejaVu', 'B', 14)
        pdf.cell(0, 10, 'Галерея зображень', 0, 1, 'L')

        # Обмеження кількості зображень
        max_images = 6
        images_to_show = image_paths[:max_images]

        pdf.set_font('DejaVu', '', 12)
        pdf.cell(0, 8, f'Відображено {len(images_to_show)} з {len(image_paths)} зображень', 0, 1, 'L')
        pdf.ln(5)

        # Додавання зображень
        for i, image_path in enumerate(images_to_show):
            if Path(image_path).exists():
                # Визначення розмірів для зображення (підлаштування під розмір сторінки)
                img_width = 180  # максимальна ширина в мм
                img_height = 100  # максимальна висота в мм

                try:
                    pdf.image(image_path, x=15, y=pdf.get_y(), w=img_width)
                    pdf.ln(img_height + 10)  # відступ після зображення

                    # Додавання підпису
                    pdf.cell(0, 8, f'Зображення {i+1}: {Path(image_path).name}', 0, 1, 'C')
                    pdf.ln(5)
                except Exception as e:
                    pdf.cell(0, 8, f'Помилка завантаження зображення {Path(image_path).name}: {e}', 0, 1, 'L')
                    pdf.ln(5)

    def _add_confidence_distribution_chart(self, pdf, confidence_data):
        """
        Додавання графіка розподілу впевненості до PDF-звіту.

        Параметри:
        -----------
        pdf : FPDF
            Об'єкт PDF-документа
        confidence_data : dict
            Дані про розподіл впевненості
        """
        # Створення графіка
        plt.figure(figsize=(8, 4))

        # Підготовка даних
        ranges = list(confidence_data.keys())
        counts = list(confidence_data.values())

        # Побудова графіка
        plt.bar(ranges, counts, color='skyblue', edgecolor='navy')
        plt.title('Розподіл впевненості виявлень')
        plt.xlabel('Діапазон впевненості')
        plt.ylabel('Кількість виявлень')
        plt.xticks(rotation=45)
        plt.tight_layout()

        # Збереження графіка у тимчасовий файл
        img_path = self.output_dir / 'temp_confidence_chart.png'
        plt.savefig(img_path)
        plt.close()

        # Додавання графіка до PDF-звіту
        pdf.ln(10)
        pdf.cell(0, 8, 'Розподіл впевненості виявлень:', 0, 1, 'L')
        pdf.image(str(img_path), x=15, y=pdf.get_y(), w=180)
        pdf.ln(90)  # Відступ після графіка

        # Видалення тимчасового файлу
        try:
            os.remove(img_path)
        except:
            pass

    def _add_size_distribution_chart(self, pdf, size_data):
        """
        Додавання графіка розподілу розмірів до PDF-звіту.

        Параметри:
        -----------
        pdf : FPDF
            Об'єкт PDF-документа
        size_data : dict
            Дані про розміри об'єктів
        """
        # Створення графіка
        plt.figure(figsize=(8, 8))

        # Підготовка даних
        widths = size_data['width']
        heights = size_data['height']
        areas = size_data['area']

        # Графік 1: Гістограма ширин
        plt.subplot(2, 2, 1)
        plt.hist(widths, bins=20, color='skyblue', edgecolor='navy', alpha=0.7)
        plt.title('Розподіл ширин')
        plt.xlabel('Ширина (пікселі)')
        plt.ylabel('Кількість')

        # Графік 2: Гістограма висот
        plt.subplot(2, 2, 2)
        plt.hist(heights, bins=20, color='lightgreen', edgecolor='darkgreen', alpha=0.7)
        plt.title('Розподіл висот')
        plt.xlabel('Висота (пікселі)')
        plt.ylabel('Кількість')

        # Графік 3: Гістограма площ
        plt.subplot(2, 2, 3)
        plt.hist(areas, bins=20, color='salmon', edgecolor='red', alpha=0.7)
        plt.title('Розподіл площ')
        plt.xlabel('Площа (пікселі²)')
        plt.ylabel('Кількість')

        # Графік 4: Діаграма розсіювання ширина/висота
        plt.subplot(2, 2, 4)
        plt.scatter(widths, heights, alpha=0.5, s=10, c='blue')
        plt.title('Співвідношення ширина/висота')
        plt.xlabel('Ширина (пікселі)')
        plt.ylabel('Висота (пікселі)')

        plt.tight_layout()

        # Збереження графіка у тимчасовий файл
        img_path = self.output_dir / 'temp_size_chart.png'
        plt.savefig(img_path)
        plt.close()

        # Додавання графіка до PDF-звіту
        pdf.ln(10)
        pdf.cell(0, 8, 'Аналіз розмірів виявлених об\'єктів:', 0, 1, 'L')
        pdf.image(str(img_path), x=15, y=pdf.get_y(), w=180)
        pdf.ln(180)  # Відступ після графіка

        # Видалення тимчасового файлу
        try:
            os.remove(img_path)
        except:
            pass

    def _add_track_length_chart(self, pdf, track_lengths):
        """
        Додавання графіка розподілу довжин треків до PDF-звіту.

        Параметри:
        -----------
        pdf : FPDF
            Об'єкт PDF-документа
        track_lengths : dict
            Словник з довжинами треків у форматі {track_id: length}
        """
        # Створення графіка
        plt.figure(figsize=(8, 6))

        # Підготовка даних
        lengths = list(track_lengths.values())

        # Гістограма довжин треків
        plt.hist(lengths, bins=20, color='skyblue', edgecolor='navy', alpha=0.7)
        plt.title('Розподіл довжин треків')
        plt.xlabel('Довжина треку (кадри)')
        plt.ylabel('Кількість треків')
        plt.grid(alpha=0.3)

        # Додавання статистичної інформації
        avg_length = sum(lengths) / len(lengths) if lengths else 0
        max_length = max(lengths) if lengths else 0
        min_length = min(lengths) if lengths else 0

        plt.axvline(avg_length, color='red', linestyle='dashed', linewidth=2, label=f'Середнє: {avg_length:.1f}')
        plt.legend()

        # Додавання текстової інформації
        text_info = (
            f"Середня довжина: {avg_length:.1f} кадрів\n"
            f"Максимальна довжина: {max_length} кадрів\n"
            f"Мінімальна довжина: {min_length} кадрів\n"
            f"Всього треків: {len(lengths)}"
        )
        plt.figtext(0.15, 0.02, text_info, fontsize=10,
                    bbox=dict(facecolor='white', alpha=0.8))

        plt.tight_layout()

        # Збереження графіка у тимчасовий файл
        img_path = self.output_dir / 'temp_track_length_chart.png'
        plt.savefig(img_path)
        plt.close()

        # Додавання графіка до PDF-звіту
        pdf.ln(10)
        pdf.cell(0, 8, 'Розподіл довжин треків:', 0, 1, 'L')
        pdf.image(str(img_path), x=15, y=pdf.get_y(), w=180)
        pdf.ln(130)  # Відступ після графіка

        # Видалення тимчасового файлу
        try:
            os.remove(img_path)
        except:
            pass

#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Система виявлення та відстеження дронів - Головний скрипт
===========================================================

Цей скрипт об'єднує всі модулі системи виявлення дронів
та надає централізований інтерфейс для роботи з ними.

Модулі системи:
1. Модуль роботи з даними - обробка та підготовка датасету
2. Модуль виявлення дронів - імплементація моделі YOLOv8
3. Модуль відстеження дронів - трекінг з використанням фільтра Калмана
4. Модуль фільтрації хибних спрацьовувань - аналіз часової узгодженості
5. Модуль візуалізації результатів - генерація теплових карт та графіків
6. Модуль інференсу для нових даних - обробка в реальному часі
7. Модуль експорту та звітності - експорт у різні формати

"""

import os
import sys
import argparse
import time
import json
import datetime
from pathlib import Path
import cv2
import numpy as np
import torch
import logging
import threading

# Імпорт модулів системи - вони вже доступні як локальні об'єкти в блокноті
# Не потрібний import, оскільки класи вже визначені в попередніх комірках

# Налаштування логування
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("drone_system.log"),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger("DroneDetectionSystem")

class DroneDetectionSystem:
    """
    Основний клас системи виявлення та відстеження дронів.
    Інтегрує всі модулі та надає єдиний інтерфейс керування.
    """

    def __init__(self, base_dir="drone_system", config_path=None):
        """
        Ініціалізація системи виявлення дронів.

        Параметри:
        -----------
        base_dir : str
            Базова директорія для зберігання даних та результатів
        config_path : str, optional
            Шлях до конфігураційного файлу
        """
        self.base_dir = Path(base_dir)
        self.base_dir.mkdir(exist_ok=True)

        # Створення піддиректорій
        self.data_dir = self.base_dir / "data"
        self.models_dir = self.base_dir / "models"
        self.results_dir = self.base_dir / "results"
        self.export_dir = self.base_dir / "exports"

        for directory in [self.data_dir, self.models_dir, self.results_dir, self.export_dir]:
            directory.mkdir(exist_ok=True)

        # Завантаження конфігурації
        self.config = self._load_config(config_path)

        # Ініціалізація модулів
        self.data_processor = None
        self.detector = None
        self.tracker = None
        self.filter = None
        self.visualizer = None
        self.inference = None
        self.exporter = None

        # Статус системи
        self.is_initialized = False
        self.is_running = False
        self.status = {
            "data_processed": False,
            "model_trained": False,
            "model_loaded": False,
            "last_operation": None,
            "last_operation_time": None
        }

        logger.info(f"Система виявлення дронів ініціалізована. Базова директорія: {self.base_dir}")

    def _load_config(self, config_path=None):
        """
        Завантаження конфігурації системи з файлу.

        Параметри:
        -----------
        config_path : str, optional
            Шлях до конфігураційного файлу

        Повертає:
        -----------
        dict : Конфігурація системи
        """
        default_config = {
            "data": {
                "dataset_id": "dasmehdixtr/drone-dataset-uav",
                "train_ratio": 0.7,
                "valid_ratio": 0.2,
                "test_ratio": 0.1
            },
            "model": {
                "model_size": "m",
                "confidence_threshold": 0.25,
                "iou_threshold": 0.45,
                "device": None  # автоматичний вибір
            },
            "tracker": {
                "max_age": 30,
                "min_hits": 3,
                "iou_threshold": 0.3
            },
            "filter": {
                "temporal_window": 5,
                "min_detections": 3,
                "confidence_threshold": 0.3
            },
            "inference": {
                "batch_size": 1,
                "skip_frames": 0,
                "resize_factor": 1.0
            },
            "class_names": ["drone"]
        }

        if config_path and Path(config_path).exists():
            try:
                with open(config_path, 'r') as f:
                    loaded_config = json.load(f)

                # Оновлюємо значення за замовчуванням
                for section, params in loaded_config.items():
                    if section in default_config:
                        if isinstance(params, dict):
                            default_config[section].update(params)
                        else:
                            default_config[section] = params
                    else:
                        default_config[section] = params

                logger.info(f"Завантажено конфігурацію з {config_path}")
            except Exception as e:
                logger.error(f"Помилка при завантаженні конфігурації: {e}")

        return default_config

    def initialize_all_modules(self):
        """
        Ініціалізація всіх модулів системи.

        Повертає:
        -----------
        bool : True, якщо ініціалізація успішна
        """
        try:
            # Ініціалізація модуля обробки даних
            self.data_processor = DataProcessor(base_path=str(self.data_dir))
            logger.info("Модуль обробки даних ініціалізовано")

            # Ініціалізація модуля детектора
            model_config = self.config.get("model", {})
            device = model_config.get("device")
            model_size = model_config.get("model_size", "m")

            self.detector = DroneDetector(model_size=model_size)
            logger.info(f"Модуль детектора ініціалізовано (модель: YOLOv8{model_size})")

            # Ініціалізація модуля трекера
            tracker_config = self.config.get("tracker", {})
            self.tracker = DroneTracker(
                max_age=tracker_config.get("max_age", 30),
                min_hits=tracker_config.get("min_hits", 3),
                iou_threshold=tracker_config.get("iou_threshold", 0.3)
            )
            logger.info("Модуль трекера ініціалізовано")

            # Ініціалізація модуля фільтрації
            filter_config = self.config.get("filter", {})
            self.filter = FalsePositiveFilter(
                temporal_window=filter_config.get("temporal_window", 5),
                min_detections=filter_config.get("min_detections", 3),
                confidence_threshold=filter_config.get("confidence_threshold", 0.3)
            )
            logger.info("Модуль фільтрації ініціалізовано")

            # Ініціалізація модуля візуалізації
            self.visualizer = ResultsVisualizer(output_dir=str(self.results_dir))
            logger.info("Модуль візуалізації ініціалізовано")

            # Ініціалізація модуля інференсу
            inference_config = self.config.get("inference", {})
            self.inference = RealTimeInference(
                detector=self.detector,
                tracker=self.tracker,
                filter=self.filter,
                visualizer=self.visualizer,
                output_dir=str(self.results_dir),
                device=device
            )
            logger.info("Модуль інференсу ініціалізовано")

            # Ініціалізація модуля експорту
            self.exporter = ExportReporting(output_dir=str(self.export_dir))
            logger.info("Модуль експорту ініціалізовано")

            # Встановлення імен класів для всіх модулів
            class_names = self.config.get("class_names", ["drone"])

            if hasattr(self.detector, 'set_class_names'):
                self.detector.set_class_names(class_names)

            if hasattr(self.inference, 'set_class_names'):
                self.inference.set_class_names(class_names)

            # Статус системи
            self.is_initialized = True
            self._update_status("all_modules_initialized")

            return True

        except Exception as e:
            logger.error(f"Помилка при ініціалізації модулів: {e}")
            return False

    def process_dataset(self, dataset_id=None, train_ratio=None, valid_ratio=None, test_ratio=None):
        """
        Обробка датасету для навчання моделі.

        Параметри:
        -----------
        dataset_id : str, optional
            Ідентифікатор датасету на Kaggle
        train_ratio : float, optional
            Частка даних для навчання
        valid_ratio : float, optional
            Частка даних для валідації
        test_ratio : float, optional
            Частка даних для тестування

        Повертає:
        -----------
        dict : Результати обробки даних
        """
        if not self.is_initialized:
            self.initialize_all_modules()

        # Отримання параметрів з конфігурації, якщо не вказані
        data_config = self.config.get("data", {})

        if dataset_id is None:
            dataset_id = data_config.get("dataset_id", "dasmehdixtr/drone-dataset-uav")

        if train_ratio is None:
            train_ratio = data_config.get("train_ratio", 0.7)

        if valid_ratio is None:
            valid_ratio = data_config.get("valid_ratio", 0.2)

        if test_ratio is None:
            test_ratio = data_config.get("test_ratio", 0.1)

        logger.info(f"Початок обробки датасету: {dataset_id}")

        try:
            # Обробка датасету
            results = self.data_processor.process_dataset(
                dataset_id=dataset_id,
                train_ratio=train_ratio,
                valid_ratio=valid_ratio,
                test_ratio=test_ratio
            )

            # Оновлення статусу
            self.status["data_processed"] = True
            self._update_status("dataset_processed")

            logger.info(f"Датасет успішно оброблено: {results['dataset_path']}")

            return results

        except Exception as e:
            logger.error(f"Помилка при обробці датасету: {e}")
            return None

    def train_model(self, epochs=50, batch_size=16, imgsz=640, patience=15):
        """
        Навчання моделі на обробленому датасеті.

        Параметри:
        -----------
        epochs : int
            Кількість епох навчання
        batch_size : int
            Розмір батчу
        imgsz : int
            Розмір вхідних зображень
        patience : int
            Параметр раннього зупинення

        Повертає:
        -----------
        str : Шлях до навченої моделі
        """
        if not self.is_initialized:
            self.initialize_all_modules()

        if not self.status["data_processed"]:
            logger.warning("Дані не оброблені. Спочатку виконайте process_dataset()")
            return None

        logger.info(f"Початок навчання моделі: {epochs} епох, розмір батчу {batch_size}")

        try:
            # Навчання моделі
            model_path = self.detector.train(
                epochs=epochs,
                batch_size=batch_size,
                imgsz=imgsz,
                patience=patience
            )

            # Оновлення статусу
            self.status["model_trained"] = True
            self._update_status("model_trained")

            logger.info(f"Модель успішно навчена: {model_path}")

            return model_path

        except Exception as e:
            logger.error(f"Помилка при навчанні моделі: {e}")
            return None

    def load_model(self, model_path=None):
        """
        Завантаження попередньо навченої моделі.

        Параметри:
        -----------
        model_path : str, optional
            Шлях до файлу моделі

        Повертає:
        -----------
        bool : True, якщо модель успішно завантажена
        """
        if not self.is_initialized:
            self.initialize_all_modules()

        try:
            # Якщо шлях до моделі не вказаний, намагаємося знайти раніше навчену
            if model_path is None:
                model_dir = self.models_dir

                # Пошук останньої навченої моделі
                model_files = list(model_dir.glob("*.pt"))

                if model_files:
                    # Сортування за часом зміни (від нових до старих)
                    model_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)
                    model_path = str(model_files[0])
                    logger.info(f"Знайдено раніше навчену модель: {model_path}")
                else:
                    model_path = None

            # Завантаження моделі
            success = self.detector.load_model(model_path)

            if success:
                # Оновлення статусу
                self.status["model_loaded"] = True
                self._update_status("model_loaded")

                logger.info(f"Модель успішно завантажена: {model_path}")
            else:
                logger.warning("Використовується попередньо навчена модель YOLOv8")

            return success

        except Exception as e:
            logger.error(f"Помилка при завантаженні моделі: {e}")
            return False

    def process_image(self, image_path, output_path=None, conf_threshold=None,
                     apply_tracking=True, apply_filtering=True):
        """
        Обробка одного зображення з виявленням дронів.

        Параметри:
        -----------
        image_path : str
            Шлях до зображення
        output_path : str, optional
            Шлях для збереження результату
        conf_threshold : float, optional
            Поріг впевненості для виявлення
        apply_tracking : bool
            Застосовувати відстеження
        apply_filtering : bool
            Застосовувати фільтрацію хибних спрацьовувань

        Повертає:
        -----------
        tuple : (Оброблене зображення, результати виявлення)
        """
        if not self.is_initialized:
            self.initialize_all_modules()

        if not self.status["model_loaded"]:
            self.load_model()

        # Отримання порогу впевненості з конфігурації, якщо не вказано
        if conf_threshold is None:
            conf_threshold = self.config.get("model", {}).get("confidence_threshold", 0.25)

        logger.info(f"Обробка зображення: {image_path}")

        try:
            # Завантаження зображення
            image = cv2.imread(image_path)
            if image is None:
                logger.error(f"Не вдалося завантажити зображення: {image_path}")
                return None, []

            # Виявлення дронів
            detection_results = self.detector.detect(image, conf=conf_threshold)

            # Отримання виявлень
            detections = []
            if len(detection_results) > 0:
                boxes = detection_results[0].boxes
                for box in boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    conf = box.conf[0].cpu().numpy()
                    cls = box.cls[0].cpu().numpy()
                    detections.append([x1, y1, x2, y2, conf, cls])

            # Застосування фільтрації, якщо потрібно
            if apply_filtering and self.filter is not None:
                filtered_detections = self.filter.filter_detections(detections, image)
            else:
                filtered_detections = detections

            # Застосування трекінгу, якщо потрібно
            tracking_results = []
            if apply_tracking and self.tracker is not None:
                tracking_results = [{
                    'frame': 0,
                    'timestamp': 0,
                    'tracks': self.tracker.update(filtered_detections)
                }]

            # Візуалізація результатів
            if apply_tracking and tracking_results:
                processed_image = self.visualizer.visualize_tracking_paths(
                    tracking_results, image.shape, min_track_length=1,
                    overlay_image=image, class_names=self.config.get("class_names")
                )
            else:
                processed_image = self.visualizer.visualize_detection(
                    image, filtered_detections, class_names=self.config.get("class_names")
                )

            # Збереження результату, якщо вказано шлях
            if output_path:
                output_path = str(Path(output_path))
                cv2.imwrite(output_path, processed_image)
                logger.info(f"Результат збережено: {output_path}")

            return processed_image, filtered_detections

        except Exception as e:
            logger.error(f"Помилка при обробці зображення: {e}")
            return None, []

    def process_video(self, video_path, output_path=None, conf_threshold=None,
                     apply_tracking=True, apply_filtering=True, show_progress=True,
                     display=False):
        """
        Обробка відео з виявленням та відстеженням дронів.

        Параметри:
        -----------
        video_path : str
            Шлях до відеофайлу
        output_path : str, optional
            Шлях для збереження результату
        conf_threshold : float, optional
            Поріг впевненості для виявлення
        apply_tracking : bool
            Застосовувати відстеження
        apply_filtering : bool
            Застосовувати фільтрацію хибних спрацьовувань
        show_progress : bool
            Показувати прогрес-бар
        display : bool
            Відображати оброблене відео в реальному часі

        Повертає:
        -----------
        dict : Результати обробки відео
        """
        if not self.is_initialized:
            self.initialize_all_modules()

        if not self.status["model_loaded"]:
            self.load_model()

        # Отримання порогу впевненості з конфігурації, якщо не вказано
        if conf_threshold is None:
            conf_threshold = self.config.get("model", {}).get("confidence_threshold", 0.25)

        logger.info(f"Обробка відео: {video_path}")

        try:
            # Використання модуля інференсу для обробки відео
            results = self.inference.process_video(
                video_source=video_path,
                output_path=output_path,
                display=display,
                save_detections=True
            )

            if results["success"]:
                logger.info(f"Відео успішно оброблено: {results['results'].get('output_path')}")
                self._update_status("video_processed")
            else:
                logger.error("Помилка при обробці відео")

            return results

        except Exception as e:
            logger.error(f"Помилка при обробці відео: {e}")
            return {"success": False, "error": str(e)}

    def start_realtime_detection(self, source=0, display=True, output_path=None,
                               apply_tracking=True, apply_filtering=True):
        """
        Запуск виявлення дронів у режимі реального часу.

        Параметри:
        -----------
        source : int або str
            Джерело відео (індекс камери або URL)
        display : bool
            Відображати оброблене відео
        output_path : str, optional
            Шлях для збереження результату
        apply_tracking : bool
            Застосовувати відстеження
        apply_filtering : bool
            Застосовувати фільтрацію хибних спрацьовувань

        Повертає:
        -----------
        bool : True, якщо обробка успішно запущена
        """
        if not self.is_initialized:
            self.initialize_all_modules()

        if not self.status["model_loaded"]:
            self.load_model()

        logger.info(f"Запуск виявлення в реальному часі, джерело: {source}")

        try:
            # Запуск обробки в реальному часі
            success = self.inference.start_realtime_processing(
                source=source,
                display=display,
                output_path=output_path
            )

            if success:
                self.is_running = True
                self._update_status("realtime_detection_started")
                logger.info("Виявлення в реальному часі запущено")
            else:
                logger.error("Помилка при запуску виявлення в реальному часі")

            return success

        except Exception as e:
            logger.error(f"Помилка при запуску виявлення в реальному часі: {e}")
            return False

    def stop_realtime_detection(self):
        """
        Зупинка виявлення дронів у режимі реального часу.

        Повертає:
        -----------
        bool : True, якщо обробка успішно зупинена
        """
        if not self.is_running:
            logger.warning("Виявлення в реальному часі не запущено")
            return False

        try:
            success = self.inference.stop_processing()

            if success:
                self.is_running = False
                self._update_status("realtime_detection_stopped")
                logger.info("Виявлення в реальному часі зупинено")
            else:
                logger.error("Помилка при зупинці виявлення в реальному часі")

            return success

        except Exception as e:
            logger.error(f"Помилка при зупинці виявлення в реальному часі: {e}")
            return False

    def export_results(self, data, export_formats=None, include_visualization=True,
                     include_statistics=True, export_name=None, compress=True):
        """
        Експорт результатів виявлення та відстеження в різні формати.

        Параметри:
        -----------
        data : dict
            Дані для експорту
        export_formats : list, optional
            Список форматів експорту
        include_visualization : bool
            Включати візуалізації в експорт
        include_statistics : bool
            Включати статистику в експорт
        export_name : str, optional
            Ім'я експорту
        compress : bool
            Стискати результати в архів

        Повертає:
        -----------
        dict : Шляхи до створених файлів
        """
        if not self.is_initialized:
            self.initialize_all_modules()

        try:
            # Експорт даних
            result_paths = self.exporter.create_batch_export(
                data=data,
                export_formats=export_formats,
                include_visualization=include_visualization,
                include_statistics=include_statistics,
                batch_name=export_name,
                compress=compress
            )

            self._update_status("results_exported")
            logger.info(f"Результати успішно експортовано")

            return result_paths

        except Exception as e:
            logger.error(f"Помилка при експорті результатів: {e}")
            return None

    def generate_report(self, detection_data=None, tracking_data=None, metrics=None,
                      report_type='full', output_path=None, include_images=True,
                      image_paths=None):
        """
        Генерація звіту за результатами виявлення та відстеження.

        Параметри:
        -----------
        detection_data : list, optional
            Дані про виявлення
        tracking_data : list, optional
            Дані про треки
        metrics : dict, optional
            Метрики ефективності моделі
        report_type : str
            Тип звіту ('full', 'summary', 'detections', 'tracking')
        output_path : str, optional
            Шлях для збереження звіту
        include_images : bool
            Включати зображення у звіт
        image_paths : list, optional
            Список шляхів до зображень для включення

        Повертає:
        -----------
        str : Шлях до згенерованого звіту
        """
        if not self.is_initialized:
            self.initialize_all_modules()

        try:
            # Генерація звіту
            report_path = self.exporter.generate_pdf_report(
                detection_data=detection_data,
                tracking_data=tracking_data,
                metrics=metrics,
                report_type=report_type,
                output_path=output_path,
                include_images=include_images,
                image_paths=image_paths
            )

            if report_path:
                self._update_status("report_generated")
                logger.info(f"Звіт успішно згенеровано: {report_path}")
                return report_path
            else:
                logger.error("Помилка при генерації звіту")
                return None

        except Exception as e:
            logger.error(f"Помилка при генерації звіту: {e}")
            return None

    def visualize_results(self, data, visualization_type, output_path=None):
        """
        Створення візуалізацій результатів виявлення та відстеження.

        Параметри:
        -----------
        data : dict або list
            Дані для візуалізації
        visualization_type : str
            Тип візуалізації ('detection', 'tracking', 'heatmap', 'statistics')
        output_path : str, optional
            Шлях для збереження візуалізації

        Повертає:
        -----------
        str або matplotlib.figure.Figure : Шлях до створеної візуалізації або об'єкт Figure
        """
        if not self.is_initialized:
            self.initialize_all_modules()

        try:
            result = None

            # Візуалізація залежно від типу
            if visualization_type == 'detection':
                if isinstance(data, list) and len(data) > 0 and 'detections' in data[0]:
                    # Візуалізація виявлень на зображенні
                    image = cv2.imread(data.get('image_path', 'test_image.jpg'))
                    detections = data[0]['detections']

                    result = self.visualizer.visualize_detection(
                        image, detections,
                        class_names=self.config.get("class_names"),
                        output_path=output_path
                    )

            elif visualization_type == 'tracking':
                if isinstance(data, list):
                    # Візуалізація траєкторій руху
                    frame_shape = data.get('frame_shape', (720, 1280))

                    result = self.visualizer.visualize_tracking_paths(
                        data, frame_shape,
                        class_names=self.config.get("class_names"),
                        output_path=output_path
                    )

            elif visualization_type == 'heatmap':
                if isinstance(data, list):
                    # Створення теплової карти
                    frame_shape = data.get('frame_shape', (720, 1280))

                    if 'detections' in data[0]:
                        # Теплова карта за даними виявлень
                        detections = []
                        for item in data:
                            detections.extend(item['detections'])

                        result = self.visualizer.generate_heatmap(
                            detections, frame_shape,
                            output_path=output_path
                        )
                    elif 'tracks' in data[0]:
                        # Теплова карта за даними треків
                        result = self.visualizer.generate_heatmap_from_tracking(
                            data, frame_shape,
                            output_path=output_path
                        )

            elif visualization_type == 'statistics':
                if isinstance(data, dict):
                    # Візуалізація статистики
                    if 'confidence_distribution' in data:
                        result = self.visualizer.plot_confidence_distribution(
                            data['confidence_distribution'],
                            output_path=output_path
                        )
                    elif 'size_distribution' in data:
                        result = self.visualizer.plot_size_distribution(
                            data['size_distribution'],
                            output_path=output_path
                        )
                    elif 'metrics' in data:
                        result = self.visualizer.plot_metrics_over_time(
                            data['metrics'],
                            list(data['metrics'].keys()),
                            output_path=output_path
                        )

            elif visualization_type == 'interactive':
                if isinstance(data, list):
                    # Створення інтерактивної візуалізації
                    if 'tracks' in data[0]:
                        result = self.visualizer.create_interactive_trajectory_plot(
                            data,
                            output_path=output_path,
                            class_names=self.config.get("class_names")
                        )
                    else:
                        result = self.visualizer.create_interactive_detection_timeline(
                            data,
                            output_path=output_path,
                            class_names=self.config.get("class_names")
                        )

            if result:
                self._update_status("visualization_created")
                logger.info(f"Візуалізацію успішно створено")
                return result
            else:
                logger.warning(f"Не вдалося створити візуалізацію типу {visualization_type}")
                return None

        except Exception as e:
            logger.error(f"Помилка при створенні візуалізації: {e}")
            return None

    def evaluate_model(self, test_data=None, conf_threshold=None, iou_threshold=None):
        """
        Оцінка ефективності моделі на тестових даних.

        Параметри:
        -----------
        test_data : str, optional
            Шлях до тестових даних
        conf_threshold : float, optional
            Поріг впевненості для виявлення
        iou_threshold : float, optional
            Поріг IoU для NMS

        Повертає:
        -----------
        dict : Метрики ефективності
        """
        if not self.is_initialized:
            self.initialize_all_modules()

        if not self.status["model_loaded"]:
            self.load_model()

        # Отримання порогів з конфігурації, якщо не вказані
        model_config = self.config.get("model", {})

        if conf_threshold is None:
            conf_threshold = model_config.get("confidence_threshold", 0.25)

        if iou_threshold is None:
            iou_threshold = model_config.get("iou_threshold", 0.45)

        logger.info("Початок оцінки ефективності моделі")

        try:
            # Оцінка моделі
            metrics = self.detector.evaluate(
                test_data=test_data,
                conf=conf_threshold,
                iou=iou_threshold
            )

            self._update_status("model_evaluated")
            logger.info(f"Оцінка ефективності моделі завершена")

            return metrics

        except Exception as e:
            logger.error(f"Помилка при оцінці ефективності моделі: {e}")
            return None

    def optimize_performance(self, target_fps=30):
        """
        Оптимізація параметрів системи для досягнення заданої продуктивності.

        Параметри:
        -----------
        target_fps : int
            Цільова кількість кадрів на секунду

        Повертає:
        -----------
        dict : Оптимізовані параметри
        """
        if not self.is_initialized:
            self.initialize_all_modules()

        if not self.status["model_loaded"]:
            self.load_model()

        logger.info(f"Оптимізація параметрів для досягнення {target_fps} FPS")

        try:
            # Оптимізація через модуль інференсу
            optimized_params = self.inference.optimize_performance(target_fps=target_fps)

            # Оновлення параметрів у конфігурації
            inference_config = self.config.get("inference", {})
            inference_config.update(optimized_params)

            self._update_status("performance_optimized")
            logger.info(f"Параметри успішно оптимізовано: {optimized_params}")

            return optimized_params

        except Exception as e:
            logger.error(f"Помилка при оптимізації параметрів: {e}")
            return None

    def setup_multi_camera_system(self, camera_sources):
        """
        Налаштування системи для роботи з кількома камерами.

        Параметри:
        -----------
        camera_sources : dict
            Словник з джерелами камер {camera_id: source}

        Повертає:
        -----------
        bool : True, якщо налаштування успішне
        """
        if not self.is_initialized:
            self.initialize_all_modules()

        if not self.status["model_loaded"]:
            self.load_model()

        logger.info(f"Налаштування мультикамерної системи з {len(camera_sources)} камерами")

        try:
            # Налаштування через модуль інференсу
            success = self.inference.setup_multi_camera(camera_sources)

            if success:
                self._update_status("multi_camera_setup")
                logger.info("Мультикамерну систему успішно налаштовано")
            else:
                logger.error("Помилка при налаштуванні мультикамерної системи")

            return success

        except Exception as e:
            logger.error(f"Помилка при налаштуванні мультикамерної системи: {e}")
            return False

    def start_multi_camera_detection(self, display=True, output_dir=None):
        """
        Запуск виявлення дронів з кількох камер.

        Параметри:
        -----------
        display : bool
            Відображати оброблене відео
        output_dir : str, optional
            Директорія для збереження результатів

        Повертає:
        -----------
        bool : True, якщо обробка успішно запущена
        """
        if not self.is_initialized:
            self.initialize_all_modules()

        logger.info("Запуск мультикамерного виявлення")

        try:
            # Запуск мультикамерної обробки
            success = self.inference.start_multi_camera_processing(
                display=display,
                output_dir=output_dir
            )

            if success:
                self.is_running = True
                self._update_status("multi_camera_detection_started")
                logger.info("Мультикамерне виявлення запущено")
            else:
                logger.error("Помилка при запуску мультикамерного виявлення")

            return success

        except Exception as e:
            logger.error(f"Помилка при запуску мультикамерного виявлення: {e}")
            return False

    def save_system_config(self, config_path=None):
        """
        Збереження поточної конфігурації системи.

        Параметри:
        -----------
        config_path : str, optional
            Шлях для збереження конфігурації

        Повертає:
        -----------
        str : Шлях до збереженої конфігурації
        """
        if config_path is None:
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
            config_path = self.base_dir / f"config_{timestamp}.json"
        else:
            config_path = Path(config_path)

        try:
            # Оновлення конфігурації поточними значеннями
            config_to_save = self.config.copy()

            # Додавання статусу системи
            config_to_save["system_status"] = self.status

            # Збереження конфігурації в JSON
            with open(config_path, 'w') as f:
                json.dump(config_to_save, f, indent=4)

            logger.info(f"Конфігурацію системи збережено: {config_path}")
            return str(config_path)

        except Exception as e:
            logger.error(f"Помилка при збереженні конфігурації: {e}")
            return None

    def _update_status(self, operation):
        """
        Оновлення статусу системи.

        Параметри:
        -----------
        operation : str
            Виконана операція
        """
        self.status["last_operation"] = operation
        self.status["last_operation_time"] = datetime.datetime.now().isoformat()

# Демонстраційний скрипт для системи виявлення та відстеження дронів
# Цей скрипт демонструє роботу всіх 7 модулів системи

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import kagglehub
import time
from pathlib import Path
from tqdm import tqdm
import torch
import zipfile
import shutil

# Перевірка доступності GPU
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Використовується пристрій: {device}")

# Створення базової директорії для результатів
base_dir = Path("./drone_system_results")
base_dir.mkdir(exist_ok=True)

# Step 1: Завантаження та підготовка даних
print("\n" + "="*80)
print("Етап 1: Завантаження та підготовка даних")
print("="*80)

# Завантаження датасету з Kaggle
print("Завантаження датасету дронів з Kaggle...")
try:
    # Проксі-функція для завантаження, якщо є проблеми з kagglehub
    def download_dataset():
        dataset_path = kagglehub.dataset_download('dasmehdixtr/drone-dataset-uav')
        return dataset_path

    dataset_path = download_dataset()
    print(f"Датасет завантажено за шляхом: {dataset_path}")

    # Ініціалізація обробника даних
    data_processor = DataProcessor(base_path='./drone_data')

    # Обробка даних (без повторного завантаження датасету)
    # Пошук анотацій у завантаженому датасеті
    annotation_dir = os.path.join(dataset_path, 'drone_dataset_yolo/dataset_txt')
    annotation_paths = data_processor.find_annotations(annotation_dir)

    # Розділення датасету
    split_info = data_processor.split_dataset(annotation_paths)

    # Копіювання файлів у відповідні директорії
    data_processor.copy_files_to_folders(annotation_paths, split_info)

    # Створення конфігураційного файлу YAML
    data_processor.create_yaml_config()

    # Візуалізація зразків з тренувального набору
    data_processor.visualize_samples(sample_count=3, dataset_type='train')

    data_yaml_path = 'data.yaml'
    print(f"Підготовка даних завершена! Конфігураційний файл створено: {data_yaml_path}")

except Exception as e:
    print(f"Помилка при завантаженні або підготовці даних: {e}")
    print("Використовуємо попередньо встановлені дані для демонстрації...")
    data_yaml_path = 'data.yaml'

# Step 2: Виявлення дронів
print("\n" + "="*80)
print("Етап 2: Виявлення дронів (YOLOv8)")
print("="*80)

# Ініціалізація та навчання детектора
print("Ініціалізація детектора дронів...")
detector = DroneDetector(config_path=data_yaml_path, model_size='s')

# Завантаження попередньо навченої моделі для демонстрації
print("Завантаження попередньо навченої моделі YOLO...")
detector.load_model()

# Вибір тестового зображення
test_images_dir = os.path.join('drone_data', 'test')
test_images = [os.path.join(test_images_dir, f) for f in os.listdir(test_images_dir)
              if f.endswith(('.jpg', '.jpeg', '.png')) and os.path.exists(os.path.join(test_images_dir, f))]

if test_images:
    test_image_path = test_images[0]
    print(f"Демонстрація виявлення на тестовому зображенні: {test_image_path}")

    # Запуск виявлення
    detection_results = detector.detect(test_image_path, conf=0.25, show=True)

    # Візуалізація результатів
    detector.visualize_detection_results(detection_results)

    # Збереження результатів для подальшого використання
    detection_output_path = os.path.join(base_dir, "detection_result.jpg")

    # Перетворення результатів у формат для трекера
    detections = []
    if len(detection_results) > 0:
        boxes = detection_results[0].boxes
        for box in boxes:
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
            conf = box.conf[0].cpu().numpy()
            cls = box.cls[0].cpu().numpy()
            detections.append([x1, y1, x2, y2, conf, cls])

    print(f"Виявлено об'єктів: {len(detections)}")
else:
    print("Тестові зображення не знайдено. Створюємо тестові дані...")
    # Створюємо тестові дані для демонстрації
    test_image = np.zeros((640, 640, 3), dtype=np.uint8)
    cv2.rectangle(test_image, (100, 100), (200, 200), (0, 255, 0), 2)
    test_image_path = os.path.join(base_dir, "test_image.jpg")
    cv2.imwrite(test_image_path, test_image)

    # Імітація даних виявлення
    detections = [
        [100, 100, 200, 200, 0.85, 0],
        [300, 300, 400, 400, 0.72, 0]
    ]
    print(f"Створено тестові дані з {len(detections)} об'єктами")

# Step 3: Відстеження дронів
print("\n" + "="*80)
print("Етап 3: Відстеження дронів")
print("="*80)

# Створення спрощеного трекера, що не використовує linear_sum_assignment
class SimpleTracker:
    """
    Спрощений трекер дронів для демонстрації, що не залежить від scipy.
    """
    def __init__(self, max_age=30, min_hits=3, iou_threshold=0.3):
        self.max_age = max_age
        self.min_hits = min_hits
        self.iou_threshold = iou_threshold
        self.tracks = []
        self.track_id_count = 0

    def _calculate_iou(self, box1, box2):
        """
        Розрахунок IoU (Intersection over Union) між двома обмежувальними рамками.
        """
        # Розпакування координат
        x1_1, y1_1, x2_1, y2_1 = box1
        x1_2, y1_2, x2_2, y2_2 = box2

        # Розрахунок координат перетину
        x1_i = max(x1_1, x1_2)
        y1_i = max(y1_1, y1_2)
        x2_i = min(x2_1, x2_2)
        y2_i = min(y2_1, y2_2)

        # Розрахунок площі перетину
        if x2_i < x1_i or y2_i < y1_i:
            # Немає перетину
            return 0.0

        intersection_area = (x2_i - x1_i) * (y2_i - y1_i)

        # Розрахунок площ обох обмежувальних рамок
        box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)
        box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)

        # Розрахунок IoU
        iou = intersection_area / float(box1_area + box2_area - intersection_area)

        return iou

    def update(self, detections, frame=None):
        """
        Оновлення треків з новими виявленнями.
        """
        # Якщо немає активних треків, створюємо нові треки для всіх виявлень
        if not self.tracks:
            for det in detections:
                track_id = self.track_id_count
                self.track_id_count += 1
                x1, y1, x2, y2, conf, cls = det
                # Формат: [x1, y1, x2, y2, track_id, confidence, class_id, state]
                self.tracks.append([x1, y1, x2, y2, track_id, conf, cls, "confirmed"])
            return self.tracks

        # Якщо є активні треки, оновлюємо їх
        updated_tracks = []

        # Для кожного виявлення
        for det in detections:
            x1, y1, x2, y2, conf, cls = det
            best_iou = 0
            best_track_idx = -1

            # Шукаємо найкращий відповідний трек за IoU
            for i, track in enumerate(self.tracks):
                iou = self._calculate_iou([x1, y1, x2, y2], track[:4])
                if iou > self.iou_threshold and iou > best_iou:
                    best_iou = iou
                    best_track_idx = i

            # Якщо знайдено відповідний трек, оновлюємо його
            if best_track_idx >= 0:
                updated_track = self.tracks[best_track_idx].copy()
                updated_track[0] = x1  # Оновлюємо координати
                updated_track[1] = y1
                updated_track[2] = x2
                updated_track[3] = y2
                updated_track[5] = conf  # Оновлюємо впевненість
                updated_track[6] = cls   # Оновлюємо клас
                updated_tracks.append(updated_track)
            else:
                # Створюємо новий трек
                track_id = self.track_id_count
                self.track_id_count += 1
                updated_tracks.append([x1, y1, x2, y2, track_id, conf, cls, "tentative"])

        # Зберігаємо оновлені треки
        self.tracks = updated_tracks

        return self.tracks

    def analyze_trajectories(self, tracking_data, fps=30, min_track_length=5, output_path=None):
        """
        Аналіз траєкторій руху.
        """
        print("Аналіз траєкторій руху об'єктів...")

        # Структурування даних за треками
        tracks_by_id = {}

        for frame_data in tracking_data:
            for track in frame_data.get('tracks', []):
                track_id = track.get('track_id')

                if track_id not in tracks_by_id:
                    tracks_by_id[track_id] = {
                        'frames': [],
                        'confidences': [],
                        'boxes': [],
                        'class_id': track.get('class_id'),
                        'state': track.get('state', '')
                    }

                tracks_by_id[track_id]['frames'].append(frame_data.get('frame'))
                tracks_by_id[track_id]['confidences'].append(track.get('confidence', 0))
                tracks_by_id[track_id]['boxes'].append(track.get('box', [0, 0, 0, 0]))

        # Фільтрація коротких треків
        tracks_by_id = {k: v for k, v in tracks_by_id.items() if len(v['frames']) >= min_track_length}

        # Розрахунок середньої довжини треку
        avg_track_length = 0
        if tracks_by_id:
            avg_track_length = sum(len(v['frames']) for v in tracks_by_id.values()) / len(tracks_by_id)

        # Збереження результатів аналізу
        if output_path:
            analysis_results = {
                'total_tracks': len(tracks_by_id),
                'avg_track_length': avg_track_length,
                'tracks': {str(k): v for k, v in tracks_by_id.items()}
            }

            with open(output_path, 'w') as f:
                json.dump(analysis_results, f, indent=2)

            print(f"Результати аналізу траєкторій збережено у: {output_path}")

        print("Аналіз траєкторій завершено.")
        print(f"Загальна кількість треків: {len(tracks_by_id)}")
        print(f"Середня тривалість треку: {avg_track_length:.1f} кадрів")

        return {
            'trajectory_analysis': tracks_by_id,
            'summary': {
                'total_tracks': len(tracks_by_id),
                'avg_track_length': avg_track_length
            }
        }

    def visualize_tracks_summary(self, tracking_data, frame_shape, output_path=None):
        """
        Візуалізація шляхів переміщення об'єктів.
        """
        # Створення порожнього зображення
        height, width = frame_shape[:2]
        vis_image = np.ones((height, width, 3), dtype=np.uint8) * 255

        # Структурування даних за треками
        tracks_by_id = {}

        for frame_data in tracking_data:
            for track in frame_data.get('tracks', []):
                track_id = track.get('track_id')

                if track_id not in tracks_by_id:
                    tracks_by_id[track_id] = {
                        'centroids': [],
                        'confidences': [],
                        'class_id': track.get('class_id'),
                        'state': track.get('state', '')
                    }

                # Отримання обмежувальної рамки
                box = track.get('box', [0, 0, 0, 0])

                # Розрахунок центроїда
                center_x = (box[0] + box[2]) / 2
                center_y = (box[1] + box[3]) / 2

                tracks_by_id[track_id]['centroids'].append((center_x, center_y))
                tracks_by_id[track_id]['confidences'].append(track.get('confidence', 0))

        # Різні кольори для різних треків
        colors = [
            (0, 255, 0),     # Зелений
            (255, 0, 0),     # Синій
            (0, 0, 255),     # Червоний
            (255, 255, 0),   # Блакитний
            (0, 255, 255),   # Жовтий
            (255, 0, 255)    # Фіолетовий
        ]

        # Візуалізація треків
        for track_id, track_data in tracks_by_id.items():
            if len(track_data['centroids']) < 2:
                continue

            # Отримання кольору
            color = colors[track_id % len(colors)]

            # Малювання траєкторії
            for i in range(1, len(track_data['centroids'])):
                pt1 = tuple(map(int, track_data['centroids'][i-1]))
                pt2 = tuple(map(int, track_data['centroids'][i]))
                cv2.line(vis_image, pt1, pt2, color, 2)

            # Малювання початкової та кінцевої точок
            start_point = tuple(map(int, track_data['centroids'][0]))
            end_point = tuple(map(int, track_data['centroids'][-1]))

            cv2.circle(vis_image, start_point, 5, (0, 255, 0), -1)  # Зелений для початку
            cv2.circle(vis_image, end_point, 5, (0, 0, 255), -1)    # Червоний для кінця

            # Додавання ідентифікатора треку
            cv2.putText(vis_image, f"ID: {track_id}", end_point,
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)

        # Збереження візуалізації
        if output_path is not None:
            cv2.imwrite(output_path, vis_image)
            print(f"Візуалізацію треків збережено у: {output_path}")

        return vis_image

# Ініціалізація спрощеного трекера
print("Ініціалізація трекера дронів...")
tracker = SimpleTracker()

# Імітація серії кадрів для демонстрації відстеження
print("Підготовка даних для відстеження...")

# Завантаження вихідного зображення для відстеження
if os.path.exists(test_image_path):
    frame = cv2.imread(test_image_path)
    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    frame_shape = frame.shape
else:
    # Створюємо тестове зображення, якщо не знайдено
    frame = np.zeros((640, 640, 3), dtype=np.uint8)
    frame_shape = frame.shape

# Імітація трекінгу для декількох кадрів
tracking_results = []
num_frames = 10

print(f"Моделювання відстеження об'єктів на {num_frames} кадрах...")
for i in range(num_frames):
    # Імітація руху об'єктів (невеликі зміни координат)
    current_detections = []
    for det in detections:
        x1, y1, x2, y2, conf, cls = det
        # Додаємо випадковий рух
        shift_x = np.random.randint(-5, 6)
        shift_y = np.random.randint(-5, 6)
        new_det = [
            max(0, x1 + shift_x),
            max(0, y1 + shift_y),
            min(frame.shape[1], x2 + shift_x),
            min(frame.shape[0], y2 + shift_y),
            conf * (0.95 + 0.1 * np.random.random()),  # Випадкова зміна впевненості
            cls
        ]
        current_detections.append(new_det)

    # Оновлення трекера
    tracks = tracker.update(current_detections)

    # Збереження результатів трекінгу
    tracking_results.append({
        'frame': i,
        'timestamp': i / 30.0,  # 30 fps
        'tracks': [
            {
                'track_id': int(track[4]),
                'box': [float(track[0]), float(track[1]), float(track[2]), float(track[3])],
                'confidence': float(track[5]),
                'class_id': int(track[6]),
                'state': track[7]
            }
            for track in tracks
        ]
    })

print(f"Відстеження завершено. Отримано {len(tracking_results)} кадрів з треками.")

# Візуалізація результатів відстеження
print("Візуалізація траєкторій руху...")
tracks_image = tracker.visualize_tracks_summary(tracking_results, frame_shape)
tracking_output_path = os.path.join(base_dir, "tracking_results.jpg")
cv2.imwrite(tracking_output_path, cv2.cvtColor(tracks_image, cv2.COLOR_RGB2BGR))
print(f"Результати відстеження збережено в: {tracking_output_path}")

# Аналіз траєкторій
print("Аналіз траєкторій руху...")
trajectory_analysis = tracker.analyze_trajectories(
    tracking_results,
    fps=30,
    output_path=os.path.join(base_dir, "trajectory_analysis.json")
)

# Step 4: Фільтрація хибних спрацьовувань
print("\n" + "="*80)
print("Етап 4: Фільтрація хибних спрацьовувань")
print("="*80)

# Ініціалізація фільтра хибних спрацьовувань
print("Ініціалізація фільтра хибних спрацьовувань...")

# Спрощена версія фільтра
class SimpleFilter:
    """
    Спрощена версія фільтра хибних спрацьовувань для демонстрації.
    """
    def __init__(self, confidence_threshold=0.3, min_size=10):
        """
        Ініціалізація спрощеного фільтра.

        Параметри:
        -----------
        confidence_threshold : float
            Поріг впевненості для фільтрації виявлень
        min_size : int
            Мінімальний розмір об'єкта (в пікселях)
        """
        self.confidence_threshold = confidence_threshold
        self.min_size = min_size
        self.stats = {'total': 0, 'filtered_out': 0, 'passed': 0}

    def filter_detections(self, detections, frame=None):
        """
        Фільтрація виявлень.

        Параметри:
        -----------
        detections : list
            Список виявлень у форматі [[x1, y1, x2, y2, conf, class_id], ...]
        frame : numpy.ndarray, опціонально
            Кадр для контекстного аналізу

        Повертає:
        -----------
        list : Список відфільтрованих виявлень
        """
        self.stats['total'] += len(detections)
        filtered = []

        for det in detections:
            if len(det) >= 6:
                x1, y1, x2, y2, conf, cls = det

                # Перевірка впевненості
                if conf < self.confidence_threshold:
                    self.stats['filtered_out'] += 1
                    continue

                # Перевірка розміру
                width = x2 - x1
                height = y2 - y1
                if width < self.min_size or height < self.min_size:
                    self.stats['filtered_out'] += 1
                    continue

                # Виявлення пройшло фільтрацію
                filtered.append(det)
                self.stats['passed'] += 1

        return filtered

    def _draw_filtered_detections(self, frame, filtered_detections):
        """
        Візуалізація відфільтрованих виявлень на кадрі.

        Параметри:
        -----------
        frame : numpy.ndarray
            Кадр для візуалізації
        filtered_detections : list
            Список відфільтрованих виявлень

        Повертає:
        -----------
        numpy.ndarray : Кадр з візуалізованими виявленнями
        """
        output_frame = frame.copy()

        # Малювання виявлень
        for det in filtered_detections:
            x1, y1, x2, y2, conf, cls = det

            # Перетворення у цілі числа
            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)

            # Колір для виявлення
            color = (0, 255, 0)  # Зелений для пройдених фільтрацію

            # Малювання обмежувальної рамки
            cv2.rectangle(output_frame, (x1, y1), (x2, y2), color, 2)

            # Малювання підпису
            label = f"Клас {int(cls)} {conf:.2f}"
            cv2.putText(output_frame, label, (x1, y1 - 5),
                      cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

        # Додавання інформації про статистику фільтрації
        cv2.putText(output_frame,
                   f"Загально: {self.stats['total']}, Відфільтровано: {self.stats['filtered_out']}, Пройшло: {self.stats['passed']}",
                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

        return output_frame

    def get_filtering_summary(self):
        """
        Отримання текстового звіту зі статистикою фільтрації.

        Повертає:
        -----------
        str : Текстовий звіт
        """
        return f"""
=== Звіт про фільтрацію хибних спрацьовувань ===
Загальна кількість виявлень: {self.stats['total']}
Кількість відфільтрованих виявлень: {self.stats['filtered_out']} ({self.stats['filtered_out']/max(1, self.stats['total'])*100:.1f}%)
Кількість пройдених виявлень: {self.stats['passed']} ({self.stats['passed']/max(1, self.stats['total'])*100:.1f}%)
"""

# Використовуємо спрощену версію фільтра
filter = SimpleFilter(
    confidence_threshold=0.3,
    min_size=10
)

# Додавання кількох хибних спрацьовувань для демонстрації
print("Додавання тестових хибних спрацьовувань...")
test_detections = current_detections.copy()
# Додаємо кілька маленьких об'єктів з низькою впевненістю
test_detections.append([10, 10, 15, 15, 0.2, 0])  # Маленький об'єкт з низькою впевненістю
test_detections.append([500, 500, 505, 505, 0.25, 0])  # Ще один маленький об'єкт

# Фільтрація детекцій
print("Застосування фільтрації...")
filtered_detections = filter.filter_detections(test_detections, frame)

print(f"До фільтрації: {len(test_detections)} об'єктів")
print(f"Після фільтрації: {len(filtered_detections)} об'єктів")

# Візуалізація результатів фільтрації
filtered_frame = filter._draw_filtered_detections(frame, filtered_detections)
filter_output_path = os.path.join(base_dir, "filtered_results.jpg")
cv2.imwrite(filter_output_path, cv2.cvtColor(filtered_frame, cv2.COLOR_RGB2BGR))
print(f"Результати фільтрації збережено в: {filter_output_path}")

# Генерація статистики фільтрації
filter_stats = filter.get_filtering_summary()
print("\nСтатистика фільтрації:")
print(filter_stats)

# Step 5: Візуалізація результатів
print("\n" + "="*80)
print("Етап 5: Візуалізація результатів")
print("="*80)

# Спрощена версія візуалізатора
class SimpleVisualizer:
    """
    Спрощена версія візуалізатора результатів для демонстрації.
    """
    def __init__(self, output_dir='visualizations'):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)

    def visualize_detection(self, image, detections, class_names=None, output_path=None):
        """
        Візуалізація виявлень на зображенні.
        """
        output_image = image.copy()

        # Малювання виявлень
        for detection in detections:
            x1, y1, x2, y2, confidence, class_id = detection

            # Перетворення в цілі числа
            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
            class_id = int(class_id)

            # Вибір кольору залежно від класу
            color = (0, 255, 0)  # Зелений для основного класу

            # Малювання обмежувальної рамки
            cv2.rectangle(output_image, (x1, y1), (x2, y2), color, 2)

            # Отримання назви класу
            if class_names is not None and class_id < len(class_names):
                class_name = class_names[class_id]
            else:
                class_name = f"Клас {class_id}"

            # Малювання підпису
            label = f"{class_name} {confidence:.2f}"
            cv2.putText(output_image, label, (x1, y1 - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)

        # Додавання інформації про кількість виявлень
        info_text = f"Виявлено об'єктів: {len(detections)}"
        cv2.putText(output_image, info_text, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)

        # Збереження результату
        if output_path is not None:
            cv2.imwrite(output_path, cv2.cvtColor(output_image, cv2.COLOR_RGB2BGR))
            print(f"Зображення з виявленнями збережено у: {output_path}")

        return output_image

    def generate_heatmap(self, detections, frame_shape, output_path=None):
        """
        Генерація теплової карти розподілу виявлень.
        """
        # Створення порожньої теплової карти
        height, width = frame_shape[:2]
        heatmap = np.zeros((height, width), dtype=np.float32)

        # Додавання виявлень до теплової карти
        for det in detections:
            x1, y1, x2, y2, conf, _ = det

            # Розрахунок центроїда
            center_x = int((x1 + x2) / 2)
            center_y = int((y1 + y2) / 2)

            # Додавання до теплової карти (з урахуванням впевненості)
            if 0 <= center_x < width and 0 <= center_y < height:
                heatmap[center_y, center_x] += conf

        # Розмиття теплової карти для покращення візуалізації
        heatmap = cv2.GaussianBlur(heatmap, (0, 0), 15)

        # Нормалізація теплової карти
        if np.max(heatmap) > 0:
            heatmap = heatmap / np.max(heatmap)

        # Перетворення теплової карти в кольорове зображення
        heatmap_colored = cv2.applyColorMap((heatmap * 255).astype(np.uint8), cv2.COLORMAP_JET)

        # Збереження теплової карти
        if output_path is not None:
            cv2.imwrite(output_path, heatmap_colored)
            print(f"Теплову карту збережено у: {output_path}")

        return heatmap_colored

    def visualize_tracking_paths(self, tracking_data, frame_shape, min_track_length=2,
                               overlay_image=None, output_path=None, class_names=None):
        """
        Візуалізація шляхів переміщення об'єктів.
        """
        # Створення порожнього зображення або використання накладеного
        if overlay_image is not None:
            if overlay_image.shape[:2] != frame_shape[:2]:
                overlay_image = cv2.resize(overlay_image, (frame_shape[1], frame_shape[0]))
            vis_image = overlay_image.copy()
        else:
            vis_image = np.ones((frame_shape[0], frame_shape[1], 3), dtype=np.uint8) * 255

        # Структурування даних за треками
        tracks_by_id = {}

        for frame_data in tracking_data:
            for track in frame_data.get('tracks', []):
                track_id = track.get('track_id')

                if track_id not in tracks_by_id:
                    tracks_by_id[track_id] = {
                        'centroids': [],
                        'class_id': track.get('class_id', 0)
                    }

                # Отримання обмежувальної рамки
                box = track.get('box', [0, 0, 0, 0])

                # Розрахунок центроїда
                center_x = (box[0] + box[2]) / 2
                center_y = (box[1] + box[3]) / 2

                tracks_by_id[track_id]['centroids'].append((center_x, center_y))

        # Фільтрація коротких треків
        tracks_by_id = {k: v for k, v in tracks_by_id.items()
                       if len(v['centroids']) >= min_track_length}

        # Різні кольори для різних треків
        colors = [
            (0, 255, 0),     # Зелений
            (255, 0, 0),     # Синій
            (0, 0, 255),     # Червоний
            (255, 255, 0),   # Блакитний
            (0, 255, 255),   # Жовтий
            (255, 0, 255)    # Фіолетовий
        ]

        # Візуалізація треків
        for track_id, track_data in tracks_by_id.items():
            # Отримання кольору
            color = colors[int(track_id) % len(colors)]

            # Малювання траєкторії
            centroids = track_data['centroids']
            for i in range(1, len(centroids)):
                pt1 = tuple(map(int, centroids[i-1]))
                pt2 = tuple(map(int, centroids[i]))
                cv2.line(vis_image, pt1, pt2, color, 2)

            # Малювання початкової та кінцевої точок
            start_point = tuple(map(int, centroids[0]))
            end_point = tuple(map(int, centroids[-1]))

            cv2.circle(vis_image, start_point, 5, (0, 255, 0), -1)  # Зелений для початку
            cv2.circle(vis_image, end_point, 5, (0, 0, 255), -1)    # Червоний для кінця

            # Додавання ідентифікатора треку
            class_name = ""
            if class_names is not None and track_data['class_id'] < len(class_names):
                class_name = class_names[track_data['class_id']]

            label = f"ID: {track_id}"
            if class_name:
                label += f" ({class_name})"

            cv2.putText(vis_image, label, (end_point[0] + 10, end_point[1]),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

        # Додавання інформації про кількість треків
        info_text = f"Кількість треків: {len(tracks_by_id)}"
        cv2.putText(vis_image, info_text, (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)

        # Збереження результату
        if output_path is not None:
            cv2.imwrite(output_path, cv2.cvtColor(vis_image, cv2.COLOR_RGB2BGR))
            print(f"Візуалізацію шляхів збережено у: {output_path}")

        return vis_image

    def plot_confidence_distribution(self, detections, output_path=None):
        """
        Побудова графіка розподілу впевненості виявлень.
        """
        if not detections:
            return None

        # Отримання значень впевненості
        confidences = [det[4] for det in detections]

        # Створення графіка
        plt.figure(figsize=(10, 6))

        # Побудова гістограми
        n, bins, patches = plt.hist(confidences, bins=20, alpha=0.7, color='skyblue',
                                   edgecolor='black')

        # Додавання середньої лінії
        plt.axvline(np.mean(confidences), color='red', linestyle='dashed', linewidth=2,
                   label=f'Середнє: {np.mean(confidences):.3f}')

        # Налаштування графіка
        plt.title('Розподіл впевненості виявлень', fontsize=14)
        plt.xlabel('Впевненість', fontsize=12)
        plt.ylabel('Кількість виявлень', fontsize=12)
        plt.grid(axis='y', alpha=0.75)
        plt.legend()

        # Збереження графіка
        if output_path is not None:
            plt.savefig(output_path)
            print(f"Графік розподілу впевненості збережено у: {output_path}")

        return plt.gcf()

# Ініціалізація візуалізатора
print("Ініціалізація модуля візуалізації...")
visualizer = SimpleVisualizer(output_dir=os.path.join(base_dir, 'visualizations'))

# Візуалізація детекцій
print("Створення візуалізації детекцій...")
detection_vis = visualizer.visualize_detection(
    frame,
    filtered_detections,
    class_names=['drone'],
    output_path=os.path.join(base_dir, 'visualizations', 'detection_visualization.jpg')
)

# Створення теплової карти
print("Створення теплової карти розподілу дронів...")
heatmap = visualizer.generate_heatmap(
    filtered_detections,
    frame_shape,
    output_path=os.path.join(base_dir, 'visualizations', 'detection_heatmap.jpg')
)

# Візуалізація траєкторій
print("Візуалізація траєкторій руху...")
path_vis = visualizer.visualize_tracking_paths(
    tracking_results,
    frame_shape,
    min_track_length=2,
    overlay_image=frame,
    output_path=os.path.join(base_dir, 'visualizations', 'tracking_paths.jpg')
)

# Створення графіка розподілу впевненості
print("Створення графіка розподілу впевненості...")
confidence_values = [det[4] for det in filtered_detections]
conf_fig = visualizer.plot_confidence_distribution(
    filtered_detections,
    output_path=os.path.join(base_dir, 'visualizations', 'confidence_distribution.png')
)

# Step 6: Інференс у режимі реального часу (імітація)
print("\n" + "="*80)
print("Етап 6: Інференс у режимі реального часу (імітація)")
print("="*80)

# Спрощена версія інференсу в реальному часі
class SimpleRealTimeInference:
    """
    Спрощена версія системи інференсу в реальному часі для демонстрації.
    """
    def __init__(self, detector=None, tracker=None, filter=None, visualizer=None, output_dir='inference_results'):
        self.detector = detector
        self.tracker = tracker
        self.filter = filter
        self.visualizer = visualizer
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.frame_count = 0
        self.processing_fps = 0

        # Параметри оптимізації
        self.batch_size = 1
        self.skip_frames = 0
        self.resize_factor = 1.0
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

        # Статистика
        self.performance_metrics = {
            'inference_times': [],
            'cpu_usage': [],
            'memory_usage': []
        }

        self.detection_stats = {
            'total_frames': 0,
            'frames_with_detections': 0,
            'total_detections': 0
        }

    def optimize_performance(self, target_fps=30):
        """
        Імітація оптимізації параметрів продуктивності.
        """
        print("Оптимізація параметрів продуктивності...")

        # Визначення оптимальних параметрів
        if self.device == 'cpu':
            self.batch_size = 1
            self.skip_frames = 1
            self.resize_factor = 0.75
        else:
            self.batch_size = 4
            self.skip_frames = 0
            self.resize_factor = 1.0

        return {
            'device': self.device,
            'batch_size': self.batch_size,
            'skip_frames': self.skip_frames,
            'resize_factor': self.resize_factor
        }

    def process_frame(self, frame, frame_index=None):
        """
        Обробка одного кадру для виявлення та відстеження дронів.
        """
        if frame is None:
            return None, [], []

        # Збільшення лічильника кадрів
        self.frame_count += 1
        if frame_index is None:
            frame_index = self.frame_count

        # Імітація роботи детектора
        start_time = time.time()

        # Виявлення дронів (спрощена імітація)
        detections = []
        for i in range(2):  # Імітуємо 2 виявлення
            x = np.random.randint(50, frame.shape[1] - 100)
            y = np.random.randint(50, frame.shape[0] - 100)
            w = np.random.randint(50, 100)
            h = np.random.randint(50, 100)
            confidence = np.random.uniform(0.6, 0.9)
            detections.append([x, y, x+w, y+h, confidence, 0])

        # Фільтрація виявлень
        if self.filter:
            detections = self.filter.filter_detections(detections, frame)

        # Відстеження дронів
        tracking_results = []
        if self.tracker:
            tracks = self.tracker.update(detections)
            tracking_results = [{
                'frame': frame_index,
                'timestamp': frame_index / 30.0,  # Приблизний час
                'tracks': [
                    {
                        'track_id': int(track[4]),
                        'box': [float(track[0]), float(track[1]), float(track[2]), float(track[3])],
                        'confidence': float(track[5]),
                        'class_id': int(track[6]),
                        'state': track[7]
                    }
                    for track in tracks
                ]
            }]

        # Візуалізація результатів
        output_frame = frame.copy()

        # Додавання номера кадру
        cv2.putText(output_frame, f"Frame: {frame_index}", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

        # Малювання виявлень
        for det in detections:
            x1, y1, x2, y2, conf, cls = det
            cv2.rectangle(output_frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
            label = f"Drone {conf:.2f}"
            cv2.putText(output_frame, label, (int(x1), int(y1) - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        # Розрахунок FPS
        process_time = time.time() - start_time
        self.performance_metrics['inference_times'].append(process_time)
        self.processing_fps = 1.0 / process_time if process_time > 0 else 0

        # Додавання інформації про FPS
        cv2.putText(output_frame, f"FPS: {self.processing_fps:.1f}", (10, 60),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

        # Оновлення статистики
        self.detection_stats['total_frames'] += 1
        if detections:
            self.detection_stats['frames_with_detections'] += 1
            self.detection_stats['total_detections'] += len(detections)

        return output_frame, detections, tracking_results

    def get_performance_report(self):
        """
        Отримання звіту про продуктивність системи.
        """
        # Розрахунок середніх значень
        avg_inference_time = sum(self.performance_metrics['inference_times']) / max(1, len(self.performance_metrics['inference_times']))

        return {
            'device': self.device,
            'processing_fps': self.processing_fps,
            'avg_inference_time': avg_inference_time,
            'batch_size': self.batch_size,
            'skip_frames': self.skip_frames,
            'resize_factor': self.resize_factor,
            'detection_stats': self.detection_stats
        }

# Ініціалізація системи інференсу
print("Ініціалізація системи інференсу в реальному часі...")
inference = SimpleRealTimeInference(
    detector=detector,
    tracker=tracker,
    filter=filter,
    visualizer=visualizer,
    output_dir=os.path.join(base_dir, 'inference_results')
)

# Оптимізація продуктивності
print("Оптимізація параметрів продуктивності...")
optimization_params = inference.optimize_performance(target_fps=30)
print(f"Оптимізовані параметри: {optimization_params}")

# Імітація обробки кадрів (замість відео)
print("Імітація обробки відеопотоку...")
inference_results = []
for i in tqdm(range(5)):  # Обробляємо 5 тестових кадрів
    # Створюємо копію кадру з невеликими змінами для імітації відео
    frame_copy = frame.copy()

    # Додаємо текст для відображення кадру
    cv2.putText(
        frame_copy, f"Frame: {i+1}",
        (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2
    )

    # Обробка кадру
    processed_frame, detections, tracking = inference.process_frame(frame_copy, i)

    # Збереження результатів
    inference_results.append({
        'frame': i,
        'detections': detections,
        'tracking': tracking
    })

    # Збереження обробленого кадру
    output_path = os.path.join(base_dir, 'inference_results', f"frame_{i+1}.jpg")
    cv2.imwrite(output_path, cv2.cvtColor(processed_frame, cv2.COLOR_RGB2BGR))

    # Імітація затримки для демонстрації
    time.sleep(0.1)

print(f"Обробка завершена. Результати збережено в {os.path.join(base_dir, 'inference_results')}")

# Отримання звіту про продуктивність
performance_report = inference.get_performance_report()
print("\nЗвіт про продуктивність системи:")
for key, value in performance_report.items():
    if isinstance(value, (int, float)):
        print(f"{key}: {value}")
    elif isinstance(value, dict) and key == 'detection_stats':
        print(f"{key}:")
        for subkey, subvalue in value.items():
            if not isinstance(subvalue, dict):
                print(f"  {subkey}: {subvalue}")

# Step 7: Експорт та звітність
print("\n" + "="*80)
print("Етап 7: Експорт результатів та створення звітів")
print("="*80)

# Спрощена версія модуля експорту та звітності
class SimpleExportReporting:
    """
    Спрощена версія модуля експорту та звітності для демонстрації.
    """
    def __init__(self, output_dir='export_results'):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)

        # Створення піддиректорій
        self.csv_dir = self.output_dir / 'csv'
        self.json_dir = self.output_dir / 'json'
        self.reports_dir = self.output_dir / 'reports'

        for directory in [self.csv_dir, self.json_dir, self.reports_dir]:
            directory.mkdir(exist_ok=True)

    def export_to_csv(self, data, filename=None, data_type='detections', extra_info=None):
        """
        Експорт даних у формат CSV.
        """
        if not data:
            return None

        # Генерація імені файлу
        if filename is None:
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"{data_type}_{timestamp}"

        # Шлях до файлу
        file_path = self.csv_dir / f"{filename}.csv"

        try:
            # Підготовка даних для CSV
            rows = []

            if data_type == 'detections':
                # Експорт даних про виявлення
                for detection_group in data:
                    frame = detection_group.get('frame', 0)
                    for detection in detection_group.get('detections', []):
                        if len(detection) >= 6:
                            x1, y1, x2, y2, conf, cls = detection[:6]
                            rows.append({
                                'frame': frame,
                                'x1': x1, 'y1': y1, 'x2': x2, 'y2': y2,
                                'confidence': conf, 'class_id': cls
                            })

            elif data_type == 'tracks':
                # Експорт даних про треки
                for track_data in data:
                    frame = track_data.get('frame', 0)
                    for track in track_data.get('tracks', []):
                        box = track.get('box', [0, 0, 0, 0])
                        rows.append({
                            'frame': frame,
                            'track_id': track.get('track_id', 0),
                            'x1': box[0], 'y1': box[1], 'x2': box[2], 'y2': box[3],
                            'confidence': track.get('confidence', 0),
                            'class_id': track.get('class_id', 0)
                        })

            # Запис даних у CSV
            if rows:
                with open(file_path, 'w', newline='') as csvfile:
                    # Визначення заголовків
                    fieldnames = rows[0].keys()
                    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

                    # Запис заголовків та даних
                    writer.writeheader()
                    writer.writerows(rows)

                print(f"Дані успішно експортовано у CSV: {file_path}")
                return str(file_path)
            else:
                print("Немає даних для експорту")
                return None

        except Exception as e:
            print(f"Помилка при експорті в CSV: {e}")
            return None

    def export_to_json(self, data, filename=None, data_type='detections', extra_info=None):
        """
        Експорт даних у формат JSON.
        """
        if not data:
            return None

        # Генерація імені файлу
        if filename is None:
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"{data_type}_{timestamp}"

        # Шлях до файлу
        file_path = self.json_dir / f"{filename}.json"

        try:
            # Підготовка даних для JSON
            export_data = {
                'data_type': data_type,
                'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'data': data
            }

            # Додавання додаткової інформації
            if extra_info:
                export_data['extra_info'] = extra_info

            # Запис даних у JSON
            with open(file_path, 'w', encoding='utf-8') as jsonfile:
                json.dump(export_data, jsonfile, indent=2)

            print(f"Дані успішно експортовано у JSON: {file_path}")
            return str(file_path)

        except Exception as e:
            print(f"Помилка при експорті в JSON: {e}")
            return None

    def export_statistics(self, detection_data=None, tracking_data=None, metrics=None,
                        formats=None, filename=None):
        """
        Експорт статистики у різні формати.
        """
        if formats is None:
            formats = ['csv', 'json']

        if filename is None:
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"stats_{timestamp}"

        # Підготовка статистичних даних
        stats = {
            'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'detection_stats': {},
            'tracking_stats': {}
        }

        # Статистика по виявленням
        if detection_data:
            total_detections = 0
            for group in detection_data:
                total_detections += len(group.get('detections', []))

            stats['detection_stats'] = {
                'total_detections': total_detections
            }

        # Статистика по трекам
        if tracking_data:
            track_ids = set()
            for frame_data in tracking_data:
                for track in frame_data.get('tracks', []):
                    track_ids.add(track.get('track_id', 0))

            stats['tracking_stats'] = {
                'total_tracks': len(track_ids)
            }

        # Додаткові метрики
        if metrics:
            stats['metrics'] = metrics

        # Експорт у вказані формати
        result_paths = {}

        for fmt in formats:
            if fmt.lower() == 'csv':
                path = self.export_to_csv([stats], filename, 'statistics')
                if path:
                    result_paths['csv'] = path
            elif fmt.lower() == 'json':
                path = self.export_to_json(stats, filename, 'statistics')
                if path:
                    result_paths['json'] = path

        return result_paths

    def generate_pdf_report(self, detection_data=None, tracking_data=None,
                          metrics=None, report_type='full', output_path=None,
                          include_images=True, image_paths=None):
        """
        Імітація генерації PDF-звіту.
        """
        if output_path is None:
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
            output_path = self.reports_dir / f"report_{report_type}_{timestamp}.txt"

        try:
            # Створення текстового звіту замість PDF для спрощення
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write("=== Звіт про систему виявлення та відстеження дронів ===\n\n")
                f.write(f"Дата створення: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

                # Загальна інформація
                f.write("== Загальна інформація ==\n")
                if detection_data:
                    total_detections = sum(len(group.get('detections', [])) for group in detection_data)
                    f.write(f"Загальна кількість виявлень: {total_detections}\n")

                if tracking_data:
                    track_ids = set()
                    for frame_data in tracking_data:
                        for track in frame_data.get('tracks', []):
                            track_ids.add(track.get('track_id', 0))
                    f.write(f"Загальна кількість треків: {len(track_ids)}\n")

                f.write("\n")

                # Інформація про використані зображення
                if include_images and image_paths:
                    f.write("== Використані зображення ==\n")
                    for i, path in enumerate(image_paths):
                        f.write(f"{i+1}. {Path(path).name}\n")
                    f.write("\n")

                f.write("=== Кінець звіту ===\n")

            print(f"Текстовий звіт створено: {output_path}")
            return str(output_path)

        except Exception as e:
            print(f"Помилка при створенні звіту: {e}")
            return None


# Ініціалізація модуля експорту
print("Ініціалізація модуля експорту та звітності...")
exporter = SimpleExportReporting(output_dir=os.path.join(base_dir, 'export_results'))

# Експорт детекцій в CSV
print("Експорт результатів детекцій в CSV...")
detection_export_data = [{'frame': 0, 'detections': filtered_detections}]
csv_path = exporter.export_to_csv(
    detection_export_data,
    filename="demo_detections",
    data_type='detections',
    extra_info={'source': 'demo', 'date': time.strftime('%Y-%m-%d')}
)

# Експорт треків в JSON
print("Експорт результатів відстеження в JSON...")
json_path = exporter.export_to_json(
    tracking_results,
    filename="demo_tracking",
    data_type='tracks'
)

# Експорт статистики
print("Експорт статистичних даних...")
stats_export = exporter.export_statistics(
    detection_data=detection_export_data,
    tracking_data=tracking_results,
    formats=['csv', 'json'],
    filename="demo_statistics"
)

# Створення звіту
print("Створення звіту з результатами...")
# Збір шляхів до зображень для звіту
report_images = [
    os.path.join(base_dir, 'visualizations', 'detection_visualization.jpg'),
    os.path.join(base_dir, 'visualizations', 'detection_heatmap.jpg'),
    os.path.join(base_dir, 'visualizations', 'tracking_paths.jpg')
]

# Створення звіту
try:
    report_path = exporter.generate_pdf_report(
        detection_data=detection_export_data,
        tracking_data=tracking_results,
        report_type='full',
        output_path=os.path.join(base_dir, 'export_results', 'demo_full_report.txt'),
        include_images=True,
        image_paths=report_images
    )
    print(f"Звіт створено: {report_path}")
except Exception as e:
    print(f"Помилка при створенні звіту: {e}")
    print("Пропускаємо створення звіту...")

# Підсумкова інформація
print("\n" + "="*80)
print("Демонстрація системи виявлення та відстеження дронів завершена!")
print("="*80)
print(f"Усі результати збережено в директорії: {base_dir}")
print("\nСтруктура результатів:")
print(f"- Результати виявлення: {os.path.join(base_dir, 'detection_result.jpg')}")
print(f"- Результати відстеження: {os.path.join(base_dir, 'tracking_results.jpg')}")
print(f"- Результати фільтрації: {os.path.join(base_dir, 'filtered_results.jpg')}")
print(f"- Візуалізації: {os.path.join(base_dir, 'visualizations')}")
print(f"- Інференс: {os.path.join(base_dir, 'inference_results')}")
print(f"- Експорт та звіти: {os.path.join(base_dir, 'export_results')}")

# Показ підсумкового зображення
plt.figure(figsize=(12, 8))
plt.imshow(path_vis)
plt.title("Результат: відстеження траєкторій дронів")
plt.axis('off')
plt.tight_layout()
plt.show()